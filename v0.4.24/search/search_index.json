{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00a4 Welcome to the documentation of Lux! What is Lux? \u00a4 Lux is a julia deep learning framework which decouples models and parameterization using deeply nested named tuples. Functional Design \u2013 Pure Functions and Deterministic Function Calls. No more implicit parameterization. Compiler and AD-friendly Neural Networks Installation Guide \u00a4 Install julia v1.6 or above . using Pkg Pkg . add ( \"Lux\" ) Resources to Get Started \u00a4 Go through the Quickstart Example . Read the introductory tutorials on julia and Lux Go through the examples sorted based on their complexity in the documentation Tip For usage related questions, please use Github Discussions or JuliaLang Discourse (machine learning domain) which allows questions and answers to be indexed. To report bugs use github issues or even better send in a pull request . Quickstart \u00a4 Tip You need to install Optimisers and Zygote if not done already. Pkg.add([\"Optimisers\", \"Zygote\"]) using Lux , Random , Optimisers , Zygote We take randomness very seriously # Seeding rng = Random . default_rng () Random . seed! ( rng , 0 ) Build the model # Construct the layer model = Chain ( BatchNorm ( 128 ), Dense ( 128 , 256 , tanh ), BatchNorm ( 256 ), Chain ( Dense ( 256 , 1 , tanh ), Dense ( 1 , 10 ))) Models don't hold parameters and states so initialize them. From there on, we just use our standard AD and Optimisers API. # Parameter and State Variables ps , st = Lux . setup ( rng , model ) .|> gpu # Dummy Input x = rand ( rng , Float32 , 128 , 2 ) |> gpu # Run the model y , st = Lux . apply ( model , x , ps , st ) # Gradients ## Pullback API to capture change in state ( l , st_ ), pb = pullback ( p -> Lux . apply ( model , x , p , st ), ps ) gs = pb (( one . ( l ), nothing ))[ 1 ] # Optimization st_opt = Optimisers . setup ( Optimisers . ADAM ( 0.0001 ), ps ) st_opt , ps = Optimisers . update ( st_opt , ps , gs ) How the documentation is structured \u00a4 Having a high-level overview of how this documentation is structured will help you know where to look for certain things. Introduction \u2013 Talks about why we wrote Lux and has pointers to frameworks in the extended julia ecosystem which might help users to get started with deep learning Tutorials \u2013 Contain tutorials of varying complexity. These contain worked examples of solving problems with Lux. Start here if you are new to Lux, or you have a particular problem class you want to model. Manual \u2013 Contains guides to some common problems encountered by users. API Reference \u2013 Contains a complete list of the functions you can use in Lux. Look here if you want to know how to use a particular function. Development Documentation \u2013 Contains information for people contributing to Lux development or writing Lux extensions. Don't worry about this section if you are using Lux to formulate and solve problems as a user. Citation \u00a4 If you found this library to be useful in academic work, then please cite: @misc { pal2022lux , author = {Pal, Avik} , title = {Lux: Explicit Parameterization of Deep Neural Networks in Julia} , year = {2022} , publisher = {GitHub} , journal = {GitHub repository} , howpublished = {\\url{https://github.com/avik-pal/Lux.jl/}} } Also consider starring our github repo","title":"Lux.jl: Explicitly Parameterized Neural Networks"},{"location":"#introduction","text":"Welcome to the documentation of Lux!","title":"Introduction"},{"location":"#what-is-lux","text":"Lux is a julia deep learning framework which decouples models and parameterization using deeply nested named tuples. Functional Design \u2013 Pure Functions and Deterministic Function Calls. No more implicit parameterization. Compiler and AD-friendly Neural Networks","title":"What is Lux?"},{"location":"#installation-guide","text":"Install julia v1.6 or above . using Pkg Pkg . add ( \"Lux\" )","title":"Installation Guide"},{"location":"#resources-to-get-started","text":"Go through the Quickstart Example . Read the introductory tutorials on julia and Lux Go through the examples sorted based on their complexity in the documentation Tip For usage related questions, please use Github Discussions or JuliaLang Discourse (machine learning domain) which allows questions and answers to be indexed. To report bugs use github issues or even better send in a pull request .","title":"Resources to Get Started"},{"location":"#quickstart","text":"Tip You need to install Optimisers and Zygote if not done already. Pkg.add([\"Optimisers\", \"Zygote\"]) using Lux , Random , Optimisers , Zygote We take randomness very seriously # Seeding rng = Random . default_rng () Random . seed! ( rng , 0 ) Build the model # Construct the layer model = Chain ( BatchNorm ( 128 ), Dense ( 128 , 256 , tanh ), BatchNorm ( 256 ), Chain ( Dense ( 256 , 1 , tanh ), Dense ( 1 , 10 ))) Models don't hold parameters and states so initialize them. From there on, we just use our standard AD and Optimisers API. # Parameter and State Variables ps , st = Lux . setup ( rng , model ) .|> gpu # Dummy Input x = rand ( rng , Float32 , 128 , 2 ) |> gpu # Run the model y , st = Lux . apply ( model , x , ps , st ) # Gradients ## Pullback API to capture change in state ( l , st_ ), pb = pullback ( p -> Lux . apply ( model , x , p , st ), ps ) gs = pb (( one . ( l ), nothing ))[ 1 ] # Optimization st_opt = Optimisers . setup ( Optimisers . ADAM ( 0.0001 ), ps ) st_opt , ps = Optimisers . update ( st_opt , ps , gs )","title":"Quickstart"},{"location":"#how-the-documentation-is-structured","text":"Having a high-level overview of how this documentation is structured will help you know where to look for certain things. Introduction \u2013 Talks about why we wrote Lux and has pointers to frameworks in the extended julia ecosystem which might help users to get started with deep learning Tutorials \u2013 Contain tutorials of varying complexity. These contain worked examples of solving problems with Lux. Start here if you are new to Lux, or you have a particular problem class you want to model. Manual \u2013 Contains guides to some common problems encountered by users. API Reference \u2013 Contains a complete list of the functions you can use in Lux. Look here if you want to know how to use a particular function. Development Documentation \u2013 Contains information for people contributing to Lux development or writing Lux extensions. Don't worry about this section if you are using Lux to formulate and solve problems as a user.","title":"How the documentation is structured"},{"location":"#citation","text":"If you found this library to be useful in academic work, then please cite: @misc { pal2022lux , author = {Pal, Avik} , title = {Lux: Explicit Parameterization of Deep Neural Networks in Julia} , year = {2022} , publisher = {GitHub} , journal = {GitHub repository} , howpublished = {\\url{https://github.com/avik-pal/Lux.jl/}} } Also consider starring our github repo","title":"Citation"},{"location":"api/contrib/","text":"All features listed on this page are experimental which means: No SemVer Guarantees. We use code here to iterate fast and most users should wait for these features to be marked non-experimental. The code will probably be moved into a separate repository in the future. Expect edge-cases and report them. It will help us move these features out of experimental sooner. None of the features are exported. Training \u00a4 Note This module will be moved into a separate package in the near future. Helper Functions making it easier to train Lux.jl models. Lux.Training is meant to be simple and provide extremely basic functionality. We provide basic building blocks which can be seamlessly composed to create complex training pipelines. # Lux.Training.AbstractVJP \u2014 Type . AbstractVJP Base Type for all Vector-Jacobian Product Backends. source # Lux.Training.backend \u2014 Function . backend ( :: AbstractVJP ) Package used to compute the VJP. source # Lux.Training.EnzymeVJP \u2014 Type . EnzymeVJP <: AbstractVJP Vector-Jacobian Product using Enzyme. source # Lux.Training.YotaVJP \u2014 Type . YotaVJP <: AbstractVJP Vector-Jacobian Product using Yota. source # Lux.Training.ZygoteVJP \u2014 Type . ZygoteVJP <: AbstractVJP Vector-Jacobian Product using Zygote. source # Lux.Training.TrainState \u2014 Type . TrainState Training State containing: model : `Lux`` model. parameters : Trainable Variables of the model . states : Non-trainable Variables of the model . optimizer_state : Optimizer State. step : Number of updates of the parameters made. source # Lux.Training.compute_gradients \u2014 Function . compute_gradients ( vjp :: AbstractVJP , objective_function :: Function , data , ts :: TrainState ) Compute the gradients of the objective function wrt parameters stored in ts . Arguments vjp : Backend used to compute the gradients. See AbstractVJP . objective_function : Objective function. The function must take 4 inputs \u2013 model, parameters, states and data. The function must return 3 values \u2013 loss, updated_state, and any computed statistics. data : Data used to compute the gradients. ts : Current Training State. See TrainState . Return A 4-Tuple containing: grads : Computed Gradients. loss : Loss from the objective function. stats : Any computed statistics from the objective function. ts : Updated Training State. source # Lux.Training.apply_gradients \u2014 Function . apply_gradients ( ts :: TrainState , grads ) Update the parameters stored in ts using the gradients grads . Arguments ts : TrainState object. grads : Gradients of the loss function wrt ts.params . Returns Updated TrainState object. source Why VJP rules ? \u00a4 In the long term, the goal is to just use AbstractDifferentiation.jl ? directly. However, there are current refactors being planned (See this issue ). Once the package is stable and we have the necessary backend support, we will be dropping the VJP rules in this module. Parameter Freezing \u00a4 Note In the long term, this will be supported via Optimisers.jl . # Lux.FrozenLayer \u2014 Type . FrozenLayer ( l :: AbstractExplicitLayer , which_params :: Union { Tuple , Nothing }) Freeze the parameters with name which_params of the layer l . Tip It is always recommended to use the Lux.freeze function instead of directly using the FrozenLayer constructor. Warning There are no checks for which_params . For example, if the original layer has parameters named (:weight, :bias)``, and which_params is set to (:myweight,)` then none of the parameters are frozen and no error is thrown. Arguments l : Lux AbstractExplicitLayer. which_params : Parameter Names to be Frozen. Can be set to nothing , in which case all parameters are frozen. Input x : Input to the layer l . Returns Output of the inner layer l Updated State Parameters Parameters of the layer l excluding which_params . States frozen_params : Parameters that are frozen, i.e., which_params . states : The state of the inner layer l . Note on Internal Layer Implementation The inner layer should work with NamedTuple parameters. In order to support custom parameter types, users need to implement Lux._merge(::CustomParamType, ::NamedTuple) . Example m = Lux . FrozenLayer ( Dense ( 2 => 2 ), ( :weight ,)) See also Lux.freeze , Lux.unfreeze . source # Lux.freeze \u2014 Function . freeze ( l :: AbstractExplicitLayer , which_params :: Union { Tuple , Nothing } = nothing ) Constructs a version of l with which_params frozen. If which_params is nothing, then all parameters are frozen. source freeze(l::AbstractExplicitLayer, ps, st::NamedTuple, which_params::Union{Tuple, Nothing} = nothing) Construct a Lux.FrozenLayer for l with the current parameters and states. If which_params is nothing, then all parameters are frozen. source # Lux.unfreeze \u2014 Function . unfreeze ( l :: FrozenLayer ) Unfreezes the layer l . source unfreeze(l::FrozenLayer, ps, st::NamedTuple) Unwraps a Lux.FrozenLayer l with the current parameters and states. source For detailed usage example look at the manual page . Map over Layer \u00a4 # Lux.layer_map \u2014 Function . layer_map ( f :: Function , l :: AbstractExplicitLayer , ps , st :: NamedTuple , name :: String = \"model\" ) Map the function f over the model l , with the parameters ps and states st . This is different from Functors.fmap since it zips the layers, parameters, and states and invokes the function on all of them together. Call Signature for f Must take 4 inputs \u2013 AbstractExplicitLayer , Corresponding Parameters, Corresponding States, and the name of the layer. Must return a tuple of 3 elements \u2013 AbstractExplicitLayer , new parameters and the new states. Tip We recommend using the macro Lux.@layer_map instead of this function. It automatically sets the name of the layer to be the variable name. Example using Lux , Random , Setfield c = Parallel ( + ; chain = Chain (; dense_1 = Dense ( 2 => 3 ), bn = BatchNorm ( 3 ), dense_2 = Dense ( 3 => 5 )), dense_3 = Dense ( 5 => 1 )) rng = Random . default_rng () ps , st = Lux . setup ( rng , c ) # Makes parameters of Dense Layers inside Chain zero function zero_dense_params ( l , ps , st , name ) if l isa Dense println ( \"zeroing params of name\" ) @set! ps . weight = zero . ( ps . weight ) @set! ps . bias = zero . ( ps . bias ) end return l , ps , st end Lux . layer_map ( zero_dense_params , c , ps , st ) source # Lux.@layer_map \u2014 Macro . @layer_map func layer ps st See the documentation of Lux.layer_map for more details. This macro eliminates the need to the set the layer name, and uses the variable name as the starting point. Example using Lux , Random , Setfield c = Parallel ( + ; chain = Chain (; dense_1 = Dense ( 2 => 3 ), bn = BatchNorm ( 3 ), dense_2 = Dense ( 3 => 5 )), dense_3 = Dense ( 5 => 1 )) rng = Random . default_rng () ps , st = Lux . setup ( rng , c ) # Makes parameters of Dense Layers inside Chain zero function zero_dense_params ( l , ps , st , name ) if l isa Dense println ( \"zeroing params of name\" ) @set! ps . weight = zero . ( ps . weight ) @set! ps . bias = zero . ( ps . bias ) end return l , ps , st end Lux . @layer_map zero_dense_params c ps st source Index \u00a4 Lux.FrozenLayer Lux.Training.AbstractVJP Lux.Training.EnzymeVJP Lux.Training.TrainState Lux.Training.YotaVJP Lux.Training.ZygoteVJP Lux.Training.apply_gradients Lux.Training.backend Lux.Training.compute_gradients Lux.freeze Lux.layer_map Lux.unfreeze Lux.@layer_map","title":"Experimental"},{"location":"api/contrib/#training","text":"Note This module will be moved into a separate package in the near future. Helper Functions making it easier to train Lux.jl models. Lux.Training is meant to be simple and provide extremely basic functionality. We provide basic building blocks which can be seamlessly composed to create complex training pipelines. # Lux.Training.AbstractVJP \u2014 Type . AbstractVJP Base Type for all Vector-Jacobian Product Backends. source # Lux.Training.backend \u2014 Function . backend ( :: AbstractVJP ) Package used to compute the VJP. source # Lux.Training.EnzymeVJP \u2014 Type . EnzymeVJP <: AbstractVJP Vector-Jacobian Product using Enzyme. source # Lux.Training.YotaVJP \u2014 Type . YotaVJP <: AbstractVJP Vector-Jacobian Product using Yota. source # Lux.Training.ZygoteVJP \u2014 Type . ZygoteVJP <: AbstractVJP Vector-Jacobian Product using Zygote. source # Lux.Training.TrainState \u2014 Type . TrainState Training State containing: model : `Lux`` model. parameters : Trainable Variables of the model . states : Non-trainable Variables of the model . optimizer_state : Optimizer State. step : Number of updates of the parameters made. source # Lux.Training.compute_gradients \u2014 Function . compute_gradients ( vjp :: AbstractVJP , objective_function :: Function , data , ts :: TrainState ) Compute the gradients of the objective function wrt parameters stored in ts . Arguments vjp : Backend used to compute the gradients. See AbstractVJP . objective_function : Objective function. The function must take 4 inputs \u2013 model, parameters, states and data. The function must return 3 values \u2013 loss, updated_state, and any computed statistics. data : Data used to compute the gradients. ts : Current Training State. See TrainState . Return A 4-Tuple containing: grads : Computed Gradients. loss : Loss from the objective function. stats : Any computed statistics from the objective function. ts : Updated Training State. source # Lux.Training.apply_gradients \u2014 Function . apply_gradients ( ts :: TrainState , grads ) Update the parameters stored in ts using the gradients grads . Arguments ts : TrainState object. grads : Gradients of the loss function wrt ts.params . Returns Updated TrainState object. source","title":"Training"},{"location":"api/contrib/#why-vjp-rules","text":"In the long term, the goal is to just use AbstractDifferentiation.jl ? directly. However, there are current refactors being planned (See this issue ). Once the package is stable and we have the necessary backend support, we will be dropping the VJP rules in this module.","title":"Why VJP rules ?"},{"location":"api/contrib/#parameter-freezing","text":"Note In the long term, this will be supported via Optimisers.jl . # Lux.FrozenLayer \u2014 Type . FrozenLayer ( l :: AbstractExplicitLayer , which_params :: Union { Tuple , Nothing }) Freeze the parameters with name which_params of the layer l . Tip It is always recommended to use the Lux.freeze function instead of directly using the FrozenLayer constructor. Warning There are no checks for which_params . For example, if the original layer has parameters named (:weight, :bias)``, and which_params is set to (:myweight,)` then none of the parameters are frozen and no error is thrown. Arguments l : Lux AbstractExplicitLayer. which_params : Parameter Names to be Frozen. Can be set to nothing , in which case all parameters are frozen. Input x : Input to the layer l . Returns Output of the inner layer l Updated State Parameters Parameters of the layer l excluding which_params . States frozen_params : Parameters that are frozen, i.e., which_params . states : The state of the inner layer l . Note on Internal Layer Implementation The inner layer should work with NamedTuple parameters. In order to support custom parameter types, users need to implement Lux._merge(::CustomParamType, ::NamedTuple) . Example m = Lux . FrozenLayer ( Dense ( 2 => 2 ), ( :weight ,)) See also Lux.freeze , Lux.unfreeze . source # Lux.freeze \u2014 Function . freeze ( l :: AbstractExplicitLayer , which_params :: Union { Tuple , Nothing } = nothing ) Constructs a version of l with which_params frozen. If which_params is nothing, then all parameters are frozen. source freeze(l::AbstractExplicitLayer, ps, st::NamedTuple, which_params::Union{Tuple, Nothing} = nothing) Construct a Lux.FrozenLayer for l with the current parameters and states. If which_params is nothing, then all parameters are frozen. source # Lux.unfreeze \u2014 Function . unfreeze ( l :: FrozenLayer ) Unfreezes the layer l . source unfreeze(l::FrozenLayer, ps, st::NamedTuple) Unwraps a Lux.FrozenLayer l with the current parameters and states. source For detailed usage example look at the manual page .","title":"Parameter Freezing"},{"location":"api/contrib/#map-over-layer","text":"# Lux.layer_map \u2014 Function . layer_map ( f :: Function , l :: AbstractExplicitLayer , ps , st :: NamedTuple , name :: String = \"model\" ) Map the function f over the model l , with the parameters ps and states st . This is different from Functors.fmap since it zips the layers, parameters, and states and invokes the function on all of them together. Call Signature for f Must take 4 inputs \u2013 AbstractExplicitLayer , Corresponding Parameters, Corresponding States, and the name of the layer. Must return a tuple of 3 elements \u2013 AbstractExplicitLayer , new parameters and the new states. Tip We recommend using the macro Lux.@layer_map instead of this function. It automatically sets the name of the layer to be the variable name. Example using Lux , Random , Setfield c = Parallel ( + ; chain = Chain (; dense_1 = Dense ( 2 => 3 ), bn = BatchNorm ( 3 ), dense_2 = Dense ( 3 => 5 )), dense_3 = Dense ( 5 => 1 )) rng = Random . default_rng () ps , st = Lux . setup ( rng , c ) # Makes parameters of Dense Layers inside Chain zero function zero_dense_params ( l , ps , st , name ) if l isa Dense println ( \"zeroing params of name\" ) @set! ps . weight = zero . ( ps . weight ) @set! ps . bias = zero . ( ps . bias ) end return l , ps , st end Lux . layer_map ( zero_dense_params , c , ps , st ) source # Lux.@layer_map \u2014 Macro . @layer_map func layer ps st See the documentation of Lux.layer_map for more details. This macro eliminates the need to the set the layer name, and uses the variable name as the starting point. Example using Lux , Random , Setfield c = Parallel ( + ; chain = Chain (; dense_1 = Dense ( 2 => 3 ), bn = BatchNorm ( 3 ), dense_2 = Dense ( 3 => 5 )), dense_3 = Dense ( 5 => 1 )) rng = Random . default_rng () ps , st = Lux . setup ( rng , c ) # Makes parameters of Dense Layers inside Chain zero function zero_dense_params ( l , ps , st , name ) if l isa Dense println ( \"zeroing params of name\" ) @set! ps . weight = zero . ( ps . weight ) @set! ps . bias = zero . ( ps . bias ) end return l , ps , st end Lux . @layer_map zero_dense_params c ps st source","title":"Map over Layer"},{"location":"api/contrib/#index","text":"Lux.FrozenLayer Lux.Training.AbstractVJP Lux.Training.EnzymeVJP Lux.Training.TrainState Lux.Training.YotaVJP Lux.Training.ZygoteVJP Lux.Training.apply_gradients Lux.Training.backend Lux.Training.compute_gradients Lux.freeze Lux.layer_map Lux.unfreeze Lux.@layer_map","title":"Index"},{"location":"api/core/","text":"Abstract Types \u00a4 # Lux.AbstractExplicitLayer \u2014 Type . AbstractExplicitLayer Abstract Type for all Lux Layers Users implementing their custom layer, must implement initialparameters(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) \u2013 This returns a NamedTuple containing the trainable parameters for the layer. initialstates(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) \u2013 This returns a NamedTuple containing the current state for the layer. For most layers this is typically empty. Layers that would potentially contain this include BatchNorm , LSTM , GRU etc. Optionally: parameterlength(layer::CustomAbstractExplicitLayer) \u2013 These can be automatically calculated, but it is recommended that the user defines these. statelength(layer::CustomAbstractExplicitLayer) \u2013 These can be automatically calculated, but it is recommended that the user defines these. See also AbstractExplicitContainerLayer source # Lux.AbstractExplicitContainerLayer \u2014 Type . AbstractExplicitContainerLayer { layers } <: AbstractExplicitLayer Abstract Container Type for certain Lux Layers. layers is a tuple containing fieldnames for the layer, and constructs the parameters and states using those. Users implementing their custom layer can extend the same functions as in AbstractExplicitLayer . Tip Advanced structure manipulation of these layers post construction is possible via Functors.fmap . For a more flexible interface, we recommend using the experimental feature Lux.@layer_map . source General \u00a4 # Lux.apply \u2014 Function . apply ( model :: AbstractExplicitLayer , x , ps :: Union { ComponentArray , NamedTuple }, st :: NamedTuple ) Simply calls model(x, ps, st) source # Lux.setup \u2014 Function . setup ( rng :: AbstractRNG , l :: AbstractExplicitLayer ) Shorthand for getting the parameters and states of the layer l . Is equivalent to (initialparameters(rng, l), initialstates(rng, l)) . Warning This function is not pure, it mutates rng . source Parameters \u00a4 # Lux.initialparameters \u2014 Function . initialparameters ( rng :: AbstractRNG , l ) Generate the initial parameters of the layer l . source # Lux.parameterlength \u2014 Function . parameterlength ( l ) Return the total number of parameters of the layer l . source States \u00a4 # Lux.initialstates \u2014 Function . initialstates ( rng :: AbstractRNG , l ) Generate the initial states of the layer l . source # Lux.statelength \u2014 Function . statelength ( l ) Return the total number of states of the layer l . source # Lux.testmode \u2014 Function . testmode ( st :: NamedTuple ) Make all occurances of training in state st \u2013 Val(false) . source # Lux.trainmode \u2014 Function . trainmode ( st :: NamedTuple ) Make all occurances of training in state st \u2013 Val(true) . source # Lux.update_state \u2014 Function . update_state ( st :: NamedTuple , key :: Symbol , value ; layer_check = _default_layer_check ( key )) Recursively update all occurances of the key in the state st with the value . source Index \u00a4 Lux.AbstractExplicitContainerLayer Lux.AbstractExplicitLayer Lux.apply Lux.initialparameters Lux.initialstates Lux.parameterlength Lux.setup Lux.statelength Lux.testmode Lux.trainmode Lux.update_state","title":"Core"},{"location":"api/core/#abstract-types","text":"# Lux.AbstractExplicitLayer \u2014 Type . AbstractExplicitLayer Abstract Type for all Lux Layers Users implementing their custom layer, must implement initialparameters(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) \u2013 This returns a NamedTuple containing the trainable parameters for the layer. initialstates(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) \u2013 This returns a NamedTuple containing the current state for the layer. For most layers this is typically empty. Layers that would potentially contain this include BatchNorm , LSTM , GRU etc. Optionally: parameterlength(layer::CustomAbstractExplicitLayer) \u2013 These can be automatically calculated, but it is recommended that the user defines these. statelength(layer::CustomAbstractExplicitLayer) \u2013 These can be automatically calculated, but it is recommended that the user defines these. See also AbstractExplicitContainerLayer source # Lux.AbstractExplicitContainerLayer \u2014 Type . AbstractExplicitContainerLayer { layers } <: AbstractExplicitLayer Abstract Container Type for certain Lux Layers. layers is a tuple containing fieldnames for the layer, and constructs the parameters and states using those. Users implementing their custom layer can extend the same functions as in AbstractExplicitLayer . Tip Advanced structure manipulation of these layers post construction is possible via Functors.fmap . For a more flexible interface, we recommend using the experimental feature Lux.@layer_map . source","title":"Abstract Types"},{"location":"api/core/#general","text":"# Lux.apply \u2014 Function . apply ( model :: AbstractExplicitLayer , x , ps :: Union { ComponentArray , NamedTuple }, st :: NamedTuple ) Simply calls model(x, ps, st) source # Lux.setup \u2014 Function . setup ( rng :: AbstractRNG , l :: AbstractExplicitLayer ) Shorthand for getting the parameters and states of the layer l . Is equivalent to (initialparameters(rng, l), initialstates(rng, l)) . Warning This function is not pure, it mutates rng . source","title":"General"},{"location":"api/core/#parameters","text":"# Lux.initialparameters \u2014 Function . initialparameters ( rng :: AbstractRNG , l ) Generate the initial parameters of the layer l . source # Lux.parameterlength \u2014 Function . parameterlength ( l ) Return the total number of parameters of the layer l . source","title":"Parameters"},{"location":"api/core/#states","text":"# Lux.initialstates \u2014 Function . initialstates ( rng :: AbstractRNG , l ) Generate the initial states of the layer l . source # Lux.statelength \u2014 Function . statelength ( l ) Return the total number of states of the layer l . source # Lux.testmode \u2014 Function . testmode ( st :: NamedTuple ) Make all occurances of training in state st \u2013 Val(false) . source # Lux.trainmode \u2014 Function . trainmode ( st :: NamedTuple ) Make all occurances of training in state st \u2013 Val(true) . source # Lux.update_state \u2014 Function . update_state ( st :: NamedTuple , key :: Symbol , value ; layer_check = _default_layer_check ( key )) Recursively update all occurances of the key in the state st with the value . source","title":"States"},{"location":"api/core/#index","text":"Lux.AbstractExplicitContainerLayer Lux.AbstractExplicitLayer Lux.apply Lux.initialparameters Lux.initialstates Lux.parameterlength Lux.setup Lux.statelength Lux.testmode Lux.trainmode Lux.update_state","title":"Index"},{"location":"api/functional/","text":"Functional Layers \u00a4 Note These functions expose the backend of Lux.jl . In the long-term we plan to move these into NNlib # Lux.dropout \u2014 Function . dropout ( rng :: AbstractRNG , x , p , q , dims , :: Val { training }) dropout ( rng :: AbstractRNG , x , mask , p , q , dims , t :: Val { training }, :: Val { update_mask }) If training then dropout is applied on x with probability p along dims . If mask is passed it is used if update_mask is false. If update_mask is true then the mask is generated and used. source # Lux.normalization \u2014 Function . normalization ( x , running_mean , running_var , scale , bias , activation , reduce_dims , :: Val { training }, momentum , epsilon ) Performs BatchNorm/GroupNorm/InstanceNorm based on input configuration Note Detailed docs are WIP source","title":"Functional"},{"location":"api/functional/#functional-layers","text":"Note These functions expose the backend of Lux.jl . In the long-term we plan to move these into NNlib # Lux.dropout \u2014 Function . dropout ( rng :: AbstractRNG , x , p , q , dims , :: Val { training }) dropout ( rng :: AbstractRNG , x , mask , p , q , dims , t :: Val { training }, :: Val { update_mask }) If training then dropout is applied on x with probability p along dims . If mask is passed it is used if update_mask is false. If update_mask is true then the mask is generated and used. source # Lux.normalization \u2014 Function . normalization ( x , running_mean , running_var , scale , bias , activation , reduce_dims , :: Val { training }, momentum , epsilon ) Performs BatchNorm/GroupNorm/InstanceNorm based on input configuration Note Detailed docs are WIP source","title":"Functional Layers"},{"location":"api/layers/","text":"Containers \u00a4 # Lux.BranchLayer \u2014 Type . BranchLayer ( layers ... ) BranchLayer (; layers ... ) Takes an input x and passes it through all the layers and returns a tuple of the outputs. Arguments Layers can be specified in two formats: A list of N Lux layers Specified as N keyword arguments. Inputs x : Will be directly passed to each of the layers Returns Tuple: (layer_1(x), layer_2(x), ..., layer_N(x)) (naming changes if using the kwargs API) Updated state of the layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) Comparison with Parallel This is slightly different from Parallel(nothing, layers...) If the input is a tuple, Parallel will pass each element individually to each layer. BranchLayer essentially assumes 1 input comes in and is branched out into N outputs. Example An easy way to replicate an input to an NTuple is to do l = BranchLayer ( NoOpLayer (), NoOpLayer (), NoOpLayer ()) source # Lux.Chain \u2014 Type . Chain ( layers ... ; disable_optimizations :: Bool = false ) Chain (; layers ... , disable_optimizations :: Bool = false ) Collects multiple layers / functions to be called in sequence on a given input. Arguments Layers can be specified in two formats: A list of N Lux layers Specified as N keyword arguments. Keyword Arguments disable_optimizations : Prevents any structural optimization Inputs Input x is passed sequentially to each layer, and must conform to the input requirements of the internal layers. Returns Output after sequentially applying all the layers to x Updated model states Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) Optimizations Performs a few optimizations to generate reasonable architectures. Can be disabled using keyword argument disable_optimizations . All sublayers are recursively optimized. If a function f is passed as a layer and it doesn't take 3 inputs, it is converted to a WrappedFunction ( f ) which takes only one input. If the layer is a Chain, it is flattened. NoOpLayer s are removed. If there is only 1 layer (left after optimizations), then it is returned without the Chain wrapper. If there are no layers (left after optimizations), a NoOpLayer is returned. Miscellaneous Properties Allows indexing. We can access the i th layer using m[i] . We can also index using ranges or arrays. Example c = Chain ( Dense ( 2 , 3 , relu ), BatchNorm ( 3 ), Dense ( 3 , 2 )) source # Lux.PairwiseFusion \u2014 Type . PairwiseFusion ( connection , layers ... ) PairwiseFusion ( connection ; layers ... ) x1 \u2192 layer1 \u2192 y1 \u2198 connection \u2192 layer2 \u2192 y2 \u2198 x2 \u2197 connection \u2192 y3 x3 \u2197 Arguments connection : Takes 2 inputs and combines them layers : AbstractExplicitLayer s. Layers can be specified in two formats: A list of N Lux layers Specified as N keyword arguments. Inputs Layer behaves differently based on input type: If the input x is a tuple of length N + 1 , then the layers must be a tuple of length N . The computation is as follows y = x [ 1 ] for i in 1 : N y = connection ( x [ i + 1 ], layers [ i ]( y )) end Any other kind of input y = x for i in 1 : N y = connection ( x , layers [ i ]( y )) end Returns See Inputs section for how the return value is computed Updated model state for all the contained layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) source # Lux.Parallel \u2014 Type . Parallel ( connection , layers ... ) Parallel ( connection ; layers ... ) Create a layer which passes an input to each path in layers , before reducing the output with connection . Arguments connection : An N -argument function that is called after passing the input through each layer. If connection = nothing , we return a tuple Parallel(nothing, f, g)(x, y) = (f(x), g(y)) Layers can be specified in two formats: A list of N Lux layers Specified as N keyword arguments. Inputs x : If x is not a tuple, then return is computed as connection([l(x) for l in layers]...) . Else one is passed to each layer, thus Parallel(+, f, g)(x, y) = f(x) + g(y) . Returns See the Inputs section for how the output is computed Updated state of the layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) See also SkipConnection which is Parallel with one identity. source # Lux.SkipConnection \u2014 Type . SkipConnection ( layer , connection ) Create a skip connection which consists of a layer or Chain of consecutive layers and a shortcut connection linking the block's input to the output through a user-supplied 2-argument callable. The first argument to the callable will be propagated through the given layer while the second is the unchanged, \"skipped\" input. The simplest \"ResNet\"-type connection is just SkipConnection(layer, +) . Arguments layer : Layer or Chain of layers to be applied to the input connection : A 2-argument function that takes layer(input) and the input Inputs x : Will be passed directly to layer Returns Output of connection(layer(input), input) Updated state of layer Parameters Parameters of layer States States of layer See Parallel for a more general implementation. source Convolutional Layers \u00a4 # Lux.Conv \u2014 Type . Conv ( k :: NTuple { N , Integer }, ( in_chs => out_chs ) :: Pair { <: Integer , <: Integer }, activation = identity ; init_weight = glorot_uniform , init_bias = zeros32 , stride = 1 , pad = 0 , dilation = 1 , groups = 1 , use_bias = true ) Standard convolutional layer. Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100 x 100 RGB image would be a 100 x 100 x 3 x 1 array, and a batch of 50 would be a 100 x 100 x 3 x 50 array. This has N = 2 spatial dimensions, and needs a kernel size like (5, 5) , a 2-tuple of integers. To take convolutions along N feature dimensions, this layer expects as input an array with ndims(x) == N + 2 , where size(x, N + 1) == in_chs is the number of input channels, and size(x, ndims(x)) is the number of observations in a batch. Note Frameworks like Pytorch perform cross-correlation in their convolution layers Arguments k : Tuple of integers specifying the size of the convolutional kernel. Eg, for 2D convolutions length(k) == 2 in_chs : Number of input channels out_chs : Number of input and output channels activation : Activation Function Keyword Arguments init_weight : Controls the initialization of the weight parameter init_bias : Controls the initialization of the bias parameter stride : Should each be either single integer, or a tuple with N integers dilation : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. groups : Expected to be an Int . It specifies the number of groups to divide a convolution into (set groups = in_chs for Depthwise Convolutions). in_chs and out_chs must be divisible by groups . use_bias : Trainable bias can be disabled entirely by setting this to false . allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Inputs x : Data satisfying ndims(x) == N + 2 && size(x, N - 1) == in_chs , i.e. size(x) = (I_N, ..., I_1, C_in, N) Returns Output of the convolution y of size (O_N, ..., O_1, C_out, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() Parameters weight : Convolution kernel bias : Bias (present if bias=true ) source Dropout Layers \u00a4 # Lux.Dropout \u2014 Type . Dropout ( p ; dims =: ) Dropout layer. Arguments p : Probability of Dropout (if p = 0 then NoOpLayer is returned) Keyword Arguments To apply dropout along certain dimension(s), specify the dims keyword. e.g. Dropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout). Inputs x : Must be an AbstractArray Returns x with dropout mask applied if training=Val(true) else just x State with updated rng States rng : Pseudo Random Number Generator training : Used to check if training/inference mode Call Lux.testmode to switch to test mode. See also VariationalHiddenDropout source # Lux.VariationalHiddenDropout \u2014 Type . VariationalHiddenDropout ( p ; dims =: ) VariationalHiddenDropout layer. The only difference from Dropout is that the mask is retained until Lux.update_state(l, :update_mask, Val(true)) is called. Arguments p : Probability of Dropout (if p = 0 then NoOpLayer is returned) Keyword Arguments To apply dropout along certain dimension(s), specify the dims keyword. e.g. VariationalHiddenDropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout). Inputs x : Must be an AbstractArray Returns x with dropout mask applied if training=Val(true) else just x State with updated rng States rng : Pseudo Random Number Generator training : Used to check if training/inference mode mask : Dropout mask. Initilly set to nothing. After every run, contains the mask applied in that call update_mask : Stores whether new mask needs to be generated in the current call Call Lux.testmode to switch to test mode. See also Dropout source Pooling Layers \u00a4 # Lux.AdaptiveMaxPool \u2014 Type . AdaptiveMaxPool ( out :: NTuple ) Adaptive Max Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out . Arguments out : Size of the first N dimensions for the output Inputs x : Expects as input an array with ndims(x) == N+2 , i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out) . Returns Output of size (out..., C, N) Empty NamedTuple() See also MaxPool , AdaptiveMeanPool . source # Lux.AdaptiveMeanPool \u2014 Type . AdaptiveMeanPool ( out :: NTuple ) Adaptive Mean Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out . Arguments out : Size of the first N dimensions for the output Inputs x : Expects as input an array with ndims(x) == N+2 , i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out) . Returns Output of size (out..., C, N) Empty NamedTuple() See also MeanPool , AdaptiveMaxPool . source # Lux.GlobalMaxPool \u2014 Type . GlobalMaxPool () Global Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing max pooling on the complete (w,h)-shaped feature maps. Inputs x : Data satisfying ndims(x) > 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (1, ..., 1, C, N) Empty NamedTuple() See also MaxPool , AdaptiveMaxPool , GlobalMeanPool source # Lux.GlobalMeanPool \u2014 Type . GlobalMeanPool () Global Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing mean pooling on the complete (w,h)-shaped feature maps. Inputs x : Data satisfying ndims(x) > 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (1, ..., 1, C, N) Empty NamedTuple() See also MeanPool , AdaptiveMeanPool , GlobalMaxPool source # Lux.MaxPool \u2014 Type . MaxPool ( window :: NTuple ; pad = 0 , stride = window ) Max pooling layer, which replaces all pixels in a block of size window with the maximum value. Arguments window : Tuple of integers specifying the size of the window. Eg, for 2D pooling length(window) == 2 Keyword Arguments stride : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. Inputs x : Data satisfying ndims(x) == N + 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (O_N, ..., O_1, C, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() See also Conv , MeanPool , GlobalMaxPool , AdaptiveMaxPool source # Lux.MeanPool \u2014 Type . MeanPool ( window :: NTuple ; pad = 0 , stride = window ) Mean pooling layer, which replaces all pixels in a block of size window with the mean value. Arguments window : Tuple of integers specifying the size of the window. Eg, for 2D pooling length(window) == 2 Keyword Arguments stride : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. Inputs x : Data satisfying ndims(x) == N + 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (O_N, ..., O_1, C, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() See also Conv , MaxPool , GlobalMeanPool , AdaptiveMeanPool source Recurrent Layers \u00a4 Warning Recurrent Layers API should be considered Experimental at this point # Lux.GRUCell \u2014 Type . GRUCell (( in_dims , out_dims ) :: Pair { <: Int , <: Int }; use_bias = true , train_state :: Bool = false , init_weight :: Tuple { Function , Function , Function } = ( glorot_uniform , glorot_uniform , glorot_uniform ), init_bias :: Tuple { Function , Function , Function } = ( zeros32 , zeros32 , zeros32 ), init_state :: Function = zeros32 ) Gated Recurrent Unit (GRU) Cell \\[ \\begin{align} r &= \\sigma(W_{ir} \\times x + W_{hr} \\times h_{prev} + b_{hr})\\\\ z &= \\sigma(W_{iz} \\times x + W_{hz} \\times h_{prev} + b_{hz})\\\\ n &= \\sigma(W_{in} \\times x + b_{in} + r \\cdot (W_{hn} \\times h_{prev} + b_{hn}))\\\\ h_{new} &= (1 - z) \\cdot n + z \\cdot h_{prev} \\end{align} \\] Arguments in_dims : Input Dimension out_dims : Output (Hidden State) Dimension use_bias : Set to false to deactivate bias train_state : Trainable initial hidden state can be activated by setting this to true init_bias : Initializer for bias. Must be a tuple containing 3 functions init_weight : Initializer for weight. Must be a tuple containing 3 functions init_state : Initializer for hidden state Inputs Case 1a: Only a single input x of shape (in_dims, batch_size) , train_state is set to false - Creates a hidden state using init_state and proceeds to Case 2. Case 1b: Only a single input x of shape (in_dims, batch_size) , train_state is set to true - Repeats hidden_state from parameters to match the shape of x and proceeds to Case 2. Case 2: Tuple (x, (h, )) is provided, then the output and a tuple containing the updated hidden state is returned. Returns Tuple containing Output \\(h_{new}\\) of shape (out_dims, batch_size) Tuple containing new hidden state \\(h_{new}\\) Updated model state Parameters weight_i : Concatenated Weights to map from input space \\(\\\\left\\\\{ W_{ir}, W_{iz}, W_{in} \\\\right\\\\}\\) . weight_h : Concatenated Weights to map from hidden space \\(\\\\left\\\\{ W_{hr}, W_{hz}, W_{hn} \\\\right\\\\}\\) bias_i : Bias vector ( \\(b_{in}\\) ; not present if use_bias=false ) bias_h : Concatenated Bias vector for the hidden space \\(\\\\left\\\\{ b_{hr}, b_{hz}, b_{hn} \\\\right\\\\}\\) (not present if use_bias=false ) hidden_state : Initial hidden state vector (not present if train_state=false ) \\(\\\\left\\\\{ b_{hr}, b_{hz}, b_{hn} \\\\right\\\\}\\) States rng : Controls the randomness (if any) in the initial state generation source # Lux.LSTMCell \u2014 Type . LSTMCell ( in_dims => out_dims ; use_bias :: Bool = true , train_state :: Bool = false , train_memory :: Bool = false , init_weight = ( glorot_uniform , glorot_uniform , glorot_uniform , glorot_uniform ), init_bias = ( zeros32 , zeros32 , ones32 , zeros32 ), init_state = zeros32 , init_memory = zeros32 ) Long Short-Term (LSTM) Cell \\[ \\begin{align} i &= \\sigma(W_{ii} \\times x + W_{hi} \\times h_{prev} + b_{i})\\\\ f &= \\sigma(W_{if} \\times x + W_{hf} \\times h_{prev} + b_{f})\\\\ g &= tanh(W_{ig} \\times x + W_{hg} \\times h_{prev} + b_{g})\\\\ o &= \\sigma(W_{io} \\times x + W_{ho} \\times h_{prev} + b_{o})\\\\ c_{new} &= f \\cdot c_{prev} + i \\cdot g\\\\ h_{new} &= o \\cdot tanh(c_{new}) \\end{align} \\] Arguments in_dims : Input Dimension out_dims : Output (Hidden State & Memory) Dimension use_bias : Set to false to deactivate bias train_state : Trainable initial hidden state can be activated by setting this to true train_memory : Trainable initial memory can be activated by setting this to true init_bias : Initializer for bias. Must be a tuple containing 4 functions init_weight : Initializer for weight. Must be a tuple containing 4 functions init_state : Initializer for hidden state init_memory : Initializer for memory Inputs Case 1a: Only a single input x of shape (in_dims, batch_size) , train_state is set to false , train_memory is set to false - Creates a hidden state using init_state , hidden memory using init_memory and proceeds to Case 2. Case 1b: Only a single input x of shape (in_dims, batch_size) , train_state is set to true , train_memory is set to false - Repeats hidden_state vector from the parameters to match the shape of x , creates hidden memory using init_memory and proceeds to Case 2. Case 1c: Only a single input x of shape (in_dims, batch_size) , train_state is set to false , train_memory is set to true - Creates a hidden state using init_state , repeats the memory vector from parameters to match the shape of x and proceeds to Case 2. Case 1d: Only a single input x of shape (in_dims, batch_size) , train_state is set to true , train_memory is set to true - Repeats the hidden state and memory vectors from the parameters to match the shape of x and proceeds to Case 2. Case 2: Tuple (x, (h, c)) is provided, then the output and a tuple containing the updated hidden state and memory is returned. Returns Tuple Containing Output \\(h_{new}\\) of shape (out_dims, batch_size) Tuple containing new hidden state \\(h_{new}\\) and new memory \\(c_{new}\\) Updated model state Parameters weight_i : Concatenated Weights to map from input space \\(\\left\\{ W_{ii}, W_{if}, W_{ig}, W_{io} \\right\\}\\) . weight_h : Concatenated Weights to map from hidden space \\(\\left\\{ W_{hi}, W_{hf}, W_{hg}, W_{ho} \\right\\}\\) bias : Bias vector (not present if use_bias=false ) hidden_state : Initial hidden state vector (not present if train_state=false ) memory : Initial memory vector (not present if train_memory=false ) States rng : Controls the randomness (if any) in the initial state generation source # Lux.RNNCell \u2014 Type . RNNCell ( in_dims => out_dims , activation = tanh ; bias :: Bool = true , train_state :: Bool = false , init_bias = zeros32 , init_weight = glorot_uniform , init_state = ones32 ) An Elman RNNCell cell with activation (typically set to tanh or relu ). \\(h_{new} = activation(weight_{ih} \\times x + weight_{hh} \\times h_{prev} + bias)\\) Arguments in_dims : Input Dimension out_dims : Output (Hidden State) Dimension activation : Activation function bias : Set to false to deactivate bias train_state : Trainable initial hidden state can be activated by setting this to true init_bias : Initializer for bias init_weight : Initializer for weight init_state : Initializer for hidden state Inputs Case 1a: Only a single input x of shape (in_dims, batch_size) , train_state is set to false - Creates a hidden state using init_state and proceeds to Case 2. Case 1b: Only a single input x of shape (in_dims, batch_size) , train_state is set to true - Repeats hidden_state from parameters to match the shape of x and proceeds to Case 2. Case 2: Tuple (x, (h, )) is provided, then the output and a tuple containing the updated hidden state is returned. Returns Tuple containing Output \\(h_{new}\\) of shape (out_dims, batch_size) Tuple containing new hidden state \\(h_{new}\\) Updated model state Parameters weight_ih : Maps the input to the hidden state. weight_hh : Maps the hidden state to the hidden state. bias : Bias vector (not present if bias=false ) hidden_state : Initial hidden state vector (not present if train_state=false ) States rng : Controls the randomness (if any) in the initial state generation source Linear Layers \u00a4 # Lux.Dense \u2014 Type . Dense ( in_dims => out_dims , activation = identity ; init_weight = glorot_uniform , init_bias = zeros32 , bias :: Bool = true ) Create a traditional fully connected layer, whose forward pass is given by: y = activation.(weight * x .+ bias) Arguments in_dims : number of input dimensions out_dims : number of output dimensions activation : activation function Keyword Arguments init_weight : initializer for the weight matrix ( weight = init_weight(rng, out_dims, in_dims) ) init_bias : initializer for the bias vector (ignored if use_bias=false ) use_bias : Trainable bias can be disabled entirely by setting this to false allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Input x must be an AbstractArray with size(x, 1) == in_dims Returns AbstractArray with dimensions (out_dims, ...) where ... are the dimensions of x Empty NamedTuple() Parameters weight : Weight Matrix of size (out_dims, in_dims) bias : Bias of size (out_dims, 1) (present if use_bias=true ) source # Lux.Scale \u2014 Type . Scale ( dims , activation = identity ; init_weight = ones32 , init_bias = zeros32 , bias :: Bool = true ) Create a Sparsely Connected Layer with a very specific structure (only Diagonal Elements are non-zero). The forward pass is given by: y = activation.(weight .* x .+ bias) Arguments dims : size of the learnable scale and bias parameters. activation : activation function Keyword Arguments init_weight : initializer for the weight matrix ( weight = init_weight(rng, out_dims, in_dims) ) init_bias : initializer for the bias vector (ignored if use_bias=false ) use_bias : Trainable bias can be disabled entirely by setting this to false allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Input x must be an Array of size (dims..., B) or (dims...[0], ..., dims[k]) for k \u2264 size(dims) Returns Array of size (dims..., B) or (dims...[0], ..., dims[k]) for k \u2264 size(dims) Empty NamedTuple() Parameters weight : Weight Array of size (dims...) bias : Bias of size (dims...) Lux 0.4.3 Scale with multiple dimensions requires at least Lux 0.4.3. source Misc. Helper Layers \u00a4 # Lux.ActivationFunction \u2014 Function . ActivationFunction ( f ) Broadcast f on the input. Arguments f : Activation function Inputs x : Any array type s.t. f can be broadcasted over it Returns Broadcasted Activation f.(x) Empty NamedTuple() Warning This layer is deprecated and will be removed in v0.5. Use WrappedFunction with manual broadcasting source # Lux.FlattenLayer \u2014 Type . FlattenLayer () Flattens the passed array into a matrix. Inputs x : AbstractArray Returns AbstractMatrix of size (:, size(x, ndims(x))) Empty NamedTuple() source # Lux.NoOpLayer \u2014 Type . NoOpLayer () As the name suggests does nothing but allows pretty printing of layers. Whatever input is passed is returned. source # Lux.ReshapeLayer \u2014 Type . ReshapeLayer ( dims ) Reshapes the passed array to have a size of (dims..., :) Arguments dims : The new dimensions of the array (excluding the last dimension). Inputs x : AbstractArray of any shape which can be reshaped in (dims..., size(x, ndims(x))) Returns AbstractArray of size (dims..., size(x, ndims(x))) Empty NamedTuple() source # Lux.SelectDim \u2014 Type . SelectDim ( dim , i ) Return a view of all the data of the input x where the index for dimension dim equals i . Equivalent to view(x,:,:,...,i,:,:,...) where i is in position d . Arguments dim : Dimension for indexing i : Index for dimension dim Inputs x : AbstractArray that can be indexed with view(x,:,:,...,i,:,:,...) Returns view(x,:,:,...,i,:,:,...) where i is in position d Empty NamedTuple() source # Lux.WrappedFunction \u2014 Type . WrappedFunction ( f ) Wraps a stateless and parameter less function. Might be used when a function is added to Chain . For example, Chain(x -> relu.(x)) would not work and the right thing to do would be Chain((x, ps, st) -> (relu.(x), st)) . An easier thing to do would be Chain(WrappedFunction(Base.Fix1(broadcast, relu))) Arguments f::Function : A stateless and parameterless function Inputs x : s.t hasmethod(f, (typeof(x),)) is true Returns Output of f(x) Empty NamedTuple() source Normalization Layers \u00a4 # Lux.BatchNorm \u2014 Type . BatchNorm ( chs :: Integer , activation = identity ; init_bias = zeros32 , init_scale = ones32 , affine = true , track_stats = true , epsilon = 1f-5 , momentum = 0.1f0 ) Batch Normalization layer. BatchNorm computes the mean and variance for each D_1 \u00d7 ... \u00d7 D_{N-2} \u00d7 1 \u00d7 D_N input slice and normalises the input accordingly. Arguments chs : Size of the channel dimension in your data. Given an array with N dimensions, call the N-1 th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension. activation : After normalization, elementwise activation activation is applied. Keyword Arguments If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed If track_stats=true , accumulates mean and variance statistics in training phase that will be used to renormalize the input in test phase. epsilon : a value added to the denominator for numerical stability momentum : the value used for the running_mean and running_var computation allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Inputs x : Array where size(x, N - 1) = chs and ndims(x) > 2 Returns y : Normalized Array Update model state Parameters affine=true bias : Bias of shape (chs,) scale : Scale of shape (chs,) affine=false - Empty NamedTuple() States Statistics if track_stats=true running_mean : Running mean of shape (chs,) running_var : Running variance of shape (chs,) Statistics if track_stats=false running_mean : nothing running_var : nothing training : Used to check if training/inference mode Use Lux.testmode during inference. Example m = Chain ( Dense ( 784 => 64 ), BatchNorm ( 64 , relu ), Dense ( 64 => 10 ), BatchNorm ( 10 )) Warning Passing a batch size of 1, during training will result in NaNs. See also GroupNorm source # Lux.GroupNorm \u2014 Type . GroupNorm ( chs :: Integer , groups :: Integer , activation = identity ; init_bias = zeros32 , init_scale = ones32 , affine = true , track_stats = true , epsilon = 1f-5 , momentum = 0.1f0 ) Group Normalization layer. Arguments chs : Size of the channel dimension in your data. Given an array with N dimensions, call the N-1 th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension. groups is the number of groups along which the statistics are computed. The number of channels must be an integer multiple of the number of groups. activation : After normalization, elementwise activation activation is applied. Keyword Arguments If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed If track_stats=true , accumulates mean and variance statistics in training phase that will be used to renormalize the input in test phase. (This feature has been deprecated and will be removed in v0.5) epsilon : a value added to the denominator for numerical stability momentum : the value used for the running_mean and running_var computation (This feature has been deprecated and will be removed in v0.5) allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Inputs x : Array where size(x, N - 1) = chs and ndims(x) > 2 Returns y : Normalized Array Update model state Parameters affine=true bias : Bias of shape (chs,) scale : Scale of shape (chs,) affine=false - Empty NamedTuple() States Statistics if track_stats=true (DEPRECATED) running_mean : Running mean of shape (groups,) running_var : Running variance of shape (groups,) Statistics if track_stats=false running_mean : nothing running_var : nothing training : Used to check if training/inference mode Use Lux.testmode during inference. Example m = Chain ( Dense ( 784 => 64 ), GroupNorm ( 64 , 4 , relu ), Dense ( 64 => 10 ), GroupNorm ( 10 , 5 )) Warning GroupNorm doesn't have CUDNN support. The GPU fallback is not very efficient. See also BatchNorm source # Lux.LayerNorm \u2014 Type . LayerNorm ( shape :: NTuple { N , Int }, activation = identity ; epsilon = 1f-5 , dims = Colon (), affine :: Bool = false , init_bias = zeros32 , init_scale = ones32 ,) Computes mean and standard deviation over the whole input array, and uses these to normalize the whole array. Optionally applies an elementwise affine transformation afterwards. Given an input array \\(x\\) , this layer computes \\[ y = \\frac{x - \\mathbb{E}[x]}{\\sqrt{Var[x] + \\epsilon}} * \\gamma + \\beta \\] where \\(\\gamma\\) & \\(\\beta\\) are trainable parameters if affine=true . Arguments shape : Broadcastable shape of input array excluding the batch dimension. activation : After normalization, elementwise activation activation is applied. Keyword Arguments epsilon : a value added to the denominator for numerical stability. dims : Dimensions to normalize the array over. If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Inputs x : AbstractArray Returns y : Normalized Array Empty NamedTuple() Parameters affine=false : Empty NamedTuple() affine=true bias : Bias of shape (shape..., 1) scale : Scale of shape (shape..., 1) source # Lux.WeightNorm \u2014 Type . WeightNorm ( layer :: AbstractExplicitLayer , which_params :: NTuple { N , Symbol }, dims :: Union { Tuple , Nothing } = nothing ) Applies weight normalization to a parameter in the given layer. \\(w = g\\frac{v}{\\|v\\|}\\) Weight normalization is a reparameterization that decouples the magnitude of a weight tensor from its direction. This updates the parameters in which_params (e.g. weight ) using two parameters: one specifying the magnitude (e.g. weight_g ) and one specifying the direction (e.g. weight_v ). Arguments layer whose parameters are being reparameterized which_params : parameter names for the parameters being reparameterized By default, a norm over the entire array is computed. Pass dims to modify the dimension. Inputs x : Should be of valid type for input to layer Returns Output from layer Updated model state of layer Parameters normalized : Parameters of layer that are being normalized unnormalized : Parameters of layer that are not being normalized States Same as that of layer source Upsampling \u00a4 # Lux.Upsample \u2014 Type . Upsample ( mode = :nearest ; [ scale , size ]) Upsample ( scale , mode = :nearest ) Upsampling Layer. Layer Construction Option 1 mode : Set to :nearest , :linear , :bilinear or :trilinear Exactly one of two keywords must be specified: If scale is a number, this applies to all but the last two dimensions (channel and batch) of the input. It may also be a tuple, to control dimensions individually. Alternatively, keyword size accepts a tuple, to directly specify the leading dimensions of the output. Option 2 If scale is a number, this applies to all but the last two dimensions (channel and batch) of the input. It may also be a tuple, to control dimensions individually. mode : Set to :nearest , :bilinear or :trilinear Currently supported upsampling mode s and corresponding NNlib's methods are: :nearest -> NNlib.upsample_nearest :bilinear -> NNlib.upsample_bilinear :trilinear -> NNlib.upsample_trilinear Inputs x : For the input dimensions look into the documentation for the corresponding NNlib function As a rule of thumb, :nearest should work with arrays of arbitrary dimensions :bilinear works with 4D Arrays :trilinear works with 5D Arrays Returns Upsampled Input of size size or of size (I_1 x scale[1], ..., I_N x scale[N], C, N) Empty NamedTuple() source Index \u00a4 Lux.AdaptiveMaxPool Lux.AdaptiveMeanPool Lux.BatchNorm Lux.BranchLayer Lux.Chain Lux.Conv Lux.Dense Lux.Dropout Lux.FlattenLayer Lux.GRUCell Lux.GlobalMaxPool Lux.GlobalMeanPool Lux.GroupNorm Lux.LSTMCell Lux.LayerNorm Lux.MaxPool Lux.MeanPool Lux.NoOpLayer Lux.PairwiseFusion Lux.Parallel Lux.RNNCell Lux.ReshapeLayer Lux.Scale Lux.SelectDim Lux.SkipConnection Lux.Upsample Lux.VariationalHiddenDropout Lux.WeightNorm Lux.WrappedFunction Lux.ActivationFunction","title":"Layers"},{"location":"api/layers/#containers","text":"# Lux.BranchLayer \u2014 Type . BranchLayer ( layers ... ) BranchLayer (; layers ... ) Takes an input x and passes it through all the layers and returns a tuple of the outputs. Arguments Layers can be specified in two formats: A list of N Lux layers Specified as N keyword arguments. Inputs x : Will be directly passed to each of the layers Returns Tuple: (layer_1(x), layer_2(x), ..., layer_N(x)) (naming changes if using the kwargs API) Updated state of the layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) Comparison with Parallel This is slightly different from Parallel(nothing, layers...) If the input is a tuple, Parallel will pass each element individually to each layer. BranchLayer essentially assumes 1 input comes in and is branched out into N outputs. Example An easy way to replicate an input to an NTuple is to do l = BranchLayer ( NoOpLayer (), NoOpLayer (), NoOpLayer ()) source # Lux.Chain \u2014 Type . Chain ( layers ... ; disable_optimizations :: Bool = false ) Chain (; layers ... , disable_optimizations :: Bool = false ) Collects multiple layers / functions to be called in sequence on a given input. Arguments Layers can be specified in two formats: A list of N Lux layers Specified as N keyword arguments. Keyword Arguments disable_optimizations : Prevents any structural optimization Inputs Input x is passed sequentially to each layer, and must conform to the input requirements of the internal layers. Returns Output after sequentially applying all the layers to x Updated model states Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) Optimizations Performs a few optimizations to generate reasonable architectures. Can be disabled using keyword argument disable_optimizations . All sublayers are recursively optimized. If a function f is passed as a layer and it doesn't take 3 inputs, it is converted to a WrappedFunction ( f ) which takes only one input. If the layer is a Chain, it is flattened. NoOpLayer s are removed. If there is only 1 layer (left after optimizations), then it is returned without the Chain wrapper. If there are no layers (left after optimizations), a NoOpLayer is returned. Miscellaneous Properties Allows indexing. We can access the i th layer using m[i] . We can also index using ranges or arrays. Example c = Chain ( Dense ( 2 , 3 , relu ), BatchNorm ( 3 ), Dense ( 3 , 2 )) source # Lux.PairwiseFusion \u2014 Type . PairwiseFusion ( connection , layers ... ) PairwiseFusion ( connection ; layers ... ) x1 \u2192 layer1 \u2192 y1 \u2198 connection \u2192 layer2 \u2192 y2 \u2198 x2 \u2197 connection \u2192 y3 x3 \u2197 Arguments connection : Takes 2 inputs and combines them layers : AbstractExplicitLayer s. Layers can be specified in two formats: A list of N Lux layers Specified as N keyword arguments. Inputs Layer behaves differently based on input type: If the input x is a tuple of length N + 1 , then the layers must be a tuple of length N . The computation is as follows y = x [ 1 ] for i in 1 : N y = connection ( x [ i + 1 ], layers [ i ]( y )) end Any other kind of input y = x for i in 1 : N y = connection ( x , layers [ i ]( y )) end Returns See Inputs section for how the return value is computed Updated model state for all the contained layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) source # Lux.Parallel \u2014 Type . Parallel ( connection , layers ... ) Parallel ( connection ; layers ... ) Create a layer which passes an input to each path in layers , before reducing the output with connection . Arguments connection : An N -argument function that is called after passing the input through each layer. If connection = nothing , we return a tuple Parallel(nothing, f, g)(x, y) = (f(x), g(y)) Layers can be specified in two formats: A list of N Lux layers Specified as N keyword arguments. Inputs x : If x is not a tuple, then return is computed as connection([l(x) for l in layers]...) . Else one is passed to each layer, thus Parallel(+, f, g)(x, y) = f(x) + g(y) . Returns See the Inputs section for how the output is computed Updated state of the layers Parameters Parameters of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) States States of each layer wrapped in a NamedTuple with fields = layer_1, layer_2, ..., layer_N (naming changes if using the kwargs API) See also SkipConnection which is Parallel with one identity. source # Lux.SkipConnection \u2014 Type . SkipConnection ( layer , connection ) Create a skip connection which consists of a layer or Chain of consecutive layers and a shortcut connection linking the block's input to the output through a user-supplied 2-argument callable. The first argument to the callable will be propagated through the given layer while the second is the unchanged, \"skipped\" input. The simplest \"ResNet\"-type connection is just SkipConnection(layer, +) . Arguments layer : Layer or Chain of layers to be applied to the input connection : A 2-argument function that takes layer(input) and the input Inputs x : Will be passed directly to layer Returns Output of connection(layer(input), input) Updated state of layer Parameters Parameters of layer States States of layer See Parallel for a more general implementation. source","title":"Containers"},{"location":"api/layers/#convolutional-layers","text":"# Lux.Conv \u2014 Type . Conv ( k :: NTuple { N , Integer }, ( in_chs => out_chs ) :: Pair { <: Integer , <: Integer }, activation = identity ; init_weight = glorot_uniform , init_bias = zeros32 , stride = 1 , pad = 0 , dilation = 1 , groups = 1 , use_bias = true ) Standard convolutional layer. Image data should be stored in WHCN order (width, height, channels, batch). In other words, a 100 x 100 RGB image would be a 100 x 100 x 3 x 1 array, and a batch of 50 would be a 100 x 100 x 3 x 50 array. This has N = 2 spatial dimensions, and needs a kernel size like (5, 5) , a 2-tuple of integers. To take convolutions along N feature dimensions, this layer expects as input an array with ndims(x) == N + 2 , where size(x, N + 1) == in_chs is the number of input channels, and size(x, ndims(x)) is the number of observations in a batch. Note Frameworks like Pytorch perform cross-correlation in their convolution layers Arguments k : Tuple of integers specifying the size of the convolutional kernel. Eg, for 2D convolutions length(k) == 2 in_chs : Number of input channels out_chs : Number of input and output channels activation : Activation Function Keyword Arguments init_weight : Controls the initialization of the weight parameter init_bias : Controls the initialization of the bias parameter stride : Should each be either single integer, or a tuple with N integers dilation : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. groups : Expected to be an Int . It specifies the number of groups to divide a convolution into (set groups = in_chs for Depthwise Convolutions). in_chs and out_chs must be divisible by groups . use_bias : Trainable bias can be disabled entirely by setting this to false . allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Inputs x : Data satisfying ndims(x) == N + 2 && size(x, N - 1) == in_chs , i.e. size(x) = (I_N, ..., I_1, C_in, N) Returns Output of the convolution y of size (O_N, ..., O_1, C_out, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() Parameters weight : Convolution kernel bias : Bias (present if bias=true ) source","title":"Convolutional Layers"},{"location":"api/layers/#dropout-layers","text":"# Lux.Dropout \u2014 Type . Dropout ( p ; dims =: ) Dropout layer. Arguments p : Probability of Dropout (if p = 0 then NoOpLayer is returned) Keyword Arguments To apply dropout along certain dimension(s), specify the dims keyword. e.g. Dropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout). Inputs x : Must be an AbstractArray Returns x with dropout mask applied if training=Val(true) else just x State with updated rng States rng : Pseudo Random Number Generator training : Used to check if training/inference mode Call Lux.testmode to switch to test mode. See also VariationalHiddenDropout source # Lux.VariationalHiddenDropout \u2014 Type . VariationalHiddenDropout ( p ; dims =: ) VariationalHiddenDropout layer. The only difference from Dropout is that the mask is retained until Lux.update_state(l, :update_mask, Val(true)) is called. Arguments p : Probability of Dropout (if p = 0 then NoOpLayer is returned) Keyword Arguments To apply dropout along certain dimension(s), specify the dims keyword. e.g. VariationalHiddenDropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout). Inputs x : Must be an AbstractArray Returns x with dropout mask applied if training=Val(true) else just x State with updated rng States rng : Pseudo Random Number Generator training : Used to check if training/inference mode mask : Dropout mask. Initilly set to nothing. After every run, contains the mask applied in that call update_mask : Stores whether new mask needs to be generated in the current call Call Lux.testmode to switch to test mode. See also Dropout source","title":"Dropout Layers"},{"location":"api/layers/#pooling-layers","text":"# Lux.AdaptiveMaxPool \u2014 Type . AdaptiveMaxPool ( out :: NTuple ) Adaptive Max Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out . Arguments out : Size of the first N dimensions for the output Inputs x : Expects as input an array with ndims(x) == N+2 , i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out) . Returns Output of size (out..., C, N) Empty NamedTuple() See also MaxPool , AdaptiveMeanPool . source # Lux.AdaptiveMeanPool \u2014 Type . AdaptiveMeanPool ( out :: NTuple ) Adaptive Mean Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out . Arguments out : Size of the first N dimensions for the output Inputs x : Expects as input an array with ndims(x) == N+2 , i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out) . Returns Output of size (out..., C, N) Empty NamedTuple() See also MeanPool , AdaptiveMaxPool . source # Lux.GlobalMaxPool \u2014 Type . GlobalMaxPool () Global Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing max pooling on the complete (w,h)-shaped feature maps. Inputs x : Data satisfying ndims(x) > 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (1, ..., 1, C, N) Empty NamedTuple() See also MaxPool , AdaptiveMaxPool , GlobalMeanPool source # Lux.GlobalMeanPool \u2014 Type . GlobalMeanPool () Global Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing mean pooling on the complete (w,h)-shaped feature maps. Inputs x : Data satisfying ndims(x) > 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (1, ..., 1, C, N) Empty NamedTuple() See also MeanPool , AdaptiveMeanPool , GlobalMaxPool source # Lux.MaxPool \u2014 Type . MaxPool ( window :: NTuple ; pad = 0 , stride = window ) Max pooling layer, which replaces all pixels in a block of size window with the maximum value. Arguments window : Tuple of integers specifying the size of the window. Eg, for 2D pooling length(window) == 2 Keyword Arguments stride : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. Inputs x : Data satisfying ndims(x) == N + 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (O_N, ..., O_1, C, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() See also Conv , MeanPool , GlobalMaxPool , AdaptiveMaxPool source # Lux.MeanPool \u2014 Type . MeanPool ( window :: NTuple ; pad = 0 , stride = window ) Mean pooling layer, which replaces all pixels in a block of size window with the mean value. Arguments window : Tuple of integers specifying the size of the window. Eg, for 2D pooling length(window) == 2 Keyword Arguments stride : Should each be either single integer, or a tuple with N integers pad : Specifies the number of elements added to the borders of the data array. It can be a single integer for equal padding all around, a tuple of N integers, to apply the same padding at begin/end of each spatial dimension, a tuple of 2*N integers, for asymmetric padding, or the singleton SamePad() , to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension. Inputs x : Data satisfying ndims(x) == N + 2 , i.e. size(x) = (I_N, ..., I_1, C, N) Returns Output of the pooling y of size (O_N, ..., O_1, C, N) where \\[ O_i = floor\\left(\\frac{I_i + pad[i] + pad[(i + N) \\% length(pad)] - dilation[i] \\times (k[i] - 1)}{stride[i]} + 1\\right) \\] Empty NamedTuple() See also Conv , MaxPool , GlobalMeanPool , AdaptiveMeanPool source","title":"Pooling Layers"},{"location":"api/layers/#recurrent-layers","text":"Warning Recurrent Layers API should be considered Experimental at this point # Lux.GRUCell \u2014 Type . GRUCell (( in_dims , out_dims ) :: Pair { <: Int , <: Int }; use_bias = true , train_state :: Bool = false , init_weight :: Tuple { Function , Function , Function } = ( glorot_uniform , glorot_uniform , glorot_uniform ), init_bias :: Tuple { Function , Function , Function } = ( zeros32 , zeros32 , zeros32 ), init_state :: Function = zeros32 ) Gated Recurrent Unit (GRU) Cell \\[ \\begin{align} r &= \\sigma(W_{ir} \\times x + W_{hr} \\times h_{prev} + b_{hr})\\\\ z &= \\sigma(W_{iz} \\times x + W_{hz} \\times h_{prev} + b_{hz})\\\\ n &= \\sigma(W_{in} \\times x + b_{in} + r \\cdot (W_{hn} \\times h_{prev} + b_{hn}))\\\\ h_{new} &= (1 - z) \\cdot n + z \\cdot h_{prev} \\end{align} \\] Arguments in_dims : Input Dimension out_dims : Output (Hidden State) Dimension use_bias : Set to false to deactivate bias train_state : Trainable initial hidden state can be activated by setting this to true init_bias : Initializer for bias. Must be a tuple containing 3 functions init_weight : Initializer for weight. Must be a tuple containing 3 functions init_state : Initializer for hidden state Inputs Case 1a: Only a single input x of shape (in_dims, batch_size) , train_state is set to false - Creates a hidden state using init_state and proceeds to Case 2. Case 1b: Only a single input x of shape (in_dims, batch_size) , train_state is set to true - Repeats hidden_state from parameters to match the shape of x and proceeds to Case 2. Case 2: Tuple (x, (h, )) is provided, then the output and a tuple containing the updated hidden state is returned. Returns Tuple containing Output \\(h_{new}\\) of shape (out_dims, batch_size) Tuple containing new hidden state \\(h_{new}\\) Updated model state Parameters weight_i : Concatenated Weights to map from input space \\(\\\\left\\\\{ W_{ir}, W_{iz}, W_{in} \\\\right\\\\}\\) . weight_h : Concatenated Weights to map from hidden space \\(\\\\left\\\\{ W_{hr}, W_{hz}, W_{hn} \\\\right\\\\}\\) bias_i : Bias vector ( \\(b_{in}\\) ; not present if use_bias=false ) bias_h : Concatenated Bias vector for the hidden space \\(\\\\left\\\\{ b_{hr}, b_{hz}, b_{hn} \\\\right\\\\}\\) (not present if use_bias=false ) hidden_state : Initial hidden state vector (not present if train_state=false ) \\(\\\\left\\\\{ b_{hr}, b_{hz}, b_{hn} \\\\right\\\\}\\) States rng : Controls the randomness (if any) in the initial state generation source # Lux.LSTMCell \u2014 Type . LSTMCell ( in_dims => out_dims ; use_bias :: Bool = true , train_state :: Bool = false , train_memory :: Bool = false , init_weight = ( glorot_uniform , glorot_uniform , glorot_uniform , glorot_uniform ), init_bias = ( zeros32 , zeros32 , ones32 , zeros32 ), init_state = zeros32 , init_memory = zeros32 ) Long Short-Term (LSTM) Cell \\[ \\begin{align} i &= \\sigma(W_{ii} \\times x + W_{hi} \\times h_{prev} + b_{i})\\\\ f &= \\sigma(W_{if} \\times x + W_{hf} \\times h_{prev} + b_{f})\\\\ g &= tanh(W_{ig} \\times x + W_{hg} \\times h_{prev} + b_{g})\\\\ o &= \\sigma(W_{io} \\times x + W_{ho} \\times h_{prev} + b_{o})\\\\ c_{new} &= f \\cdot c_{prev} + i \\cdot g\\\\ h_{new} &= o \\cdot tanh(c_{new}) \\end{align} \\] Arguments in_dims : Input Dimension out_dims : Output (Hidden State & Memory) Dimension use_bias : Set to false to deactivate bias train_state : Trainable initial hidden state can be activated by setting this to true train_memory : Trainable initial memory can be activated by setting this to true init_bias : Initializer for bias. Must be a tuple containing 4 functions init_weight : Initializer for weight. Must be a tuple containing 4 functions init_state : Initializer for hidden state init_memory : Initializer for memory Inputs Case 1a: Only a single input x of shape (in_dims, batch_size) , train_state is set to false , train_memory is set to false - Creates a hidden state using init_state , hidden memory using init_memory and proceeds to Case 2. Case 1b: Only a single input x of shape (in_dims, batch_size) , train_state is set to true , train_memory is set to false - Repeats hidden_state vector from the parameters to match the shape of x , creates hidden memory using init_memory and proceeds to Case 2. Case 1c: Only a single input x of shape (in_dims, batch_size) , train_state is set to false , train_memory is set to true - Creates a hidden state using init_state , repeats the memory vector from parameters to match the shape of x and proceeds to Case 2. Case 1d: Only a single input x of shape (in_dims, batch_size) , train_state is set to true , train_memory is set to true - Repeats the hidden state and memory vectors from the parameters to match the shape of x and proceeds to Case 2. Case 2: Tuple (x, (h, c)) is provided, then the output and a tuple containing the updated hidden state and memory is returned. Returns Tuple Containing Output \\(h_{new}\\) of shape (out_dims, batch_size) Tuple containing new hidden state \\(h_{new}\\) and new memory \\(c_{new}\\) Updated model state Parameters weight_i : Concatenated Weights to map from input space \\(\\left\\{ W_{ii}, W_{if}, W_{ig}, W_{io} \\right\\}\\) . weight_h : Concatenated Weights to map from hidden space \\(\\left\\{ W_{hi}, W_{hf}, W_{hg}, W_{ho} \\right\\}\\) bias : Bias vector (not present if use_bias=false ) hidden_state : Initial hidden state vector (not present if train_state=false ) memory : Initial memory vector (not present if train_memory=false ) States rng : Controls the randomness (if any) in the initial state generation source # Lux.RNNCell \u2014 Type . RNNCell ( in_dims => out_dims , activation = tanh ; bias :: Bool = true , train_state :: Bool = false , init_bias = zeros32 , init_weight = glorot_uniform , init_state = ones32 ) An Elman RNNCell cell with activation (typically set to tanh or relu ). \\(h_{new} = activation(weight_{ih} \\times x + weight_{hh} \\times h_{prev} + bias)\\) Arguments in_dims : Input Dimension out_dims : Output (Hidden State) Dimension activation : Activation function bias : Set to false to deactivate bias train_state : Trainable initial hidden state can be activated by setting this to true init_bias : Initializer for bias init_weight : Initializer for weight init_state : Initializer for hidden state Inputs Case 1a: Only a single input x of shape (in_dims, batch_size) , train_state is set to false - Creates a hidden state using init_state and proceeds to Case 2. Case 1b: Only a single input x of shape (in_dims, batch_size) , train_state is set to true - Repeats hidden_state from parameters to match the shape of x and proceeds to Case 2. Case 2: Tuple (x, (h, )) is provided, then the output and a tuple containing the updated hidden state is returned. Returns Tuple containing Output \\(h_{new}\\) of shape (out_dims, batch_size) Tuple containing new hidden state \\(h_{new}\\) Updated model state Parameters weight_ih : Maps the input to the hidden state. weight_hh : Maps the hidden state to the hidden state. bias : Bias vector (not present if bias=false ) hidden_state : Initial hidden state vector (not present if train_state=false ) States rng : Controls the randomness (if any) in the initial state generation source","title":"Recurrent Layers"},{"location":"api/layers/#linear-layers","text":"# Lux.Dense \u2014 Type . Dense ( in_dims => out_dims , activation = identity ; init_weight = glorot_uniform , init_bias = zeros32 , bias :: Bool = true ) Create a traditional fully connected layer, whose forward pass is given by: y = activation.(weight * x .+ bias) Arguments in_dims : number of input dimensions out_dims : number of output dimensions activation : activation function Keyword Arguments init_weight : initializer for the weight matrix ( weight = init_weight(rng, out_dims, in_dims) ) init_bias : initializer for the bias vector (ignored if use_bias=false ) use_bias : Trainable bias can be disabled entirely by setting this to false allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Input x must be an AbstractArray with size(x, 1) == in_dims Returns AbstractArray with dimensions (out_dims, ...) where ... are the dimensions of x Empty NamedTuple() Parameters weight : Weight Matrix of size (out_dims, in_dims) bias : Bias of size (out_dims, 1) (present if use_bias=true ) source # Lux.Scale \u2014 Type . Scale ( dims , activation = identity ; init_weight = ones32 , init_bias = zeros32 , bias :: Bool = true ) Create a Sparsely Connected Layer with a very specific structure (only Diagonal Elements are non-zero). The forward pass is given by: y = activation.(weight .* x .+ bias) Arguments dims : size of the learnable scale and bias parameters. activation : activation function Keyword Arguments init_weight : initializer for the weight matrix ( weight = init_weight(rng, out_dims, in_dims) ) init_bias : initializer for the bias vector (ignored if use_bias=false ) use_bias : Trainable bias can be disabled entirely by setting this to false allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Input x must be an Array of size (dims..., B) or (dims...[0], ..., dims[k]) for k \u2264 size(dims) Returns Array of size (dims..., B) or (dims...[0], ..., dims[k]) for k \u2264 size(dims) Empty NamedTuple() Parameters weight : Weight Array of size (dims...) bias : Bias of size (dims...) Lux 0.4.3 Scale with multiple dimensions requires at least Lux 0.4.3. source","title":"Linear Layers"},{"location":"api/layers/#misc-helper-layers","text":"# Lux.ActivationFunction \u2014 Function . ActivationFunction ( f ) Broadcast f on the input. Arguments f : Activation function Inputs x : Any array type s.t. f can be broadcasted over it Returns Broadcasted Activation f.(x) Empty NamedTuple() Warning This layer is deprecated and will be removed in v0.5. Use WrappedFunction with manual broadcasting source # Lux.FlattenLayer \u2014 Type . FlattenLayer () Flattens the passed array into a matrix. Inputs x : AbstractArray Returns AbstractMatrix of size (:, size(x, ndims(x))) Empty NamedTuple() source # Lux.NoOpLayer \u2014 Type . NoOpLayer () As the name suggests does nothing but allows pretty printing of layers. Whatever input is passed is returned. source # Lux.ReshapeLayer \u2014 Type . ReshapeLayer ( dims ) Reshapes the passed array to have a size of (dims..., :) Arguments dims : The new dimensions of the array (excluding the last dimension). Inputs x : AbstractArray of any shape which can be reshaped in (dims..., size(x, ndims(x))) Returns AbstractArray of size (dims..., size(x, ndims(x))) Empty NamedTuple() source # Lux.SelectDim \u2014 Type . SelectDim ( dim , i ) Return a view of all the data of the input x where the index for dimension dim equals i . Equivalent to view(x,:,:,...,i,:,:,...) where i is in position d . Arguments dim : Dimension for indexing i : Index for dimension dim Inputs x : AbstractArray that can be indexed with view(x,:,:,...,i,:,:,...) Returns view(x,:,:,...,i,:,:,...) where i is in position d Empty NamedTuple() source # Lux.WrappedFunction \u2014 Type . WrappedFunction ( f ) Wraps a stateless and parameter less function. Might be used when a function is added to Chain . For example, Chain(x -> relu.(x)) would not work and the right thing to do would be Chain((x, ps, st) -> (relu.(x), st)) . An easier thing to do would be Chain(WrappedFunction(Base.Fix1(broadcast, relu))) Arguments f::Function : A stateless and parameterless function Inputs x : s.t hasmethod(f, (typeof(x),)) is true Returns Output of f(x) Empty NamedTuple() source","title":"Misc. Helper Layers"},{"location":"api/layers/#normalization-layers","text":"# Lux.BatchNorm \u2014 Type . BatchNorm ( chs :: Integer , activation = identity ; init_bias = zeros32 , init_scale = ones32 , affine = true , track_stats = true , epsilon = 1f-5 , momentum = 0.1f0 ) Batch Normalization layer. BatchNorm computes the mean and variance for each D_1 \u00d7 ... \u00d7 D_{N-2} \u00d7 1 \u00d7 D_N input slice and normalises the input accordingly. Arguments chs : Size of the channel dimension in your data. Given an array with N dimensions, call the N-1 th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension. activation : After normalization, elementwise activation activation is applied. Keyword Arguments If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed If track_stats=true , accumulates mean and variance statistics in training phase that will be used to renormalize the input in test phase. epsilon : a value added to the denominator for numerical stability momentum : the value used for the running_mean and running_var computation allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Inputs x : Array where size(x, N - 1) = chs and ndims(x) > 2 Returns y : Normalized Array Update model state Parameters affine=true bias : Bias of shape (chs,) scale : Scale of shape (chs,) affine=false - Empty NamedTuple() States Statistics if track_stats=true running_mean : Running mean of shape (chs,) running_var : Running variance of shape (chs,) Statistics if track_stats=false running_mean : nothing running_var : nothing training : Used to check if training/inference mode Use Lux.testmode during inference. Example m = Chain ( Dense ( 784 => 64 ), BatchNorm ( 64 , relu ), Dense ( 64 => 10 ), BatchNorm ( 10 )) Warning Passing a batch size of 1, during training will result in NaNs. See also GroupNorm source # Lux.GroupNorm \u2014 Type . GroupNorm ( chs :: Integer , groups :: Integer , activation = identity ; init_bias = zeros32 , init_scale = ones32 , affine = true , track_stats = true , epsilon = 1f-5 , momentum = 0.1f0 ) Group Normalization layer. Arguments chs : Size of the channel dimension in your data. Given an array with N dimensions, call the N-1 th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension. groups is the number of groups along which the statistics are computed. The number of channels must be an integer multiple of the number of groups. activation : After normalization, elementwise activation activation is applied. Keyword Arguments If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed If track_stats=true , accumulates mean and variance statistics in training phase that will be used to renormalize the input in test phase. (This feature has been deprecated and will be removed in v0.5) epsilon : a value added to the denominator for numerical stability momentum : the value used for the running_mean and running_var computation (This feature has been deprecated and will be removed in v0.5) allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Inputs x : Array where size(x, N - 1) = chs and ndims(x) > 2 Returns y : Normalized Array Update model state Parameters affine=true bias : Bias of shape (chs,) scale : Scale of shape (chs,) affine=false - Empty NamedTuple() States Statistics if track_stats=true (DEPRECATED) running_mean : Running mean of shape (groups,) running_var : Running variance of shape (groups,) Statistics if track_stats=false running_mean : nothing running_var : nothing training : Used to check if training/inference mode Use Lux.testmode during inference. Example m = Chain ( Dense ( 784 => 64 ), GroupNorm ( 64 , 4 , relu ), Dense ( 64 => 10 ), GroupNorm ( 10 , 5 )) Warning GroupNorm doesn't have CUDNN support. The GPU fallback is not very efficient. See also BatchNorm source # Lux.LayerNorm \u2014 Type . LayerNorm ( shape :: NTuple { N , Int }, activation = identity ; epsilon = 1f-5 , dims = Colon (), affine :: Bool = false , init_bias = zeros32 , init_scale = ones32 ,) Computes mean and standard deviation over the whole input array, and uses these to normalize the whole array. Optionally applies an elementwise affine transformation afterwards. Given an input array \\(x\\) , this layer computes \\[ y = \\frac{x - \\mathbb{E}[x]}{\\sqrt{Var[x] + \\epsilon}} * \\gamma + \\beta \\] where \\(\\gamma\\) & \\(\\beta\\) are trainable parameters if affine=true . Arguments shape : Broadcastable shape of input array excluding the batch dimension. activation : After normalization, elementwise activation activation is applied. Keyword Arguments epsilon : a value added to the denominator for numerical stability. dims : Dimensions to normalize the array over. If affine=true , it also applies a shift and a rescale to the input through to learnable per-channel bias and scale parameters. init_bias : Controls how the bias is initiliazed init_scale : Controls how the scale is initiliazed allow_fast_activation : If true , then certain activations can be approximated with a faster version. The new activation function will be given by NNlib.fast_act(activation) Inputs x : AbstractArray Returns y : Normalized Array Empty NamedTuple() Parameters affine=false : Empty NamedTuple() affine=true bias : Bias of shape (shape..., 1) scale : Scale of shape (shape..., 1) source # Lux.WeightNorm \u2014 Type . WeightNorm ( layer :: AbstractExplicitLayer , which_params :: NTuple { N , Symbol }, dims :: Union { Tuple , Nothing } = nothing ) Applies weight normalization to a parameter in the given layer. \\(w = g\\frac{v}{\\|v\\|}\\) Weight normalization is a reparameterization that decouples the magnitude of a weight tensor from its direction. This updates the parameters in which_params (e.g. weight ) using two parameters: one specifying the magnitude (e.g. weight_g ) and one specifying the direction (e.g. weight_v ). Arguments layer whose parameters are being reparameterized which_params : parameter names for the parameters being reparameterized By default, a norm over the entire array is computed. Pass dims to modify the dimension. Inputs x : Should be of valid type for input to layer Returns Output from layer Updated model state of layer Parameters normalized : Parameters of layer that are being normalized unnormalized : Parameters of layer that are not being normalized States Same as that of layer source","title":"Normalization Layers"},{"location":"api/layers/#upsampling","text":"# Lux.Upsample \u2014 Type . Upsample ( mode = :nearest ; [ scale , size ]) Upsample ( scale , mode = :nearest ) Upsampling Layer. Layer Construction Option 1 mode : Set to :nearest , :linear , :bilinear or :trilinear Exactly one of two keywords must be specified: If scale is a number, this applies to all but the last two dimensions (channel and batch) of the input. It may also be a tuple, to control dimensions individually. Alternatively, keyword size accepts a tuple, to directly specify the leading dimensions of the output. Option 2 If scale is a number, this applies to all but the last two dimensions (channel and batch) of the input. It may also be a tuple, to control dimensions individually. mode : Set to :nearest , :bilinear or :trilinear Currently supported upsampling mode s and corresponding NNlib's methods are: :nearest -> NNlib.upsample_nearest :bilinear -> NNlib.upsample_bilinear :trilinear -> NNlib.upsample_trilinear Inputs x : For the input dimensions look into the documentation for the corresponding NNlib function As a rule of thumb, :nearest should work with arrays of arbitrary dimensions :bilinear works with 4D Arrays :trilinear works with 5D Arrays Returns Upsampled Input of size size or of size (I_1 x scale[1], ..., I_N x scale[N], C, N) Empty NamedTuple() source","title":"Upsampling"},{"location":"api/layers/#index","text":"Lux.AdaptiveMaxPool Lux.AdaptiveMeanPool Lux.BatchNorm Lux.BranchLayer Lux.Chain Lux.Conv Lux.Dense Lux.Dropout Lux.FlattenLayer Lux.GRUCell Lux.GlobalMaxPool Lux.GlobalMeanPool Lux.GroupNorm Lux.LSTMCell Lux.LayerNorm Lux.MaxPool Lux.MeanPool Lux.NoOpLayer Lux.PairwiseFusion Lux.Parallel Lux.RNNCell Lux.ReshapeLayer Lux.Scale Lux.SelectDim Lux.SkipConnection Lux.Upsample Lux.VariationalHiddenDropout Lux.WeightNorm Lux.WrappedFunction Lux.ActivationFunction","title":"Index"},{"location":"api/utilities/","text":"Data Transfer \u00a4 # Lux.cpu \u2014 Function . cpu ( x ) Transfer x to CPU source # Lux.gpu \u2014 Function . gpu ( x ) Transfer x to GPU source Initialization \u00a4 # Lux.glorot_normal \u2014 Function . glorot_normal ( rng :: AbstractRNG , size ... ; gain = 1 ) Return an Array{Float32} of the given size containing random numbers drawn from a normal distribution with standard deviation gain * sqrt(2 / (fan_in + fan_out)) . This method is described in [1] and also known as Xavier initialization. References [1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics . 2010. source # Lux.glorot_uniform \u2014 Function . glorot_uniform ( rng :: AbstractRNG , size ... ; gain = 1 ) Return an Array{Float32} of the given size containing random numbers drawn from a uniform distribution on the interval \\([-x, x]\\) , where x = gain * sqrt(6 / (fan_in + fan_out)) . This method is described in [1] and also known as Xavier initialization. References [1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics . 2010. source # Lux.ones32 \u2014 Function . ones32 ( rng :: AbstractRNG , size ... ) = ones ( Float32 , size ... ) Return an Array{Float32} of ones of the given size . ( rng is ignored) source # Lux.zeros32 \u2014 Function . zeros32 ( rng :: AbstractRNG , size ... ) = zeros ( Float32 , size ... ) Return an Array{Float32} of zeros of the given size . ( rng is ignored) source Miscellaneous Utilities \u00a4 # Lux.applyactivation \u2014 Function . applyactivation ( f :: Function , x :: AbstractArray ) Apply the function f on x elementwise, i.e. f.(x) . Dispatches to CUDNN if possible. Warning This function has been deprecated. Use f.(x) instead. source # Lux.elementwise_add \u2014 Function . elementwise_add ( x , y ) Computes x .+ y . Dispatches to CUDNN if possible. Warning This function has been deprecated. Use x .+ y instead. source # Lux.elementwise_mul \u2014 Function . elementwise_mul ( x , y ) Computes x .* y . Dispatches to CUDNN if possible. Warning This function has been deprecated. Use x .* y instead. source # Lux.istraining \u2014 Function . istraining ( :: Val { training }) istraining ( st :: NamedTuple ) Returns true if training is true or if st contains a training field with value true . Else returns false . Method undefined if st.training is not of type Val . source # Lux.multigate \u2014 Function . multigate ( x :: AbstractArray , :: Val { N }) Split up x into N equally sized chunks (along dimension 1 ). source # Lux.replicate \u2014 Function . replicate ( rng :: AbstractRNG ) replicate ( rng :: CUDA . RNG ) Creates a copy of the rng state depending on its type. source Index \u00a4 Lux.applyactivation Lux.cpu Lux.elementwise_add Lux.elementwise_mul Lux.glorot_normal Lux.glorot_uniform Lux.gpu Lux.istraining Lux.multigate Lux.ones32 Lux.replicate Lux.zeros32","title":"Utilities"},{"location":"api/utilities/#data-transfer","text":"# Lux.cpu \u2014 Function . cpu ( x ) Transfer x to CPU source # Lux.gpu \u2014 Function . gpu ( x ) Transfer x to GPU source","title":"Data Transfer"},{"location":"api/utilities/#initialization","text":"# Lux.glorot_normal \u2014 Function . glorot_normal ( rng :: AbstractRNG , size ... ; gain = 1 ) Return an Array{Float32} of the given size containing random numbers drawn from a normal distribution with standard deviation gain * sqrt(2 / (fan_in + fan_out)) . This method is described in [1] and also known as Xavier initialization. References [1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics . 2010. source # Lux.glorot_uniform \u2014 Function . glorot_uniform ( rng :: AbstractRNG , size ... ; gain = 1 ) Return an Array{Float32} of the given size containing random numbers drawn from a uniform distribution on the interval \\([-x, x]\\) , where x = gain * sqrt(6 / (fan_in + fan_out)) . This method is described in [1] and also known as Xavier initialization. References [1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics . 2010. source # Lux.ones32 \u2014 Function . ones32 ( rng :: AbstractRNG , size ... ) = ones ( Float32 , size ... ) Return an Array{Float32} of ones of the given size . ( rng is ignored) source # Lux.zeros32 \u2014 Function . zeros32 ( rng :: AbstractRNG , size ... ) = zeros ( Float32 , size ... ) Return an Array{Float32} of zeros of the given size . ( rng is ignored) source","title":"Initialization"},{"location":"api/utilities/#miscellaneous-utilities","text":"# Lux.applyactivation \u2014 Function . applyactivation ( f :: Function , x :: AbstractArray ) Apply the function f on x elementwise, i.e. f.(x) . Dispatches to CUDNN if possible. Warning This function has been deprecated. Use f.(x) instead. source # Lux.elementwise_add \u2014 Function . elementwise_add ( x , y ) Computes x .+ y . Dispatches to CUDNN if possible. Warning This function has been deprecated. Use x .+ y instead. source # Lux.elementwise_mul \u2014 Function . elementwise_mul ( x , y ) Computes x .* y . Dispatches to CUDNN if possible. Warning This function has been deprecated. Use x .* y instead. source # Lux.istraining \u2014 Function . istraining ( :: Val { training }) istraining ( st :: NamedTuple ) Returns true if training is true or if st contains a training field with value true . Else returns false . Method undefined if st.training is not of type Val . source # Lux.multigate \u2014 Function . multigate ( x :: AbstractArray , :: Val { N }) Split up x into N equally sized chunks (along dimension 1 ). source # Lux.replicate \u2014 Function . replicate ( rng :: AbstractRNG ) replicate ( rng :: CUDA . RNG ) Creates a copy of the rng state depending on its type. source","title":"Miscellaneous Utilities"},{"location":"api/utilities/#index","text":"Lux.applyactivation Lux.cpu Lux.elementwise_add Lux.elementwise_mul Lux.glorot_normal Lux.glorot_uniform Lux.gpu Lux.istraining Lux.multigate Lux.ones32 Lux.replicate Lux.zeros32","title":"Index"},{"location":"devdocs/layer_implementation/","text":"Layer Implementation \u00a4 Recurrent Neural Networks \u00a4 Cell Implementations \u00a4 Explicit Management on End-User Side \u00a4 Note We currently use this implementation User is responsible for managing the memory and hidden states. Pros \u00a4 Simple Design and Implementation. Hard for the User to mess up, i.e. there is no explicit requirement to call things like Flux.reset! . In the first call user passes the input . In the subsequent calls, the user passes a tuple containing the input , hidden_state and memory (if needed). Cons \u00a4 Requires more explicit management from the user which might make it harder to use. Currently the call order convention is not enforced which could lead to sneaky errors. (Implementing a check is quite trivial if we store a call counter in the model state ). Store Hidden State and Memory in Model State \u00a4 Storing the memory and hidden state in st would allow user to just pass x without varying how calls are made at different timesteps. Pros \u00a4 Easier for the end-user. Cons \u00a4 reset ing the hidden-state and memory is slightly tricky. One way would be to store a initial_hidden_state and initial_memory in the state alongside the hidden_state and memory . RNN Blocks \u00a4 Note This is currently unimplemented An example implementation would be struct RNN { R } <: Lux . AbstractExplicitContainerLayer {( :recurrent_cell ,)} recurrent_cell :: R end function ( l :: RNN )( x :: AbstractArray { T , 3 }, ps :: NamedTuple , st :: NamedTuple ) where { T } x_init , x_rest = Iterators . peel ( eachslice ( x ; dims = 2 )) ( y , carry ), st = l . recurrent_cell ( x_init , ps , st ) for x in x_rest ( y , carry ), st = l . recurrent_cell (( x , carry ), ps , st ) end return y , st end We enforce the inputs to be of the format in_dims \u00d7 sequence_length \u00d7 batch_size .","title":"Layer Implementation"},{"location":"devdocs/layer_implementation/#layer-implementation","text":"","title":"Layer Implementation"},{"location":"devdocs/layer_implementation/#recurrent-neural-networks","text":"","title":"Recurrent Neural Networks"},{"location":"devdocs/layer_implementation/#cell-implementations","text":"","title":"Cell Implementations"},{"location":"devdocs/layer_implementation/#explicit-management-on-end-user-side","text":"Note We currently use this implementation User is responsible for managing the memory and hidden states.","title":"Explicit Management on End-User Side"},{"location":"devdocs/layer_implementation/#store-hidden-state-and-memory-in-model-state","text":"Storing the memory and hidden state in st would allow user to just pass x without varying how calls are made at different timesteps.","title":"Store Hidden State and Memory in Model State"},{"location":"devdocs/layer_implementation/#rnn-blocks","text":"Note This is currently unimplemented An example implementation would be struct RNN { R } <: Lux . AbstractExplicitContainerLayer {( :recurrent_cell ,)} recurrent_cell :: R end function ( l :: RNN )( x :: AbstractArray { T , 3 }, ps :: NamedTuple , st :: NamedTuple ) where { T } x_init , x_rest = Iterators . peel ( eachslice ( x ; dims = 2 )) ( y , carry ), st = l . recurrent_cell ( x_init , ps , st ) for x in x_rest ( y , carry ), st = l . recurrent_cell (( x , carry ), ps , st ) end return y , st end We enforce the inputs to be of the format in_dims \u00d7 sequence_length \u00d7 batch_size .","title":"RNN Blocks"},{"location":"devdocs/style_guide/","text":"Style Guide \u00a4 We strictly enforce a style guide across the repository. For the most part we rely on SciMLStyle . However, any additional guideline mentioned in this document takes precedence. How to auto-format your code? Firstly, install JuliaFormatter by running julia -e 'using Pkg; Pkg.add(PackageSpec(name=\"JuliaFormatter\"))' . Next, from the root directory of the project, simply run julia -e 'using JuliaFormatter; format(\".\")' . We do have automatic formatter, which opens PR after fixing common style issues, however, we strictly don't merge PRs without a green style check. Note If you find any existing code which doesn't adhere to these guidelines, open an issue so that we can fix that. Code Styling \u00a4 Keyword Arguments must be separated using a semicolon ; Functions must use return . Returning the last value is quite ambiguous \u2013 did the author actually want it returned? Format docstrings as you would format regular code. If the docstring constains LaTeX in multiple lines, use math block. No avoiding multiply symbol \u2013 so 2x is invalid instead do it like other languages 2 * x . Unicode Characters \u00a4 No use of unicode characters is allowed. The only exception is when defining DSLs. In this particular case, how to type the unicode must be properly documented. Testing \u00a4 Note Unfortunately we haven't yet tested all the functionality in the base library using these guidelines. The file structure of the test folder should mirror that of the src folder. Every file in src should have a complementary file in the test folder, containing tests relevant to that file's contents. Add generic utilities for testing in test/test_utils.jl and include them in the relevant files. Use JET.jl to test for dynamic dispatch in the functionality you added, specifically use run_JET_tests from test/test_utils.jl . Always test for gradient correctness. Zygote can be notorious for incorrect gradients, so add tests using test_gradient_correctness_fdm for finite differencing or use any other AD framework and tally the results. Try adding to backend packages \u00a4 Lux is mostly a frontend for defining Neural Networks. As such, if an optimization needs to be applied to lets say NNlib.jl , it is better to open a PR there since all frameworks using NNlib.jl get to benefit from these fixes. Similarly, if a bug comes to the forefront from one of the backend packages, make sure to open a corresponding issue there to ensure they are appropriately tracked. Mutability \u00a4 This is strictly enforced, i.e. all layers/functions provided as part of the external API must be pure functions, even if they come with a performance penalty. Branching \u2013 Generated Functions \u00a4 Zygote doesn't like branches in code. Like it or not, we are stuck with it for the near future. Even if julia is able to optimize branches away, Zygote will most certainly throw away those optimizations (these can be tested via Zygote.@code_ir ). Writing efficient non-branching code to make Zygote happy \u00a4 Rely on @generated functions to remove most runtime branching. Certain examples: Layers behaving differently during training and inference \u2013 we know at compile-time whether a layer is being run in training/inference mode via istraining(st) . Composite Layers relying on a variable number of internal layers \u2013 Again we know the length of the number of internal layers at compile time. Hence we can manually unroll the loops. See Parallel , Chain , etc. Pass around Val in state. Flux.jl sets training to be (:auto, true, false) . Hence, which branch will be evaluated, will have to be determined at runtime time ( bad ). Instead if we pass Val(true) , we will be able to specialize functions directly based on true , false , etc. ensuring there is no runtime cost for these operations. See BatchNorm , Dropout , etc. Deprecation \u00a4 Deprecations should be handled according to SemVer recommendations, i.e. there should be atleast one version where we throw a deprecation warning. This ensures users know how to modify their code for upcoming releases. This blog details the process of deprecating functionalities in Julia packages. We follow the same process. Some additional guidelines are: Add tests using Test.@test_deprecated to ensure that deprecations are indeed working as expected. Add a warning to the documentation about deprecations (and how to use the new recommended functionality). Add # Deprecated Functionality (Remove in <VERSION NUMBER>) before the tests and deprecated functionality not placed in src/deprecated.jl (like kwarg deprecations). This makes it easier to search and delete the functionalities before making a breaking release. Documentation \u00a4 We use Documenter.jl + mkdocs for our documentation. Adding Tutorials \u00a4 Add tutorials must be added to the examples directory. Then add an entry for the path and tutorial name in docs/make.jl . Finally, update the navigation nav in docs/mkdocs.yml Documentation for Layers \u00a4 The first line must be indented by 4 spaces and should contain the possible ways to construct the layer. This should be followed up with a description about what the layer does. If mathematical equations are needed to explain what the layer does, go for it. Often times we fuse parameters to make computation faster, this should be reflected in the equations being used, i.e. equations and the internal code must be consistent. (See LSTMCell , GRUCell for some examples.) Note There is no need to document how the layers are being called since they must adhere to layer(x, ps, st) . Any deviation from that and the PR will not be accepted. Next, we will have certain subsections (though all of them might not be necessary for all layers). Arguments : This section should be present unless the layer is constructed without any arguments (See NoOpLayer ). All the arguments and their explicit constraints must be explained. It is recommended to separate out the Keyword Arguments in their own section. Inputs : This section should always be present. List out the requirements x needs to satisfy. (Don't write about ps and st since that is expected by default.) Returns : What will the layer return? We know the second element will be a state but is that updated in any form or not? Parameters : What are the properties of the NamedTuple returned from initialparameters ? Omit if the layer is parameterless. States : What are the properties of the NamedTuple returned from initialstates ? Omit if the layer is stateless.","title":"Style Guide"},{"location":"devdocs/style_guide/#style-guide","text":"We strictly enforce a style guide across the repository. For the most part we rely on SciMLStyle . However, any additional guideline mentioned in this document takes precedence. How to auto-format your code? Firstly, install JuliaFormatter by running julia -e 'using Pkg; Pkg.add(PackageSpec(name=\"JuliaFormatter\"))' . Next, from the root directory of the project, simply run julia -e 'using JuliaFormatter; format(\".\")' . We do have automatic formatter, which opens PR after fixing common style issues, however, we strictly don't merge PRs without a green style check. Note If you find any existing code which doesn't adhere to these guidelines, open an issue so that we can fix that.","title":"Style Guide"},{"location":"devdocs/style_guide/#code-styling","text":"Keyword Arguments must be separated using a semicolon ; Functions must use return . Returning the last value is quite ambiguous \u2013 did the author actually want it returned? Format docstrings as you would format regular code. If the docstring constains LaTeX in multiple lines, use math block. No avoiding multiply symbol \u2013 so 2x is invalid instead do it like other languages 2 * x .","title":"Code Styling"},{"location":"devdocs/style_guide/#unicode-characters","text":"No use of unicode characters is allowed. The only exception is when defining DSLs. In this particular case, how to type the unicode must be properly documented.","title":"Unicode Characters"},{"location":"devdocs/style_guide/#testing","text":"Note Unfortunately we haven't yet tested all the functionality in the base library using these guidelines. The file structure of the test folder should mirror that of the src folder. Every file in src should have a complementary file in the test folder, containing tests relevant to that file's contents. Add generic utilities for testing in test/test_utils.jl and include them in the relevant files. Use JET.jl to test for dynamic dispatch in the functionality you added, specifically use run_JET_tests from test/test_utils.jl . Always test for gradient correctness. Zygote can be notorious for incorrect gradients, so add tests using test_gradient_correctness_fdm for finite differencing or use any other AD framework and tally the results.","title":"Testing"},{"location":"devdocs/style_guide/#try-adding-to-backend-packages","text":"Lux is mostly a frontend for defining Neural Networks. As such, if an optimization needs to be applied to lets say NNlib.jl , it is better to open a PR there since all frameworks using NNlib.jl get to benefit from these fixes. Similarly, if a bug comes to the forefront from one of the backend packages, make sure to open a corresponding issue there to ensure they are appropriately tracked.","title":"Try adding to backend packages"},{"location":"devdocs/style_guide/#mutability","text":"This is strictly enforced, i.e. all layers/functions provided as part of the external API must be pure functions, even if they come with a performance penalty.","title":"Mutability"},{"location":"devdocs/style_guide/#branching-generated-functions","text":"Zygote doesn't like branches in code. Like it or not, we are stuck with it for the near future. Even if julia is able to optimize branches away, Zygote will most certainly throw away those optimizations (these can be tested via Zygote.@code_ir ).","title":"Branching \u2013 Generated Functions"},{"location":"devdocs/style_guide/#writing-efficient-non-branching-code-to-make-zygote-happy","text":"Rely on @generated functions to remove most runtime branching. Certain examples: Layers behaving differently during training and inference \u2013 we know at compile-time whether a layer is being run in training/inference mode via istraining(st) . Composite Layers relying on a variable number of internal layers \u2013 Again we know the length of the number of internal layers at compile time. Hence we can manually unroll the loops. See Parallel , Chain , etc. Pass around Val in state. Flux.jl sets training to be (:auto, true, false) . Hence, which branch will be evaluated, will have to be determined at runtime time ( bad ). Instead if we pass Val(true) , we will be able to specialize functions directly based on true , false , etc. ensuring there is no runtime cost for these operations. See BatchNorm , Dropout , etc.","title":"Writing efficient non-branching code to make Zygote happy"},{"location":"devdocs/style_guide/#deprecation","text":"Deprecations should be handled according to SemVer recommendations, i.e. there should be atleast one version where we throw a deprecation warning. This ensures users know how to modify their code for upcoming releases. This blog details the process of deprecating functionalities in Julia packages. We follow the same process. Some additional guidelines are: Add tests using Test.@test_deprecated to ensure that deprecations are indeed working as expected. Add a warning to the documentation about deprecations (and how to use the new recommended functionality). Add # Deprecated Functionality (Remove in <VERSION NUMBER>) before the tests and deprecated functionality not placed in src/deprecated.jl (like kwarg deprecations). This makes it easier to search and delete the functionalities before making a breaking release.","title":"Deprecation"},{"location":"devdocs/style_guide/#documentation","text":"We use Documenter.jl + mkdocs for our documentation.","title":"Documentation"},{"location":"devdocs/style_guide/#adding-tutorials","text":"Add tutorials must be added to the examples directory. Then add an entry for the path and tutorial name in docs/make.jl . Finally, update the navigation nav in docs/mkdocs.yml","title":"Adding Tutorials"},{"location":"devdocs/style_guide/#documentation-for-layers","text":"The first line must be indented by 4 spaces and should contain the possible ways to construct the layer. This should be followed up with a description about what the layer does. If mathematical equations are needed to explain what the layer does, go for it. Often times we fuse parameters to make computation faster, this should be reflected in the equations being used, i.e. equations and the internal code must be consistent. (See LSTMCell , GRUCell for some examples.) Note There is no need to document how the layers are being called since they must adhere to layer(x, ps, st) . Any deviation from that and the PR will not be accepted. Next, we will have certain subsections (though all of them might not be necessary for all layers). Arguments : This section should be present unless the layer is constructed without any arguments (See NoOpLayer ). All the arguments and their explicit constraints must be explained. It is recommended to separate out the Keyword Arguments in their own section. Inputs : This section should always be present. List out the requirements x needs to satisfy. (Don't write about ps and st since that is expected by default.) Returns : What will the layer return? We know the second element will be a state but is that updated in any form or not? Parameters : What are the properties of the NamedTuple returned from initialparameters ? Omit if the layer is parameterless. States : What are the properties of the NamedTuple returned from initialstates ? Omit if the layer is stateless.","title":"Documentation for Layers"},{"location":"examples/examples/","text":"Tutorials & Examples using Lux \u00a4 Tutorials \u00a4 Julia & Lux for the Uninitiated Fitting a Simple Polynomial Training a Simple LSTM MNIST Classification using NeuralODE Bayesian Neural Network Scipts \u00a4 ImageNet Classification Packages \u00a4 See Ecosystem for more details.","title":"Home"},{"location":"examples/examples/#tutorials-examples-using-lux","text":"","title":"Tutorials &amp; Examples using Lux"},{"location":"examples/examples/#tutorials","text":"Julia & Lux for the Uninitiated Fitting a Simple Polynomial Training a Simple LSTM MNIST Classification using NeuralODE Bayesian Neural Network","title":"Tutorials"},{"location":"examples/examples/#scipts","text":"ImageNet Classification","title":"Scipts"},{"location":"examples/examples/#packages","text":"See Ecosystem for more details.","title":"Packages"},{"location":"examples/generated/beginner/Basics/main/","text":"Julia & Lux for the Uninitiated \u00a4 This is a quick intro to Lux loosely based on: PyTorch's tutorial . Flux's tutorial . Flax's tutorial . It introduces basic Julia programming, as well Zygote , a source-to-source automatic differentiation (AD) framework in Julia. We'll use these tools to build a very simple neural network. Let's start with importing Lux.jl using Lux , Random Activating project at `~/work/Lux.jl/Lux.jl/examples` Now let us control the randomness in our code using proper Pseudo Random Number Generator (PRNG) rng = Random . default_rng () Random . seed! ( rng , 0 ) Random.TaskLocalRNG() Arrays \u00a4 The starting point for all of our models is the Array (sometimes referred to as a Tensor in other frameworks). This is really just a list of numbers, which might be arranged into a shape like a square. Let's write down an array with three elements. x = [ 1 , 2 , 3 ] 3-element Vector{Int64}: 1 2 3 Here's a matrix \u2013 a square array with four elements. x = [ 1 2 ; 3 4 ] 2\u00d72 Matrix{Int64}: 1 2 3 4 We often work with arrays of thousands of elements, and don't usually write them down by hand. Here's how we can create an array of 5\u00d73 = 15 elements, each a random number from zero to one. x = rand ( rng , 5 , 3 ) 5\u00d73 Matrix{Float64}: 0.455238 0.746943 0.193291 0.547642 0.746801 0.116989 0.773354 0.97667 0.899766 0.940585 0.0869468 0.422918 0.0296477 0.351491 0.707534 There's a few functions like this; try replacing rand with ones , zeros , or randn . By default, Julia works stores numbers is a high-precision format called Float64 . In ML we often don't need all those digits, and can ask Julia to work with Float32 instead. We can even ask for more digits using BigFloat . x = rand ( BigFloat , 5 , 3 ) 5\u00d73 Matrix{BigFloat}: 0.981339 0.793159 0.459019 0.043883 0.624384 0.56055 0.164786 0.524008 0.0355555 0.414769 0.577181 0.621958 0.00823197 0.30215 0.655881 x = rand ( Float32 , 5 , 3 ) 5\u00d73 Matrix{Float32}: 0.567794 0.369178 0.342539 0.0985227 0.201145 0.587206 0.776598 0.148248 0.0851708 0.723731 0.0770206 0.839303 0.404728 0.230954 0.679087 We can ask the array how many elements it has. length ( x ) 15 Or, more specifically, what size it has. size ( x ) (5, 3) We sometimes want to see some elements of the array on their own. x 5\u00d73 Matrix{Float32}: 0.567794 0.369178 0.342539 0.0985227 0.201145 0.587206 0.776598 0.148248 0.0851708 0.723731 0.0770206 0.839303 0.404728 0.230954 0.679087 x [ 2 , 3 ] 0.58720636f0 This means get the second row and the third column. We can also get every row of the third column. x [ : , 3 ] 5-element Vector{Float32}: 0.34253937 0.58720636 0.085170805 0.8393034 0.67908657 We can add arrays, and subtract them, which adds or subtracts each element of the array. x + x 5\u00d73 Matrix{Float32}: 1.13559 0.738356 0.685079 0.197045 0.40229 1.17441 1.5532 0.296496 0.170342 1.44746 0.154041 1.67861 0.809456 0.461908 1.35817 x - x 5\u00d73 Matrix{Float32}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 Julia supports a feature called broadcasting , using the . syntax. This tiles small arrays (or single numbers) to fill bigger ones. x .+ 1 5\u00d73 Matrix{Float32}: 1.56779 1.36918 1.34254 1.09852 1.20114 1.58721 1.7766 1.14825 1.08517 1.72373 1.07702 1.8393 1.40473 1.23095 1.67909 We can see Julia tile the column vector 1:5 across all rows of the larger array. zeros ( 5 , 5 ) .+ ( 1 : 5 ) 5\u00d75 Matrix{Float64}: 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 4.0 4.0 5.0 5.0 5.0 5.0 5.0 The x' syntax is used to transpose a column 1:5 into an equivalent row, and Julia will tile that across columns. zeros ( 5 , 5 ) .+ ( 1 : 5 ) ' 5\u00d75 Matrix{Float64}: 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 We can use this to make a times table. ( 1 : 5 ) .* ( 1 : 5 ) ' 5\u00d75 Matrix{Int64}: 1 2 3 4 5 2 4 6 8 10 3 6 9 12 15 4 8 12 16 20 5 10 15 20 25 Finally, and importantly for machine learning, we can conveniently do things like matrix multiply. W = randn ( 5 , 10 ) x = rand ( 10 ) W * x 5-element Vector{Float64}: 1.2197981041108443 -2.62625877100596 -2.8573820474674845 -2.4319346874291314 1.010866857715021 Julia's arrays are very powerful, and you can learn more about what they can do here . CUDA Arrays \u00a4 CUDA functionality is provided separately by the CUDA.jl package . If you have a GPU and CUDA available, Lux will automatically build the required CUDA dependencies using CUDA.jl . You can manually add CUDA . Once CUDA is loaded you can move any array to the GPU with the cu function (or the gpu function exported by `Lux``), and it supports all of the above operations with the same syntax. # using CUDA # x = cu(rand(5, 3)) (Im)mutability \u00a4 Lux as you might have read is Immutable by convention which means that the core library is built without any form of mutation and all functions are pure. However, we don't enforce it in any form. We do strongly recommend that users extending this framework for their respective applications don't mutate their arrays. x = reshape ( 1 : 8 , 2 , 4 ) 2\u00d74 reshape(::UnitRange{Int64}, 2, 4) with eltype Int64: 1 3 5 7 2 4 6 8 To update this array, we should first copy the array. x_copy = copy ( x ) view ( x_copy , : , 1 ) .= 0 println ( \"Original Array \" , x ) println ( \"Mutated Array \" , x_copy ) Original Array [1 3 5 7; 2 4 6 8] Mutated Array [0 3 5 7; 0 4 6 8] Note that our current default AD engine (Zygote) is unable to differentiate through this mutation, however, for these specialized cases it is quite trivial to write custom backward passes. (This problem will be fixed once we move towards Enzyme.jl) Managing Randomness \u00a4 We rely on the Julia StdLib Random for managing the randomness in our execution. First, we create an PRNG and seed it. rng = Random . default_rng () # Creates a Xoshiro PRNG Random . seed! ( rng , 0 ) Random.TaskLocalRNG() If we call any function that relies on rng and uses it via randn , rand , etc. rng will be mutated. As we have already established we care a lot about immutability, hence we should use Lux.replicate on PRNG before using them. First, let us run a random number generator 3 times with the replicate d rng. for i in 1 : 3 println ( \"Iteration $i \" , rand ( Lux . replicate ( rng ), 10 )) end Iteration 1 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 2 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 3 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] As expected we get the same output. We can remove the replicate call and we will get different outputs. for i in 1 : 3 println ( \"Iteration $i \" , rand ( rng , 10 )) end Iteration 1 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 2 [0.018743665453639813, 0.8601828553599953, 0.6556360448565952, 0.7746656838366666, 0.7817315740767116, 0.5553797706980106, 0.1261990389976131, 0.4488101521328277, 0.624383955429775, 0.05657739601024536] Iteration 3 [0.19597391412112541, 0.6830945313415872, 0.6776220912718907, 0.6456416023530093, 0.6340362477836592, 0.5595843665394066, 0.5675557670686644, 0.34351700231383653, 0.7237308297251812, 0.3691778381831775] Automatic Differentiation \u00a4 Julia has quite a few (maybe too many) AD tools. For the purpose of this tutorial, we will use AbstractDifferentiation.jl which provides a uniform API across multiple AD backends. For the backends we will use: ForwardDiff.jl \u2013 For Jacobian-Vector Product (JVP) Zygote.jl \u2013 For Vector-Jacobian Product (VJP) Slight Detour : We have had several questions regarding if we will be considering any other AD system for the reverse-diff backend. For now we will stick to Zygote.jl, however once Enzyme.jl has support for custom rules and we have tested Lux extensively with it, we will make the switch. Even though, theoretically, a VJP (Vector-Jacobian product - reverse autodiff) and a JVP (Jacobian-Vector product - forward-mode autodiff) are similar\u2014they compute a product of a Jacobian and a vector\u2014they differ by the computational complexity of the operation. In short, when you have a large number of parameters (hence a wide matrix), a JVP is less efficient computationally than a VJP, and, conversely, a JVP is more efficient when the Jacobian matrix is a tall matrix. using ForwardDiff , Zygote , AbstractDifferentiation Gradients \u00a4 For our first example, consider a simple function computing \\(f(x) = \\frac{1}{2}x^T x\\) , where \\(\\nabla f(x) = x\\) f ( x ) = x ' * x / 2 \u2207f ( x ) = x v = randn ( rng , Float32 , 4 ) 4-element Vector{Float32}: -0.4051151 -0.4593922 0.92155594 1.1871622 Let's use AbstractDifferentiation and Zygote to compute the gradients. println ( \"Actual Gradient: \" , \u2207f ( v )) println ( \"Computed Gradient via Reverse Mode AD (Zygote): \" , AD . gradient ( AD . ZygoteBackend (), f , v )[ 1 ]) println ( \"Computed Gradient via Forward Mode AD (ForwardDiff): \" , AD . gradient ( AD . ForwardDiffBackend (), f , v )[ 1 ]) Actual Gradient: Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Computed Gradient via Reverse Mode AD (Zygote): Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Computed Gradient via Forward Mode AD (ForwardDiff): Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Note that AD.gradient will only work for scalar valued outputs. Jacobian-Vector Product \u00a4 I will defer the discussion on forward-mode AD to https://book.sciml.ai/notes/08/ . Here let us just look at a mini example on how to use it. f ( x ) = x .* x ./ 2 x = randn ( rng , Float32 , 5 ) v = ones ( Float32 , 5 ) 5-element Vector{Float32}: 1.0 1.0 1.0 1.0 1.0 Construct the pushforward function. pf_f = AD . value_and_pushforward_function ( AD . ForwardDiffBackend (), f , x ) #17 (generic function with 1 method) Compute the jvp. val , jvp = pf_f ( v ) println ( \"Computed Value: f(\" , x , \") = \" , val ) println ( \"JVP: \" , jvp [ 1 ]) Computed Value: f(Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]) = Float32[0.3850005, 0.71437216, 0.0016247969, 0.031389393, 0.0043726736] JVP: Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656] Vector-Jacobian Product \u00a4 Using the same function and inputs, let us compute the VJP. pb_f = AD . value_and_pullback_function ( AD . ZygoteBackend (), f , x ) #25 (generic function with 1 method) Compute the vjp. val , vjp = pb_f ( v ) println ( \"Computed Value: f(\" , x , \") = \" , val ) println ( \"VJP: \" , vjp [ 1 ]) Computed Value: f(Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]) = Float32[0.3850005, 0.71437216, 0.0016247969, 0.031389393, 0.0043726736] VJP: Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656] Linear Regression \u00a4 Finally, now let us consider a linear regression problem. From a set of data-points \\(\\left\\{ (x_i, y_i), i \\in \\left\\{ 1, \\dots, k \\right\\}, x_i \\in \\mathbb{R}^n, y_i \\in \\mathbb{R}^m \\right\\}\\) , we try to find a set of parameters \\(W\\) and \\(b\\) , s.t. \\(f_{W,b}(x) = Wx + b\\) , which minimizes the mean squared error: \\[ L(W, b) \\longrightarrow \\sum_{i = 1}^{k} \\frac{1}{2} \\| y_i - f_{W,b}(x_i) \\|_2^2 \\] We can write f from scratch, but to demonstrate Lux , let us use the Dense layer. model = Dense ( 10 => 5 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) Random.TaskLocalRNG() Let us initialize the parameters and states (in this case it is empty) for the model. ps , st = Lux . setup ( rng , model ) ps = ps |> Lux . ComponentArray ComponentVector{Float32}(weight = Float32[-0.5583162 0.3457679 \u2026 -0.35419345 0.039559156; -0.05661944 -0.4899126 \u2026 0.22614014 0.27704597; \u2026 ; 0.06026341 -0.11202827 \u2026 0.42526972 -0.3576447; 0.23414856 -0.5949539 \u2026 0.08254115 -0.5224755], bias = Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;]) Set problem dimensions. n_samples = 20 x_dim = 10 y_dim = 5 5 Generate random ground truth W and b. W = randn ( rng , Float32 , y_dim , x_dim ) b = randn ( rng , Float32 , y_dim ) 5-element Vector{Float32}: 0.68468636 -0.57578707 0.0594993 -0.9436797 1.5164032 Generate samples with additional noise. x_samples = randn ( rng , Float32 , x_dim , n_samples ) y_samples = W * x_samples .+ b .+ 0.01f0 .* randn ( rng , Float32 , y_dim , n_samples ) println ( \"x shape: \" , size ( x_samples ), \"; y shape: \" , size ( y_samples )) x shape: (10, 20); y shape: (5, 20) For updating our parameters let's use Optimisers.jl using Optimisers opt = Optimisers . Descent ( 0.01f0 ) Optimisers.Descent{Float32}(0.01f0) Initialize the initial state of the optimiser opt_state = Optimisers . setup ( opt , ps ) Leaf(Descent{Float32}(0.01), nothing) Define the loss function mse ( model , ps , st , X , y ) = sum ( abs2 , model ( X , ps , st )[ 1 ] .- y ) mse ( weight , bias , X , y ) = sum ( abs2 , weight * X .+ bias .- y ) loss_function ( ps , X , y ) = mse ( model , ps , st , X , y ) println ( \"Loss Value with ground true W & b: \" , mse ( W , b , x_samples , y_samples )) for i in 1 : 100 # In actual code, don't use globals. But here I will simply for the sake of demonstration global ps , st , opt_state # Compute the gradient gs = gradient ( loss_function , ps , x_samples , y_samples )[ 1 ] # Perform parameter update opt_state , ps = Optimisers . update ( opt_state , ps , gs ) if i % 10 == 1 || i == 100 println ( \"Loss Value after $i iterations: \" , mse ( model , ps , st , x_samples , y_samples )) end end Loss Value with ground true W & b: 0.009175307 Loss Value after 1 iterations: 165.57005 Loss Value after 11 iterations: 4.351237 Loss Value after 21 iterations: 0.6856849 Loss Value after 31 iterations: 0.15421417 Loss Value after 41 iterations: 0.041469414 Loss Value after 51 iterations: 0.014032223 Loss Value after 61 iterations: 0.006883738 Loss Value after 71 iterations: 0.004938521 Loss Value after 81 iterations: 0.004391277 Loss Value after 91 iterations: 0.0042331247 Loss Value after 100 iterations: 0.0041888584 This page was generated using Literate.jl .","title":"Julia & Lux for the Uninitiated"},{"location":"examples/generated/beginner/Basics/main/#julia-lux-for-the-uninitiated","text":"This is a quick intro to Lux loosely based on: PyTorch's tutorial . Flux's tutorial . Flax's tutorial . It introduces basic Julia programming, as well Zygote , a source-to-source automatic differentiation (AD) framework in Julia. We'll use these tools to build a very simple neural network. Let's start with importing Lux.jl using Lux , Random Activating project at `~/work/Lux.jl/Lux.jl/examples` Now let us control the randomness in our code using proper Pseudo Random Number Generator (PRNG) rng = Random . default_rng () Random . seed! ( rng , 0 ) Random.TaskLocalRNG()","title":"Julia &amp; Lux for the Uninitiated"},{"location":"examples/generated/beginner/Basics/main/#arrays","text":"The starting point for all of our models is the Array (sometimes referred to as a Tensor in other frameworks). This is really just a list of numbers, which might be arranged into a shape like a square. Let's write down an array with three elements. x = [ 1 , 2 , 3 ] 3-element Vector{Int64}: 1 2 3 Here's a matrix \u2013 a square array with four elements. x = [ 1 2 ; 3 4 ] 2\u00d72 Matrix{Int64}: 1 2 3 4 We often work with arrays of thousands of elements, and don't usually write them down by hand. Here's how we can create an array of 5\u00d73 = 15 elements, each a random number from zero to one. x = rand ( rng , 5 , 3 ) 5\u00d73 Matrix{Float64}: 0.455238 0.746943 0.193291 0.547642 0.746801 0.116989 0.773354 0.97667 0.899766 0.940585 0.0869468 0.422918 0.0296477 0.351491 0.707534 There's a few functions like this; try replacing rand with ones , zeros , or randn . By default, Julia works stores numbers is a high-precision format called Float64 . In ML we often don't need all those digits, and can ask Julia to work with Float32 instead. We can even ask for more digits using BigFloat . x = rand ( BigFloat , 5 , 3 ) 5\u00d73 Matrix{BigFloat}: 0.981339 0.793159 0.459019 0.043883 0.624384 0.56055 0.164786 0.524008 0.0355555 0.414769 0.577181 0.621958 0.00823197 0.30215 0.655881 x = rand ( Float32 , 5 , 3 ) 5\u00d73 Matrix{Float32}: 0.567794 0.369178 0.342539 0.0985227 0.201145 0.587206 0.776598 0.148248 0.0851708 0.723731 0.0770206 0.839303 0.404728 0.230954 0.679087 We can ask the array how many elements it has. length ( x ) 15 Or, more specifically, what size it has. size ( x ) (5, 3) We sometimes want to see some elements of the array on their own. x 5\u00d73 Matrix{Float32}: 0.567794 0.369178 0.342539 0.0985227 0.201145 0.587206 0.776598 0.148248 0.0851708 0.723731 0.0770206 0.839303 0.404728 0.230954 0.679087 x [ 2 , 3 ] 0.58720636f0 This means get the second row and the third column. We can also get every row of the third column. x [ : , 3 ] 5-element Vector{Float32}: 0.34253937 0.58720636 0.085170805 0.8393034 0.67908657 We can add arrays, and subtract them, which adds or subtracts each element of the array. x + x 5\u00d73 Matrix{Float32}: 1.13559 0.738356 0.685079 0.197045 0.40229 1.17441 1.5532 0.296496 0.170342 1.44746 0.154041 1.67861 0.809456 0.461908 1.35817 x - x 5\u00d73 Matrix{Float32}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 Julia supports a feature called broadcasting , using the . syntax. This tiles small arrays (or single numbers) to fill bigger ones. x .+ 1 5\u00d73 Matrix{Float32}: 1.56779 1.36918 1.34254 1.09852 1.20114 1.58721 1.7766 1.14825 1.08517 1.72373 1.07702 1.8393 1.40473 1.23095 1.67909 We can see Julia tile the column vector 1:5 across all rows of the larger array. zeros ( 5 , 5 ) .+ ( 1 : 5 ) 5\u00d75 Matrix{Float64}: 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 4.0 4.0 5.0 5.0 5.0 5.0 5.0 The x' syntax is used to transpose a column 1:5 into an equivalent row, and Julia will tile that across columns. zeros ( 5 , 5 ) .+ ( 1 : 5 ) ' 5\u00d75 Matrix{Float64}: 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 1.0 2.0 3.0 4.0 5.0 We can use this to make a times table. ( 1 : 5 ) .* ( 1 : 5 ) ' 5\u00d75 Matrix{Int64}: 1 2 3 4 5 2 4 6 8 10 3 6 9 12 15 4 8 12 16 20 5 10 15 20 25 Finally, and importantly for machine learning, we can conveniently do things like matrix multiply. W = randn ( 5 , 10 ) x = rand ( 10 ) W * x 5-element Vector{Float64}: 1.2197981041108443 -2.62625877100596 -2.8573820474674845 -2.4319346874291314 1.010866857715021 Julia's arrays are very powerful, and you can learn more about what they can do here .","title":"Arrays"},{"location":"examples/generated/beginner/Basics/main/#cuda-arrays","text":"CUDA functionality is provided separately by the CUDA.jl package . If you have a GPU and CUDA available, Lux will automatically build the required CUDA dependencies using CUDA.jl . You can manually add CUDA . Once CUDA is loaded you can move any array to the GPU with the cu function (or the gpu function exported by `Lux``), and it supports all of the above operations with the same syntax. # using CUDA # x = cu(rand(5, 3))","title":"CUDA Arrays"},{"location":"examples/generated/beginner/Basics/main/#immutability","text":"Lux as you might have read is Immutable by convention which means that the core library is built without any form of mutation and all functions are pure. However, we don't enforce it in any form. We do strongly recommend that users extending this framework for their respective applications don't mutate their arrays. x = reshape ( 1 : 8 , 2 , 4 ) 2\u00d74 reshape(::UnitRange{Int64}, 2, 4) with eltype Int64: 1 3 5 7 2 4 6 8 To update this array, we should first copy the array. x_copy = copy ( x ) view ( x_copy , : , 1 ) .= 0 println ( \"Original Array \" , x ) println ( \"Mutated Array \" , x_copy ) Original Array [1 3 5 7; 2 4 6 8] Mutated Array [0 3 5 7; 0 4 6 8] Note that our current default AD engine (Zygote) is unable to differentiate through this mutation, however, for these specialized cases it is quite trivial to write custom backward passes. (This problem will be fixed once we move towards Enzyme.jl)","title":"(Im)mutability"},{"location":"examples/generated/beginner/Basics/main/#managing-randomness","text":"We rely on the Julia StdLib Random for managing the randomness in our execution. First, we create an PRNG and seed it. rng = Random . default_rng () # Creates a Xoshiro PRNG Random . seed! ( rng , 0 ) Random.TaskLocalRNG() If we call any function that relies on rng and uses it via randn , rand , etc. rng will be mutated. As we have already established we care a lot about immutability, hence we should use Lux.replicate on PRNG before using them. First, let us run a random number generator 3 times with the replicate d rng. for i in 1 : 3 println ( \"Iteration $i \" , rand ( Lux . replicate ( rng ), 10 )) end Iteration 1 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 2 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 3 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] As expected we get the same output. We can remove the replicate call and we will get different outputs. for i in 1 : 3 println ( \"Iteration $i \" , rand ( rng , 10 )) end Iteration 1 [0.4552384158732863, 0.5476424498276177, 0.7733535276924052, 0.9405848223512736, 0.02964765308691042, 0.74694291453392, 0.7468008914093891, 0.9766699015845924, 0.08694684883050086, 0.35149138733595564] Iteration 2 [0.018743665453639813, 0.8601828553599953, 0.6556360448565952, 0.7746656838366666, 0.7817315740767116, 0.5553797706980106, 0.1261990389976131, 0.4488101521328277, 0.624383955429775, 0.05657739601024536] Iteration 3 [0.19597391412112541, 0.6830945313415872, 0.6776220912718907, 0.6456416023530093, 0.6340362477836592, 0.5595843665394066, 0.5675557670686644, 0.34351700231383653, 0.7237308297251812, 0.3691778381831775]","title":"Managing Randomness"},{"location":"examples/generated/beginner/Basics/main/#automatic-differentiation","text":"Julia has quite a few (maybe too many) AD tools. For the purpose of this tutorial, we will use AbstractDifferentiation.jl which provides a uniform API across multiple AD backends. For the backends we will use: ForwardDiff.jl \u2013 For Jacobian-Vector Product (JVP) Zygote.jl \u2013 For Vector-Jacobian Product (VJP) Slight Detour : We have had several questions regarding if we will be considering any other AD system for the reverse-diff backend. For now we will stick to Zygote.jl, however once Enzyme.jl has support for custom rules and we have tested Lux extensively with it, we will make the switch. Even though, theoretically, a VJP (Vector-Jacobian product - reverse autodiff) and a JVP (Jacobian-Vector product - forward-mode autodiff) are similar\u2014they compute a product of a Jacobian and a vector\u2014they differ by the computational complexity of the operation. In short, when you have a large number of parameters (hence a wide matrix), a JVP is less efficient computationally than a VJP, and, conversely, a JVP is more efficient when the Jacobian matrix is a tall matrix. using ForwardDiff , Zygote , AbstractDifferentiation","title":"Automatic Differentiation"},{"location":"examples/generated/beginner/Basics/main/#gradients","text":"For our first example, consider a simple function computing \\(f(x) = \\frac{1}{2}x^T x\\) , where \\(\\nabla f(x) = x\\) f ( x ) = x ' * x / 2 \u2207f ( x ) = x v = randn ( rng , Float32 , 4 ) 4-element Vector{Float32}: -0.4051151 -0.4593922 0.92155594 1.1871622 Let's use AbstractDifferentiation and Zygote to compute the gradients. println ( \"Actual Gradient: \" , \u2207f ( v )) println ( \"Computed Gradient via Reverse Mode AD (Zygote): \" , AD . gradient ( AD . ZygoteBackend (), f , v )[ 1 ]) println ( \"Computed Gradient via Forward Mode AD (ForwardDiff): \" , AD . gradient ( AD . ForwardDiffBackend (), f , v )[ 1 ]) Actual Gradient: Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Computed Gradient via Reverse Mode AD (Zygote): Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Computed Gradient via Forward Mode AD (ForwardDiff): Float32[-0.4051151, -0.4593922, 0.92155594, 1.1871622] Note that AD.gradient will only work for scalar valued outputs.","title":"Gradients"},{"location":"examples/generated/beginner/Basics/main/#jacobian-vector-product","text":"I will defer the discussion on forward-mode AD to https://book.sciml.ai/notes/08/ . Here let us just look at a mini example on how to use it. f ( x ) = x .* x ./ 2 x = randn ( rng , Float32 , 5 ) v = ones ( Float32 , 5 ) 5-element Vector{Float32}: 1.0 1.0 1.0 1.0 1.0 Construct the pushforward function. pf_f = AD . value_and_pushforward_function ( AD . ForwardDiffBackend (), f , x ) #17 (generic function with 1 method) Compute the jvp. val , jvp = pf_f ( v ) println ( \"Computed Value: f(\" , x , \") = \" , val ) println ( \"JVP: \" , jvp [ 1 ]) Computed Value: f(Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]) = Float32[0.3850005, 0.71437216, 0.0016247969, 0.031389393, 0.0043726736] JVP: Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]","title":"Jacobian-Vector Product"},{"location":"examples/generated/beginner/Basics/main/#vector-jacobian-product","text":"Using the same function and inputs, let us compute the VJP. pb_f = AD . value_and_pullback_function ( AD . ZygoteBackend (), f , x ) #25 (generic function with 1 method) Compute the vjp. val , vjp = pb_f ( v ) println ( \"Computed Value: f(\" , x , \") = \" , val ) println ( \"VJP: \" , vjp [ 1 ]) Computed Value: f(Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]) = Float32[0.3850005, 0.71437216, 0.0016247969, 0.031389393, 0.0043726736] VJP: Float32[-0.877497, 1.1953009, -0.057005208, 0.25055695, 0.09351656]","title":"Vector-Jacobian Product"},{"location":"examples/generated/beginner/Basics/main/#linear-regression","text":"Finally, now let us consider a linear regression problem. From a set of data-points \\(\\left\\{ (x_i, y_i), i \\in \\left\\{ 1, \\dots, k \\right\\}, x_i \\in \\mathbb{R}^n, y_i \\in \\mathbb{R}^m \\right\\}\\) , we try to find a set of parameters \\(W\\) and \\(b\\) , s.t. \\(f_{W,b}(x) = Wx + b\\) , which minimizes the mean squared error: \\[ L(W, b) \\longrightarrow \\sum_{i = 1}^{k} \\frac{1}{2} \\| y_i - f_{W,b}(x_i) \\|_2^2 \\] We can write f from scratch, but to demonstrate Lux , let us use the Dense layer. model = Dense ( 10 => 5 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) Random.TaskLocalRNG() Let us initialize the parameters and states (in this case it is empty) for the model. ps , st = Lux . setup ( rng , model ) ps = ps |> Lux . ComponentArray ComponentVector{Float32}(weight = Float32[-0.5583162 0.3457679 \u2026 -0.35419345 0.039559156; -0.05661944 -0.4899126 \u2026 0.22614014 0.27704597; \u2026 ; 0.06026341 -0.11202827 \u2026 0.42526972 -0.3576447; 0.23414856 -0.5949539 \u2026 0.08254115 -0.5224755], bias = Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;]) Set problem dimensions. n_samples = 20 x_dim = 10 y_dim = 5 5 Generate random ground truth W and b. W = randn ( rng , Float32 , y_dim , x_dim ) b = randn ( rng , Float32 , y_dim ) 5-element Vector{Float32}: 0.68468636 -0.57578707 0.0594993 -0.9436797 1.5164032 Generate samples with additional noise. x_samples = randn ( rng , Float32 , x_dim , n_samples ) y_samples = W * x_samples .+ b .+ 0.01f0 .* randn ( rng , Float32 , y_dim , n_samples ) println ( \"x shape: \" , size ( x_samples ), \"; y shape: \" , size ( y_samples )) x shape: (10, 20); y shape: (5, 20) For updating our parameters let's use Optimisers.jl using Optimisers opt = Optimisers . Descent ( 0.01f0 ) Optimisers.Descent{Float32}(0.01f0) Initialize the initial state of the optimiser opt_state = Optimisers . setup ( opt , ps ) Leaf(Descent{Float32}(0.01), nothing) Define the loss function mse ( model , ps , st , X , y ) = sum ( abs2 , model ( X , ps , st )[ 1 ] .- y ) mse ( weight , bias , X , y ) = sum ( abs2 , weight * X .+ bias .- y ) loss_function ( ps , X , y ) = mse ( model , ps , st , X , y ) println ( \"Loss Value with ground true W & b: \" , mse ( W , b , x_samples , y_samples )) for i in 1 : 100 # In actual code, don't use globals. But here I will simply for the sake of demonstration global ps , st , opt_state # Compute the gradient gs = gradient ( loss_function , ps , x_samples , y_samples )[ 1 ] # Perform parameter update opt_state , ps = Optimisers . update ( opt_state , ps , gs ) if i % 10 == 1 || i == 100 println ( \"Loss Value after $i iterations: \" , mse ( model , ps , st , x_samples , y_samples )) end end Loss Value with ground true W & b: 0.009175307 Loss Value after 1 iterations: 165.57005 Loss Value after 11 iterations: 4.351237 Loss Value after 21 iterations: 0.6856849 Loss Value after 31 iterations: 0.15421417 Loss Value after 41 iterations: 0.041469414 Loss Value after 51 iterations: 0.014032223 Loss Value after 61 iterations: 0.006883738 Loss Value after 71 iterations: 0.004938521 Loss Value after 81 iterations: 0.004391277 Loss Value after 91 iterations: 0.0042331247 Loss Value after 100 iterations: 0.0041888584 This page was generated using Literate.jl .","title":"Linear Regression"},{"location":"examples/generated/beginner/PolynomialFitting/main/","text":"Fitting a Polynomial using MLP \u00a4 In this tutorial we will fit a MultiLayer Perceptron (MLP) on data generated from a polynomial. Package Imports \u00a4 import Lux import NNlib , Optimisers , Plots , Random , Statistics , Zygote Activating project at `~/work/Lux.jl/Lux.jl/examples` Dataset \u00a4 Generate 128 datapoints from the polynomial \\(y = x^2 - 2x\\) . function generate_data ( rng :: Random . AbstractRNG ) x = reshape ( collect ( range ( - 2.0f0 , 2.0f0 , 128 )), ( 1 , 128 )) y = evalpoly . ( x , (( 0 , - 2 , 1 ),)) .+ randn ( rng , ( 1 , 128 )) .* 0.1f0 return ( x , y ) end generate_data (generic function with 1 method) Initialize the random number generator and fetch the dataset. rng = Random . MersenneTwister () Random . seed! ( rng , 12345 ) ( x , y ) = generate_data ( rng ) (Float32[-2.0 -1.968504 \u2026 1.968504 2.0], [8.11723579535073 7.8972862806322315 \u2026 -0.21213293699653427 0.049985105882301]) Let's visualize the dataset Plots . plot ( x -> evalpoly ( x , ( 0 , - 2 , 1 )), x [ 1 , : ]; label = false ) Plots . scatter! ( x [ 1 , : ], y [ 1 , : ]; label = false , markersize = 3 ) Neural Network \u00a4 For this problem, you should not be using a neural network. But let's still do that! function construct_model () return Lux . Chain ( Lux . Dense ( 1 , 16 , NNlib . relu ), Lux . Dense ( 16 , 1 )) end model = construct_model () Chain( layer_1 = Dense(1 => 16, relu), # 32 parameters layer_2 = Dense(16 => 1), # 17 parameters ) # Total: 49 parameters, # plus 0 states, summarysize 32 bytes. Optimizer \u00a4 We will use Adam from Optimisers.jl opt = Optimisers . Adam ( 0.03 ) Optimisers.Adam{Float64}(0.03, (0.8999999761581421, 0.9990000128746033), 2.220446049250313e-16) Loss Function \u00a4 We will use the Lux.Training API so we need to ensure that our loss function takes 4 inputs \u2013 model, parameters, states and data. The function must return 3 values \u2013 loss, updated_state, and any computed statistics. function loss_function ( model , ps , st , data ) y_pred , st = Lux . apply ( model , data [ 1 ], ps , st ) mse_loss = Statistics . mean ( abs2 , y_pred .- data [ 2 ]) return mse_loss , st , () end loss_function (generic function with 1 method) Training \u00a4 First we will create a Lux.Training.TrainState which is essentially a convenience wrapper over parameters, states and optimizer states. tstate = Lux . Training . TrainState ( rng , model , opt ; transform_variables = Lux . gpu ) Lux.Training.TrainState{NamedTuple{(:layer_1, :layer_2), Tuple{NamedTuple{(:weight, :bias), Tuple{Matrix{Float32}, Matrix{Float32}}}, NamedTuple{(:weight, :bias), Tuple{Matrix{Float32}, Matrix{Float32}}}}}, NamedTuple{(:layer_1, :layer_2), Tuple{NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}}}, NamedTuple{(:layer_1, :layer_2), Tuple{NamedTuple{(:weight, :bias), Tuple{Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float64, Float64}}}, Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float64, Float64}}}}}, NamedTuple{(:weight, :bias), Tuple{Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float64, Float64}}}, Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float64, Float64}}}}}}}, Chain{NamedTuple{(:layer_1, :layer_2), Tuple{Dense{true, typeof(NNlib.relu), typeof(Lux.glorot_uniform), typeof(Lux.zeros32)}, Dense{true, typeof(identity), typeof(Lux.glorot_uniform), typeof(Lux.zeros32)}}}}}(Chain(), (layer_1 = (weight = Float32[0.36222202; 0.23371002; \u2026 ; 0.5260752; -0.07562564;;], bias = Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;]), layer_2 = (weight = Float32[-0.14330137 -0.39328107 \u2026 -0.34761065 -0.05758927], bias = Float32[0.0;;])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()), (layer_1 = (weight = Leaf(Adam{Float64}(0.03, (0.9, 0.999), 2.22045e-16), (Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;], Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;], (0.9, 0.999))), bias = Leaf(Adam{Float64}(0.03, (0.9, 0.999), 2.22045e-16), (Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;], Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;], (0.9, 0.999)))), layer_2 = (weight = Leaf(Adam{Float64}(0.03, (0.9, 0.999), 2.22045e-16), (Float32[0.0 0.0 \u2026 0.0 0.0], Float32[0.0 0.0 \u2026 0.0 0.0], (0.9, 0.999))), bias = Leaf(Adam{Float64}(0.03, (0.9, 0.999), 2.22045e-16), (Float32[0.0;;], Float32[0.0;;], (0.9, 0.999))))), 0) Now we will use Zygote for our AD requirements. vjp_rule = Lux . Training . ZygoteVJP () Lux.Training.ZygoteVJP() Finally the training loop. function main ( tstate :: Lux . Training . TrainState , vjp :: Lux . Training . AbstractVJP , data :: Tuple , epochs :: Int ) data = data .|> Lux . gpu for epoch in 1 : epochs grads , loss , stats , tstate = Lux . Training . compute_gradients ( vjp , loss_function , data , tstate ) @info epoch = epoch loss = loss tstate = Lux . Training . apply_gradients ( tstate , grads ) end return tstate end tstate = main ( tstate , vjp_rule , ( x , y ), 250 ) y_pred = Lux . cpu ( Lux . apply ( tstate . model , Lux . gpu ( x ), tstate . parameters , tstate . states )[ 1 ]) 1\u00d7128 Matrix{Float32}: 7.93183 7.76661 7.60138 7.43616 \u2026 -0.305276 -0.280904 -0.256531 Let's plot the results Plots . plot ( x -> evalpoly ( x , ( 0 , - 2 , 1 )), x [ 1 , : ]; label = false ) Plots . scatter! ( x [ 1 , : ], y [ 1 , : ]; label = \"Actual Data\" , markersize = 3 ) Plots . scatter! ( x [ 1 , : ], y_pred [ 1 , : ]; label = \"Predictions\" , markersize = 3 ) This page was generated using Literate.jl .","title":"Fitting a Polynomial"},{"location":"examples/generated/beginner/PolynomialFitting/main/#fitting-a-polynomial-using-mlp","text":"In this tutorial we will fit a MultiLayer Perceptron (MLP) on data generated from a polynomial.","title":"Fitting a Polynomial using MLP"},{"location":"examples/generated/beginner/PolynomialFitting/main/#package-imports","text":"import Lux import NNlib , Optimisers , Plots , Random , Statistics , Zygote Activating project at `~/work/Lux.jl/Lux.jl/examples`","title":"Package Imports"},{"location":"examples/generated/beginner/PolynomialFitting/main/#dataset","text":"Generate 128 datapoints from the polynomial \\(y = x^2 - 2x\\) . function generate_data ( rng :: Random . AbstractRNG ) x = reshape ( collect ( range ( - 2.0f0 , 2.0f0 , 128 )), ( 1 , 128 )) y = evalpoly . ( x , (( 0 , - 2 , 1 ),)) .+ randn ( rng , ( 1 , 128 )) .* 0.1f0 return ( x , y ) end generate_data (generic function with 1 method) Initialize the random number generator and fetch the dataset. rng = Random . MersenneTwister () Random . seed! ( rng , 12345 ) ( x , y ) = generate_data ( rng ) (Float32[-2.0 -1.968504 \u2026 1.968504 2.0], [8.11723579535073 7.8972862806322315 \u2026 -0.21213293699653427 0.049985105882301]) Let's visualize the dataset Plots . plot ( x -> evalpoly ( x , ( 0 , - 2 , 1 )), x [ 1 , : ]; label = false ) Plots . scatter! ( x [ 1 , : ], y [ 1 , : ]; label = false , markersize = 3 )","title":"Dataset"},{"location":"examples/generated/beginner/PolynomialFitting/main/#neural-network","text":"For this problem, you should not be using a neural network. But let's still do that! function construct_model () return Lux . Chain ( Lux . Dense ( 1 , 16 , NNlib . relu ), Lux . Dense ( 16 , 1 )) end model = construct_model () Chain( layer_1 = Dense(1 => 16, relu), # 32 parameters layer_2 = Dense(16 => 1), # 17 parameters ) # Total: 49 parameters, # plus 0 states, summarysize 32 bytes.","title":"Neural Network"},{"location":"examples/generated/beginner/PolynomialFitting/main/#optimizer","text":"We will use Adam from Optimisers.jl opt = Optimisers . Adam ( 0.03 ) Optimisers.Adam{Float64}(0.03, (0.8999999761581421, 0.9990000128746033), 2.220446049250313e-16)","title":"Optimizer"},{"location":"examples/generated/beginner/PolynomialFitting/main/#loss-function","text":"We will use the Lux.Training API so we need to ensure that our loss function takes 4 inputs \u2013 model, parameters, states and data. The function must return 3 values \u2013 loss, updated_state, and any computed statistics. function loss_function ( model , ps , st , data ) y_pred , st = Lux . apply ( model , data [ 1 ], ps , st ) mse_loss = Statistics . mean ( abs2 , y_pred .- data [ 2 ]) return mse_loss , st , () end loss_function (generic function with 1 method)","title":"Loss Function"},{"location":"examples/generated/beginner/PolynomialFitting/main/#training","text":"First we will create a Lux.Training.TrainState which is essentially a convenience wrapper over parameters, states and optimizer states. tstate = Lux . Training . TrainState ( rng , model , opt ; transform_variables = Lux . gpu ) Lux.Training.TrainState{NamedTuple{(:layer_1, :layer_2), Tuple{NamedTuple{(:weight, :bias), Tuple{Matrix{Float32}, Matrix{Float32}}}, NamedTuple{(:weight, :bias), Tuple{Matrix{Float32}, Matrix{Float32}}}}}, NamedTuple{(:layer_1, :layer_2), Tuple{NamedTuple{(), Tuple{}}, NamedTuple{(), Tuple{}}}}, NamedTuple{(:layer_1, :layer_2), Tuple{NamedTuple{(:weight, :bias), Tuple{Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float64, Float64}}}, Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float64, Float64}}}}}, NamedTuple{(:weight, :bias), Tuple{Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float64, Float64}}}, Optimisers.Leaf{Optimisers.Adam{Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float64, Float64}}}}}}}, Chain{NamedTuple{(:layer_1, :layer_2), Tuple{Dense{true, typeof(NNlib.relu), typeof(Lux.glorot_uniform), typeof(Lux.zeros32)}, Dense{true, typeof(identity), typeof(Lux.glorot_uniform), typeof(Lux.zeros32)}}}}}(Chain(), (layer_1 = (weight = Float32[0.36222202; 0.23371002; \u2026 ; 0.5260752; -0.07562564;;], bias = Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;]), layer_2 = (weight = Float32[-0.14330137 -0.39328107 \u2026 -0.34761065 -0.05758927], bias = Float32[0.0;;])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()), (layer_1 = (weight = Leaf(Adam{Float64}(0.03, (0.9, 0.999), 2.22045e-16), (Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;], Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;], (0.9, 0.999))), bias = Leaf(Adam{Float64}(0.03, (0.9, 0.999), 2.22045e-16), (Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;], Float32[0.0; 0.0; \u2026 ; 0.0; 0.0;;], (0.9, 0.999)))), layer_2 = (weight = Leaf(Adam{Float64}(0.03, (0.9, 0.999), 2.22045e-16), (Float32[0.0 0.0 \u2026 0.0 0.0], Float32[0.0 0.0 \u2026 0.0 0.0], (0.9, 0.999))), bias = Leaf(Adam{Float64}(0.03, (0.9, 0.999), 2.22045e-16), (Float32[0.0;;], Float32[0.0;;], (0.9, 0.999))))), 0) Now we will use Zygote for our AD requirements. vjp_rule = Lux . Training . ZygoteVJP () Lux.Training.ZygoteVJP() Finally the training loop. function main ( tstate :: Lux . Training . TrainState , vjp :: Lux . Training . AbstractVJP , data :: Tuple , epochs :: Int ) data = data .|> Lux . gpu for epoch in 1 : epochs grads , loss , stats , tstate = Lux . Training . compute_gradients ( vjp , loss_function , data , tstate ) @info epoch = epoch loss = loss tstate = Lux . Training . apply_gradients ( tstate , grads ) end return tstate end tstate = main ( tstate , vjp_rule , ( x , y ), 250 ) y_pred = Lux . cpu ( Lux . apply ( tstate . model , Lux . gpu ( x ), tstate . parameters , tstate . states )[ 1 ]) 1\u00d7128 Matrix{Float32}: 7.93183 7.76661 7.60138 7.43616 \u2026 -0.305276 -0.280904 -0.256531 Let's plot the results Plots . plot ( x -> evalpoly ( x , ( 0 , - 2 , 1 )), x [ 1 , : ]; label = false ) Plots . scatter! ( x [ 1 , : ], y [ 1 , : ]; label = \"Actual Data\" , markersize = 3 ) Plots . scatter! ( x [ 1 , : ], y_pred [ 1 , : ]; label = \"Predictions\" , markersize = 3 ) This page was generated using Literate.jl .","title":"Training"},{"location":"examples/generated/beginner/SimpleRNN/main/","text":"Training a Simple LSTM \u00a4 In this tutorial we will go over using a recurrent neural network to classify clockwise and anticlockwise spirals. By the end of this tutorial you will be able to: Create custom Lux models. Become familiar with the Lux recurrent neural network API. Training using Optimisers.jl and Zygote.jl. Package Imports \u00a4 using Lux using MLUtils , Optimisers , Zygote , NNlib , Random , Statistics Activating project at `~/work/Lux.jl/Lux.jl/examples` Dataset \u00a4 We will use MLUtils to generate 500 (noisy) clockwise and 500 (noisy) anticlockwise spirals. Using this data we will create a MLUtils.DataLoader . Our dataloader will give us sequences of size 2 \u00d7 seq len \u00d7 batch size and we need to predict a binary value whether the sequence is clockwise or anticlockwise. function get_dataloaders (; dataset_size = 1000 , sequence_length = 50 ) # Create the spirals data = [ MLUtils . Datasets . make_spiral ( sequence_length ) for _ in 1 : dataset_size ] # Get the labels labels = vcat ( repeat ([ 0.0f0 ], dataset_size \u00f7 2 ), repeat ([ 1.0f0 ], dataset_size \u00f7 2 )) clockwise_spirals = [ reshape ( d [ 1 ][ : , 1 : sequence_length ], : , sequence_length , 1 ) for d in data [ 1 : ( dataset_size \u00f7 2 )]] anticlockwise_spirals = [ reshape ( d [ 1 ][ : , ( sequence_length + 1 ) : end ], : , sequence_length , 1 ) for d in data [(( dataset_size \u00f7 2 ) + 1 ) : end ]] x_data = Float32 . ( cat ( clockwise_spirals ... , anticlockwise_spirals ... ; dims = 3 )) # Split the dataset ( x_train , y_train ), ( x_val , y_val ) = splitobs (( x_data , labels ); at = 0.8 , shuffle = true ) # Create DataLoaders return ( # Use DataLoader to automatically minibatch and shuffle the data DataLoader ( collect . (( x_train , y_train )); batchsize = 128 , shuffle = true ), # Don't shuffle the validation data DataLoader ( collect . (( x_val , y_val )); batchsize = 128 , shuffle = false )) end get_dataloaders (generic function with 1 method) Creating a Classifier \u00a4 We will be extending the Lux.AbstractExplicitContainerLayer type for our custom model since it will contain a lstm block and a classifier head. We pass the fieldnames lstm_cell and classifier to the type to ensure that the parameters and states are automatically populated and we don't have to define Lux.initialparameters and Lux.initialstates . struct SpiralClassifier { L , C } <: Lux . AbstractExplicitContainerLayer {( :lstm_cell , :classifier )} lstm_cell :: L classifier :: C end We won't define the model from scratch but rather use the Lux.LSTMCell and Lux.Dense . function SpiralClassifier ( in_dims , hidden_dims , out_dims ) return SpiralClassifier ( LSTMCell ( in_dims => hidden_dims ), Dense ( hidden_dims => out_dims , sigmoid )) end Main.SpiralClassifier Now we need to define the behavior of the Classifier when it is invoked. function ( s :: SpiralClassifier )( x :: AbstractArray { T , 3 }, ps :: NamedTuple , st :: NamedTuple ) where { T } # First we will have to run the sequence through the LSTM Cell # The first call to LSTM Cell will create the initial hidden state # See that the parameters and states are automatically populated into a field called `lstm_cell` # We use `eachslice` to get the elements in the sequence without copying, # and `Iterators.peel` to split out the first element for LSTM initialization. x_init , x_rest = Iterators . peel ( eachslice ( x ; dims = 2 )) ( y , carry ), st_lstm = s . lstm_cell ( x_init , ps . lstm_cell , st . lstm_cell ) # Now that we have the hidden state and memory in `carry` we will pass the input and `carry` jointly for x in x_rest ( y , carry ), st_lstm = s . lstm_cell (( x , carry ), ps . lstm_cell , st_lstm ) end # After running through the sequence we will pass the output through the classifier y , st_classifier = s . classifier ( y , ps . classifier , st . classifier ) # Finally remember to create the updated state st = merge ( st , ( classifier = st_classifier , lstm_cell = st_lstm )) return vec ( y ), st end Defining Accuracy, Loss and Optimiser \u00a4 Now let's define the binarycrossentropy loss. Typically it is recommended to use logitbinarycrossentropy since it is more numerically stable, but for the sake of simplicity we will use binarycrossentropy . function xlogy ( x , y ) result = x * log ( y ) return ifelse ( iszero ( x ), zero ( result ), result ) end function binarycrossentropy ( y_pred , y_true ) y_pred = y_pred .+ eps ( eltype ( y_pred )) return mean ( @. - xlogy ( y_true , y_pred ) - xlogy ( 1 - y_true , 1 - y_pred )) end function compute_loss ( x , y , model , ps , st ) y_pred , st = model ( x , ps , st ) return binarycrossentropy ( y_pred , y ), y_pred , st end matches ( y_pred , y_true ) = sum (( y_pred .> 0.5 ) .== y_true ) accuracy ( y_pred , y_true ) = matches ( y_pred , y_true ) / length ( y_pred ) accuracy (generic function with 1 method) Finally lets create an optimiser given the model parameters. function create_optimiser ( ps ) opt = Optimisers . ADAM ( 0.01f0 ) return Optimisers . setup ( opt , ps ) end create_optimiser (generic function with 1 method) Training the Model \u00a4 function main () # Get the dataloaders ( train_loader , val_loader ) = get_dataloaders () # Create the model model = SpiralClassifier ( 2 , 8 , 1 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , model ) # Create the optimiser opt_state = create_optimiser ( ps ) for epoch in 1 : 25 # Train the model for ( x , y ) in train_loader ( loss , y_pred , st ), back = pullback ( p -> compute_loss ( x , y , model , p , st ), ps ) gs = back (( one ( loss ), nothing , nothing ))[ 1 ] opt_state , ps = Optimisers . update ( opt_state , ps , gs ) println ( \"Epoch [ $epoch ]: Loss $loss \" ) end # Validate the model st_ = Lux . testmode ( st ) for ( x , y ) in val_loader ( loss , y_pred , st_ ) = compute_loss ( x , y , model , ps , st_ ) acc = accuracy ( y_pred , y ) println ( \"Validation: Loss $loss Accuracy $acc \" ) end end end main () Epoch [1]: Loss 0.561492 Epoch [1]: Loss 0.5049322 Epoch [1]: Loss 0.4733414 Epoch [1]: Loss 0.44829372 Epoch [1]: Loss 0.43330285 Epoch [1]: Loss 0.40884116 Epoch [1]: Loss 0.39148536 Validation: Loss 0.3664357 Accuracy 1.0 Validation: Loss 0.37418374 Accuracy 1.0 Epoch [2]: Loss 0.35810763 Epoch [2]: Loss 0.3540123 Epoch [2]: Loss 0.34280914 Epoch [2]: Loss 0.31932053 Epoch [2]: Loss 0.29979163 Epoch [2]: Loss 0.2854033 Epoch [2]: Loss 0.27200708 Validation: Loss 0.25686267 Accuracy 1.0 Validation: Loss 0.26163244 Accuracy 1.0 Epoch [3]: Loss 0.25949383 Epoch [3]: Loss 0.24392258 Epoch [3]: Loss 0.2316668 Epoch [3]: Loss 0.2247244 Epoch [3]: Loss 0.20731024 Epoch [3]: Loss 0.19880317 Epoch [3]: Loss 0.19710156 Validation: Loss 0.1796924 Accuracy 1.0 Validation: Loss 0.18212949 Accuracy 1.0 Epoch [4]: Loss 0.18085614 Epoch [4]: Loss 0.17043298 Epoch [4]: Loss 0.16408418 Epoch [4]: Loss 0.15665929 Epoch [4]: Loss 0.14891386 Epoch [4]: Loss 0.14152794 Epoch [4]: Loss 0.13711964 Validation: Loss 0.12865411 Accuracy 1.0 Validation: Loss 0.13010192 Accuracy 1.0 Epoch [5]: Loss 0.12951383 Epoch [5]: Loss 0.12434526 Epoch [5]: Loss 0.11591293 Epoch [5]: Loss 0.11358936 Epoch [5]: Loss 0.10719828 Epoch [5]: Loss 0.10342907 Epoch [5]: Loss 0.09996709 Validation: Loss 0.093723595 Accuracy 1.0 Validation: Loss 0.09507543 Accuracy 1.0 Epoch [6]: Loss 0.09453928 Epoch [6]: Loss 0.090762645 Epoch [6]: Loss 0.08522213 Epoch [6]: Loss 0.083558984 Epoch [6]: Loss 0.07872709 Epoch [6]: Loss 0.07606823 Epoch [6]: Loss 0.07143456 Validation: Loss 0.0691199 Accuracy 1.0 Validation: Loss 0.07055586 Accuracy 1.0 Epoch [7]: Loss 0.07066444 Epoch [7]: Loss 0.06535727 Epoch [7]: Loss 0.0656072 Epoch [7]: Loss 0.060713094 Epoch [7]: Loss 0.058773097 Epoch [7]: Loss 0.055840626 Epoch [7]: Loss 0.054903753 Validation: Loss 0.051482532 Accuracy 1.0 Validation: Loss 0.052948117 Accuracy 1.0 Epoch [8]: Loss 0.0522733 Epoch [8]: Loss 0.04939264 Epoch [8]: Loss 0.047106456 Epoch [8]: Loss 0.04681232 Epoch [8]: Loss 0.044289384 Epoch [8]: Loss 0.042036798 Epoch [8]: Loss 0.042080157 Validation: Loss 0.038663447 Accuracy 1.0 Validation: Loss 0.040051427 Accuracy 1.0 Epoch [9]: Loss 0.03931776 Epoch [9]: Loss 0.038019795 Epoch [9]: Loss 0.035986934 Epoch [9]: Loss 0.034299023 Epoch [9]: Loss 0.03251434 Epoch [9]: Loss 0.03268974 Epoch [9]: Loss 0.03248941 Validation: Loss 0.029465772 Accuracy 1.0 Validation: Loss 0.030722562 Accuracy 1.0 Epoch [10]: Loss 0.030847851 Epoch [10]: Loss 0.02819908 Epoch [10]: Loss 0.02781074 Epoch [10]: Loss 0.027358903 Epoch [10]: Loss 0.026614834 Epoch [10]: Loss 0.023540288 Epoch [10]: Loss 0.023531206 Validation: Loss 0.02310122 Accuracy 1.0 Validation: Loss 0.024206176 Accuracy 1.0 Epoch [11]: Loss 0.025256008 Epoch [11]: Loss 0.02156265 Epoch [11]: Loss 0.020619348 Epoch [11]: Loss 0.021506965 Epoch [11]: Loss 0.020865383 Epoch [11]: Loss 0.020460127 Epoch [11]: Loss 0.02015041 Validation: Loss 0.018762922 Accuracy 1.0 Validation: Loss 0.019735102 Accuracy 1.0 Epoch [12]: Loss 0.019467251 Epoch [12]: Loss 0.018296994 Epoch [12]: Loss 0.017543338 Epoch [12]: Loss 0.017393222 Epoch [12]: Loss 0.01791835 Epoch [12]: Loss 0.016282294 Epoch [12]: Loss 0.017786937 Validation: Loss 0.015760787 Accuracy 1.0 Validation: Loss 0.016596807 Accuracy 1.0 Epoch [13]: Loss 0.016018663 Epoch [13]: Loss 0.015988281 Epoch [13]: Loss 0.016073948 Epoch [13]: Loss 0.014674231 Epoch [13]: Loss 0.013723783 Epoch [13]: Loss 0.015024225 Epoch [13]: Loss 0.012125992 Validation: Loss 0.013574325 Accuracy 1.0 Validation: Loss 0.014318142 Accuracy 1.0 Epoch [14]: Loss 0.013762573 Epoch [14]: Loss 0.013576588 Epoch [14]: Loss 0.013685017 Epoch [14]: Loss 0.013587369 Epoch [14]: Loss 0.011999476 Epoch [14]: Loss 0.012414616 Epoch [14]: Loss 0.012820663 Validation: Loss 0.01196147 Accuracy 1.0 Validation: Loss 0.012629891 Accuracy 1.0 Epoch [15]: Loss 0.012100892 Epoch [15]: Loss 0.012052081 Epoch [15]: Loss 0.012009954 Epoch [15]: Loss 0.01116526 Epoch [15]: Loss 0.011827394 Epoch [15]: Loss 0.011070059 Epoch [15]: Loss 0.010764796 Validation: Loss 0.010710885 Accuracy 1.0 Validation: Loss 0.011307776 Accuracy 1.0 Epoch [16]: Loss 0.0110752825 Epoch [16]: Loss 0.010561046 Epoch [16]: Loss 0.010730271 Epoch [16]: Loss 0.01040523 Epoch [16]: Loss 0.01029533 Epoch [16]: Loss 0.010239698 Epoch [16]: Loss 0.008787475 Validation: Loss 0.009679158 Accuracy 1.0 Validation: Loss 0.01023557 Accuracy 1.0 Epoch [17]: Loss 0.010150017 Epoch [17]: Loss 0.009025935 Epoch [17]: Loss 0.010305103 Epoch [17]: Loss 0.009451431 Epoch [17]: Loss 0.008786821 Epoch [17]: Loss 0.009461325 Epoch [17]: Loss 0.009145363 Validation: Loss 0.008837716 Accuracy 1.0 Validation: Loss 0.009345841 Accuracy 1.0 Epoch [18]: Loss 0.009202933 Epoch [18]: Loss 0.009076394 Epoch [18]: Loss 0.008618591 Epoch [18]: Loss 0.008942827 Epoch [18]: Loss 0.008269382 Epoch [18]: Loss 0.008285252 Epoch [18]: Loss 0.008135834 Validation: Loss 0.008113932 Accuracy 1.0 Validation: Loss 0.008590452 Accuracy 1.0 Epoch [19]: Loss 0.008532625 Epoch [19]: Loss 0.0076831337 Epoch [19]: Loss 0.008384508 Epoch [19]: Loss 0.008625487 Epoch [19]: Loss 0.007643648 Epoch [19]: Loss 0.0076102763 Epoch [19]: Loss 0.0065414836 Validation: Loss 0.0074992394 Accuracy 1.0 Validation: Loss 0.007939624 Accuracy 1.0 Epoch [20]: Loss 0.007730668 Epoch [20]: Loss 0.0077398065 Epoch [20]: Loss 0.007778799 Epoch [20]: Loss 0.007438405 Epoch [20]: Loss 0.00675506 Epoch [20]: Loss 0.0070469934 Epoch [20]: Loss 0.0076075895 Validation: Loss 0.006959292 Accuracy 1.0 Validation: Loss 0.007375357 Accuracy 1.0 Epoch [21]: Loss 0.0076369424 Epoch [21]: Loss 0.007516828 Epoch [21]: Loss 0.0067849928 Epoch [21]: Loss 0.0066547818 Epoch [21]: Loss 0.005815434 Epoch [21]: Loss 0.0069671134 Epoch [21]: Loss 0.0070822258 Validation: Loss 0.006485629 Accuracy 1.0 Validation: Loss 0.0068737827 Accuracy 1.0 Epoch [22]: Loss 0.006496716 Epoch [22]: Loss 0.0065093264 Epoch [22]: Loss 0.006543028 Epoch [22]: Loss 0.006421078 Epoch [22]: Loss 0.0061733 Epoch [22]: Loss 0.0063228104 Epoch [22]: Loss 0.007062661 Validation: Loss 0.006065048 Accuracy 1.0 Validation: Loss 0.006429774 Accuracy 1.0 Epoch [23]: Loss 0.005854824 Epoch [23]: Loss 0.00634446 Epoch [23]: Loss 0.0061396887 Epoch [23]: Loss 0.0058893436 Epoch [23]: Loss 0.0060816016 Epoch [23]: Loss 0.0061780205 Epoch [23]: Loss 0.0047367197 Validation: Loss 0.0056867786 Accuracy 1.0 Validation: Loss 0.006031164 Accuracy 1.0 Epoch [24]: Loss 0.0055466625 Epoch [24]: Loss 0.005799369 Epoch [24]: Loss 0.005791777 Epoch [24]: Loss 0.0055120173 Epoch [24]: Loss 0.005501915 Epoch [24]: Loss 0.0057529747 Epoch [24]: Loss 0.0058667273 Validation: Loss 0.005351951 Accuracy 1.0 Validation: Loss 0.005677441 Accuracy 1.0 Epoch [25]: Loss 0.005498485 Epoch [25]: Loss 0.005672701 Epoch [25]: Loss 0.0052312263 Epoch [25]: Loss 0.0050940546 Epoch [25]: Loss 0.005527606 Epoch [25]: Loss 0.004832493 Epoch [25]: Loss 0.0058748657 Validation: Loss 0.0050473055 Accuracy 1.0 Validation: Loss 0.0053545195 Accuracy 1.0 This page was generated using Literate.jl .","title":"Training a Simple LSTM"},{"location":"examples/generated/beginner/SimpleRNN/main/#training-a-simple-lstm","text":"In this tutorial we will go over using a recurrent neural network to classify clockwise and anticlockwise spirals. By the end of this tutorial you will be able to: Create custom Lux models. Become familiar with the Lux recurrent neural network API. Training using Optimisers.jl and Zygote.jl.","title":"Training a Simple LSTM"},{"location":"examples/generated/beginner/SimpleRNN/main/#package-imports","text":"using Lux using MLUtils , Optimisers , Zygote , NNlib , Random , Statistics Activating project at `~/work/Lux.jl/Lux.jl/examples`","title":"Package Imports"},{"location":"examples/generated/beginner/SimpleRNN/main/#dataset","text":"We will use MLUtils to generate 500 (noisy) clockwise and 500 (noisy) anticlockwise spirals. Using this data we will create a MLUtils.DataLoader . Our dataloader will give us sequences of size 2 \u00d7 seq len \u00d7 batch size and we need to predict a binary value whether the sequence is clockwise or anticlockwise. function get_dataloaders (; dataset_size = 1000 , sequence_length = 50 ) # Create the spirals data = [ MLUtils . Datasets . make_spiral ( sequence_length ) for _ in 1 : dataset_size ] # Get the labels labels = vcat ( repeat ([ 0.0f0 ], dataset_size \u00f7 2 ), repeat ([ 1.0f0 ], dataset_size \u00f7 2 )) clockwise_spirals = [ reshape ( d [ 1 ][ : , 1 : sequence_length ], : , sequence_length , 1 ) for d in data [ 1 : ( dataset_size \u00f7 2 )]] anticlockwise_spirals = [ reshape ( d [ 1 ][ : , ( sequence_length + 1 ) : end ], : , sequence_length , 1 ) for d in data [(( dataset_size \u00f7 2 ) + 1 ) : end ]] x_data = Float32 . ( cat ( clockwise_spirals ... , anticlockwise_spirals ... ; dims = 3 )) # Split the dataset ( x_train , y_train ), ( x_val , y_val ) = splitobs (( x_data , labels ); at = 0.8 , shuffle = true ) # Create DataLoaders return ( # Use DataLoader to automatically minibatch and shuffle the data DataLoader ( collect . (( x_train , y_train )); batchsize = 128 , shuffle = true ), # Don't shuffle the validation data DataLoader ( collect . (( x_val , y_val )); batchsize = 128 , shuffle = false )) end get_dataloaders (generic function with 1 method)","title":"Dataset"},{"location":"examples/generated/beginner/SimpleRNN/main/#creating-a-classifier","text":"We will be extending the Lux.AbstractExplicitContainerLayer type for our custom model since it will contain a lstm block and a classifier head. We pass the fieldnames lstm_cell and classifier to the type to ensure that the parameters and states are automatically populated and we don't have to define Lux.initialparameters and Lux.initialstates . struct SpiralClassifier { L , C } <: Lux . AbstractExplicitContainerLayer {( :lstm_cell , :classifier )} lstm_cell :: L classifier :: C end We won't define the model from scratch but rather use the Lux.LSTMCell and Lux.Dense . function SpiralClassifier ( in_dims , hidden_dims , out_dims ) return SpiralClassifier ( LSTMCell ( in_dims => hidden_dims ), Dense ( hidden_dims => out_dims , sigmoid )) end Main.SpiralClassifier Now we need to define the behavior of the Classifier when it is invoked. function ( s :: SpiralClassifier )( x :: AbstractArray { T , 3 }, ps :: NamedTuple , st :: NamedTuple ) where { T } # First we will have to run the sequence through the LSTM Cell # The first call to LSTM Cell will create the initial hidden state # See that the parameters and states are automatically populated into a field called `lstm_cell` # We use `eachslice` to get the elements in the sequence without copying, # and `Iterators.peel` to split out the first element for LSTM initialization. x_init , x_rest = Iterators . peel ( eachslice ( x ; dims = 2 )) ( y , carry ), st_lstm = s . lstm_cell ( x_init , ps . lstm_cell , st . lstm_cell ) # Now that we have the hidden state and memory in `carry` we will pass the input and `carry` jointly for x in x_rest ( y , carry ), st_lstm = s . lstm_cell (( x , carry ), ps . lstm_cell , st_lstm ) end # After running through the sequence we will pass the output through the classifier y , st_classifier = s . classifier ( y , ps . classifier , st . classifier ) # Finally remember to create the updated state st = merge ( st , ( classifier = st_classifier , lstm_cell = st_lstm )) return vec ( y ), st end","title":"Creating a Classifier"},{"location":"examples/generated/beginner/SimpleRNN/main/#defining-accuracy-loss-and-optimiser","text":"Now let's define the binarycrossentropy loss. Typically it is recommended to use logitbinarycrossentropy since it is more numerically stable, but for the sake of simplicity we will use binarycrossentropy . function xlogy ( x , y ) result = x * log ( y ) return ifelse ( iszero ( x ), zero ( result ), result ) end function binarycrossentropy ( y_pred , y_true ) y_pred = y_pred .+ eps ( eltype ( y_pred )) return mean ( @. - xlogy ( y_true , y_pred ) - xlogy ( 1 - y_true , 1 - y_pred )) end function compute_loss ( x , y , model , ps , st ) y_pred , st = model ( x , ps , st ) return binarycrossentropy ( y_pred , y ), y_pred , st end matches ( y_pred , y_true ) = sum (( y_pred .> 0.5 ) .== y_true ) accuracy ( y_pred , y_true ) = matches ( y_pred , y_true ) / length ( y_pred ) accuracy (generic function with 1 method) Finally lets create an optimiser given the model parameters. function create_optimiser ( ps ) opt = Optimisers . ADAM ( 0.01f0 ) return Optimisers . setup ( opt , ps ) end create_optimiser (generic function with 1 method)","title":"Defining Accuracy, Loss and Optimiser"},{"location":"examples/generated/beginner/SimpleRNN/main/#training-the-model","text":"function main () # Get the dataloaders ( train_loader , val_loader ) = get_dataloaders () # Create the model model = SpiralClassifier ( 2 , 8 , 1 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , model ) # Create the optimiser opt_state = create_optimiser ( ps ) for epoch in 1 : 25 # Train the model for ( x , y ) in train_loader ( loss , y_pred , st ), back = pullback ( p -> compute_loss ( x , y , model , p , st ), ps ) gs = back (( one ( loss ), nothing , nothing ))[ 1 ] opt_state , ps = Optimisers . update ( opt_state , ps , gs ) println ( \"Epoch [ $epoch ]: Loss $loss \" ) end # Validate the model st_ = Lux . testmode ( st ) for ( x , y ) in val_loader ( loss , y_pred , st_ ) = compute_loss ( x , y , model , ps , st_ ) acc = accuracy ( y_pred , y ) println ( \"Validation: Loss $loss Accuracy $acc \" ) end end end main () Epoch [1]: Loss 0.561492 Epoch [1]: Loss 0.5049322 Epoch [1]: Loss 0.4733414 Epoch [1]: Loss 0.44829372 Epoch [1]: Loss 0.43330285 Epoch [1]: Loss 0.40884116 Epoch [1]: Loss 0.39148536 Validation: Loss 0.3664357 Accuracy 1.0 Validation: Loss 0.37418374 Accuracy 1.0 Epoch [2]: Loss 0.35810763 Epoch [2]: Loss 0.3540123 Epoch [2]: Loss 0.34280914 Epoch [2]: Loss 0.31932053 Epoch [2]: Loss 0.29979163 Epoch [2]: Loss 0.2854033 Epoch [2]: Loss 0.27200708 Validation: Loss 0.25686267 Accuracy 1.0 Validation: Loss 0.26163244 Accuracy 1.0 Epoch [3]: Loss 0.25949383 Epoch [3]: Loss 0.24392258 Epoch [3]: Loss 0.2316668 Epoch [3]: Loss 0.2247244 Epoch [3]: Loss 0.20731024 Epoch [3]: Loss 0.19880317 Epoch [3]: Loss 0.19710156 Validation: Loss 0.1796924 Accuracy 1.0 Validation: Loss 0.18212949 Accuracy 1.0 Epoch [4]: Loss 0.18085614 Epoch [4]: Loss 0.17043298 Epoch [4]: Loss 0.16408418 Epoch [4]: Loss 0.15665929 Epoch [4]: Loss 0.14891386 Epoch [4]: Loss 0.14152794 Epoch [4]: Loss 0.13711964 Validation: Loss 0.12865411 Accuracy 1.0 Validation: Loss 0.13010192 Accuracy 1.0 Epoch [5]: Loss 0.12951383 Epoch [5]: Loss 0.12434526 Epoch [5]: Loss 0.11591293 Epoch [5]: Loss 0.11358936 Epoch [5]: Loss 0.10719828 Epoch [5]: Loss 0.10342907 Epoch [5]: Loss 0.09996709 Validation: Loss 0.093723595 Accuracy 1.0 Validation: Loss 0.09507543 Accuracy 1.0 Epoch [6]: Loss 0.09453928 Epoch [6]: Loss 0.090762645 Epoch [6]: Loss 0.08522213 Epoch [6]: Loss 0.083558984 Epoch [6]: Loss 0.07872709 Epoch [6]: Loss 0.07606823 Epoch [6]: Loss 0.07143456 Validation: Loss 0.0691199 Accuracy 1.0 Validation: Loss 0.07055586 Accuracy 1.0 Epoch [7]: Loss 0.07066444 Epoch [7]: Loss 0.06535727 Epoch [7]: Loss 0.0656072 Epoch [7]: Loss 0.060713094 Epoch [7]: Loss 0.058773097 Epoch [7]: Loss 0.055840626 Epoch [7]: Loss 0.054903753 Validation: Loss 0.051482532 Accuracy 1.0 Validation: Loss 0.052948117 Accuracy 1.0 Epoch [8]: Loss 0.0522733 Epoch [8]: Loss 0.04939264 Epoch [8]: Loss 0.047106456 Epoch [8]: Loss 0.04681232 Epoch [8]: Loss 0.044289384 Epoch [8]: Loss 0.042036798 Epoch [8]: Loss 0.042080157 Validation: Loss 0.038663447 Accuracy 1.0 Validation: Loss 0.040051427 Accuracy 1.0 Epoch [9]: Loss 0.03931776 Epoch [9]: Loss 0.038019795 Epoch [9]: Loss 0.035986934 Epoch [9]: Loss 0.034299023 Epoch [9]: Loss 0.03251434 Epoch [9]: Loss 0.03268974 Epoch [9]: Loss 0.03248941 Validation: Loss 0.029465772 Accuracy 1.0 Validation: Loss 0.030722562 Accuracy 1.0 Epoch [10]: Loss 0.030847851 Epoch [10]: Loss 0.02819908 Epoch [10]: Loss 0.02781074 Epoch [10]: Loss 0.027358903 Epoch [10]: Loss 0.026614834 Epoch [10]: Loss 0.023540288 Epoch [10]: Loss 0.023531206 Validation: Loss 0.02310122 Accuracy 1.0 Validation: Loss 0.024206176 Accuracy 1.0 Epoch [11]: Loss 0.025256008 Epoch [11]: Loss 0.02156265 Epoch [11]: Loss 0.020619348 Epoch [11]: Loss 0.021506965 Epoch [11]: Loss 0.020865383 Epoch [11]: Loss 0.020460127 Epoch [11]: Loss 0.02015041 Validation: Loss 0.018762922 Accuracy 1.0 Validation: Loss 0.019735102 Accuracy 1.0 Epoch [12]: Loss 0.019467251 Epoch [12]: Loss 0.018296994 Epoch [12]: Loss 0.017543338 Epoch [12]: Loss 0.017393222 Epoch [12]: Loss 0.01791835 Epoch [12]: Loss 0.016282294 Epoch [12]: Loss 0.017786937 Validation: Loss 0.015760787 Accuracy 1.0 Validation: Loss 0.016596807 Accuracy 1.0 Epoch [13]: Loss 0.016018663 Epoch [13]: Loss 0.015988281 Epoch [13]: Loss 0.016073948 Epoch [13]: Loss 0.014674231 Epoch [13]: Loss 0.013723783 Epoch [13]: Loss 0.015024225 Epoch [13]: Loss 0.012125992 Validation: Loss 0.013574325 Accuracy 1.0 Validation: Loss 0.014318142 Accuracy 1.0 Epoch [14]: Loss 0.013762573 Epoch [14]: Loss 0.013576588 Epoch [14]: Loss 0.013685017 Epoch [14]: Loss 0.013587369 Epoch [14]: Loss 0.011999476 Epoch [14]: Loss 0.012414616 Epoch [14]: Loss 0.012820663 Validation: Loss 0.01196147 Accuracy 1.0 Validation: Loss 0.012629891 Accuracy 1.0 Epoch [15]: Loss 0.012100892 Epoch [15]: Loss 0.012052081 Epoch [15]: Loss 0.012009954 Epoch [15]: Loss 0.01116526 Epoch [15]: Loss 0.011827394 Epoch [15]: Loss 0.011070059 Epoch [15]: Loss 0.010764796 Validation: Loss 0.010710885 Accuracy 1.0 Validation: Loss 0.011307776 Accuracy 1.0 Epoch [16]: Loss 0.0110752825 Epoch [16]: Loss 0.010561046 Epoch [16]: Loss 0.010730271 Epoch [16]: Loss 0.01040523 Epoch [16]: Loss 0.01029533 Epoch [16]: Loss 0.010239698 Epoch [16]: Loss 0.008787475 Validation: Loss 0.009679158 Accuracy 1.0 Validation: Loss 0.01023557 Accuracy 1.0 Epoch [17]: Loss 0.010150017 Epoch [17]: Loss 0.009025935 Epoch [17]: Loss 0.010305103 Epoch [17]: Loss 0.009451431 Epoch [17]: Loss 0.008786821 Epoch [17]: Loss 0.009461325 Epoch [17]: Loss 0.009145363 Validation: Loss 0.008837716 Accuracy 1.0 Validation: Loss 0.009345841 Accuracy 1.0 Epoch [18]: Loss 0.009202933 Epoch [18]: Loss 0.009076394 Epoch [18]: Loss 0.008618591 Epoch [18]: Loss 0.008942827 Epoch [18]: Loss 0.008269382 Epoch [18]: Loss 0.008285252 Epoch [18]: Loss 0.008135834 Validation: Loss 0.008113932 Accuracy 1.0 Validation: Loss 0.008590452 Accuracy 1.0 Epoch [19]: Loss 0.008532625 Epoch [19]: Loss 0.0076831337 Epoch [19]: Loss 0.008384508 Epoch [19]: Loss 0.008625487 Epoch [19]: Loss 0.007643648 Epoch [19]: Loss 0.0076102763 Epoch [19]: Loss 0.0065414836 Validation: Loss 0.0074992394 Accuracy 1.0 Validation: Loss 0.007939624 Accuracy 1.0 Epoch [20]: Loss 0.007730668 Epoch [20]: Loss 0.0077398065 Epoch [20]: Loss 0.007778799 Epoch [20]: Loss 0.007438405 Epoch [20]: Loss 0.00675506 Epoch [20]: Loss 0.0070469934 Epoch [20]: Loss 0.0076075895 Validation: Loss 0.006959292 Accuracy 1.0 Validation: Loss 0.007375357 Accuracy 1.0 Epoch [21]: Loss 0.0076369424 Epoch [21]: Loss 0.007516828 Epoch [21]: Loss 0.0067849928 Epoch [21]: Loss 0.0066547818 Epoch [21]: Loss 0.005815434 Epoch [21]: Loss 0.0069671134 Epoch [21]: Loss 0.0070822258 Validation: Loss 0.006485629 Accuracy 1.0 Validation: Loss 0.0068737827 Accuracy 1.0 Epoch [22]: Loss 0.006496716 Epoch [22]: Loss 0.0065093264 Epoch [22]: Loss 0.006543028 Epoch [22]: Loss 0.006421078 Epoch [22]: Loss 0.0061733 Epoch [22]: Loss 0.0063228104 Epoch [22]: Loss 0.007062661 Validation: Loss 0.006065048 Accuracy 1.0 Validation: Loss 0.006429774 Accuracy 1.0 Epoch [23]: Loss 0.005854824 Epoch [23]: Loss 0.00634446 Epoch [23]: Loss 0.0061396887 Epoch [23]: Loss 0.0058893436 Epoch [23]: Loss 0.0060816016 Epoch [23]: Loss 0.0061780205 Epoch [23]: Loss 0.0047367197 Validation: Loss 0.0056867786 Accuracy 1.0 Validation: Loss 0.006031164 Accuracy 1.0 Epoch [24]: Loss 0.0055466625 Epoch [24]: Loss 0.005799369 Epoch [24]: Loss 0.005791777 Epoch [24]: Loss 0.0055120173 Epoch [24]: Loss 0.005501915 Epoch [24]: Loss 0.0057529747 Epoch [24]: Loss 0.0058667273 Validation: Loss 0.005351951 Accuracy 1.0 Validation: Loss 0.005677441 Accuracy 1.0 Epoch [25]: Loss 0.005498485 Epoch [25]: Loss 0.005672701 Epoch [25]: Loss 0.0052312263 Epoch [25]: Loss 0.0050940546 Epoch [25]: Loss 0.005527606 Epoch [25]: Loss 0.004832493 Epoch [25]: Loss 0.0058748657 Validation: Loss 0.0050473055 Accuracy 1.0 Validation: Loss 0.0053545195 Accuracy 1.0 This page was generated using Literate.jl .","title":"Training the Model"},{"location":"examples/generated/intermediate/BayesianNN/main/","text":"Bayesian Neural Network \u00a4 We borrow this tutorial from the official Turing Docs . We will show how the explicit parameterization of Lux enables first-class composability with packages which expect flattened out parameter vectors. We will use Turing.jl with Lux.jl to implement implementing a classification algorithm. Lets start by importing the relevant libraries. # Import libraries using Lux using Turing , Plots , Random , ReverseDiff , NNlib , Functors # Hide sampling progress Turing . setprogress! ( false ); # Use reverse_diff due to the number of parameters in neural networks Turing . setadbackend ( :reversediff ) :reversediff Generating data \u00a4 Our goal here is to use a Bayesian neural network to classify points in an artificial dataset. The code below generates data points arranged in a box-like pattern and displays a graph of the dataset we'll be working with. # Number of points to generate N = 80 M = round ( Int , N / 4 ) rng = Random . default_rng () Random . seed! ( rng , 1234 ) # Generate artificial data x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; xt1s = Array ([[ x1s [ i ] + 0.5f0 ; x2s [ i ] + 0.5f0 ] for i in 1 : M ]) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; append! ( xt1s , Array ([[ x1s [ i ] - 5.0f0 ; x2s [ i ] - 5.0f0 ] for i in 1 : M ])) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; xt0s = Array ([[ x1s [ i ] + 0.5f0 ; x2s [ i ] - 5.0f0 ] for i in 1 : M ]) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; append! ( xt0s , Array ([[ x1s [ i ] - 5.0f0 ; x2s [ i ] + 0.5f0 ] for i in 1 : M ])) # Store all the data for later xs = [ xt1s ; xt0s ] ts = [ ones ( 2 * M ); zeros ( 2 * M )] # Plot data points function plot_data () x1 = first . ( xt1s ) y1 = last . ( xt1s ) x2 = first . ( xt0s ) y2 = last . ( xt0s ) plt = Plots . scatter ( x1 , y1 ; color = \"red\" , clim = ( 0 , 1 )) Plots . scatter! ( plt , x2 , y2 ; color = \"blue\" , clim = ( 0 , 1 )) return plt end plot_data () Building the Neural Network \u00a4 The next step is to define a feedforward neural network where we express our parameters as distributions, and not single points as with traditional neural networks. For this we will use Dense to define liner layers and compose them via Chain , both are neural network primitives from Lux . The network nn we will create will have two hidden layers with tanh activations and one output layer with sigmoid activation, as shown below. The nn is an instance that acts as a function and can take data, parameters and current state as inputs and output predictions. We will define distributions on the neural network parameters. # Construct a neural network using Lux nn = Chain ( Dense ( 2 , 3 , tanh ), Dense ( 3 , 2 , tanh ), Dense ( 2 , 1 , sigmoid )) # Initialize the model weights and state ps , st = Lux . setup ( rng , nn ) Lux . parameterlength ( nn ) # number of paraemters in NN 20 The probabilistic model specification below creates a parameters variable, which has IID normal variables. The parameters represents all parameters of our neural net (weights and biases). # Create a regularization term and a Gaussian prior variance term. alpha = 0.09 sig = sqrt ( 1.0 / alpha ) 3.3333333333333335 Construct named tuple from a sampled parameter vector. We could also use ComponentArrays here and simply broadcast to avoid doing this. But let's do it this way to avoid dependencies. function vector_to_parameters ( ps_new :: AbstractVector , ps :: NamedTuple ) @assert length ( ps_new ) == Lux . parameterlength ( ps ) i = 1 function get_ps ( x ) z = reshape ( view ( ps_new , i : ( i + length ( x ) - 1 )), size ( x )) i += length ( x ) return z end return fmap ( get_ps , ps ) end # Specify the probabilistic model. @model function bayes_nn ( xs , ts ) global st # Sample the parameters nparameters = Lux . parameterlength ( nn ) parameters ~ MvNormal ( zeros ( nparameters ), sig .* ones ( nparameters )) # Forward NN to make predictions preds , st = nn ( xs , vector_to_parameters ( parameters , ps ), st ) # Observe each prediction. for i in 1 : length ( ts ) ts [ i ] ~ Bernoulli ( preds [ i ]) end end bayes_nn (generic function with 2 methods) Inference can now be performed by calling sample. We use the HMC sampler here. # Perform inference. N = 5000 ch = sample ( bayes_nn ( hcat ( xs ... ), ts ), HMC ( 0.05 , 4 ), N ) Chains MCMC chain (5000\u00d729\u00d71 Array{Float64, 3}): Iterations = 1:1:5000 Number of chains = 1 Samples per chain = 5000 Wall duration = 142.22 seconds Compute duration = 142.22 seconds parameters = parameters[1], parameters[2], parameters[3], parameters[4], parameters[5], parameters[6], parameters[7], parameters[8], parameters[9], parameters[10], parameters[11], parameters[12], parameters[13], parameters[14], parameters[15], parameters[16], parameters[17], parameters[18], parameters[19], parameters[20] internals = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, step_size, nom_step_size Summary Statistics parameters mean std naive_se mcse ess rhat \u22ef Symbol Float64 Float64 Float64 Float64 Float64 Float64 \u22ef parameters[1] 1.4675 2.3083 0.0326 0.2693 11.7281 2.0767 \u22ef parameters[2] 5.5552 2.7594 0.0390 0.3231 12.4936 1.1899 \u22ef parameters[3] 0.0273 0.7531 0.0107 0.0774 18.6028 1.1024 \u22ef parameters[4] -1.8129 1.6025 0.0227 0.1796 15.6117 1.0448 \u22ef parameters[5] 0.7135 1.3562 0.0192 0.1557 13.5410 1.1842 \u22ef parameters[6] 4.7089 1.7599 0.0249 0.1976 18.8688 1.0080 \u22ef parameters[7] -5.0105 3.4342 0.0486 0.4005 12.7796 1.0072 \u22ef parameters[8] 0.1951 2.3736 0.0336 0.2763 12.0470 1.4253 \u22ef parameters[9] 0.8814 1.6137 0.0228 0.1798 19.0521 1.0278 \u22ef parameters[10] -0.9196 4.1529 0.0587 0.4896 10.7452 2.1730 \u22ef parameters[11] -0.0995 2.6126 0.0369 0.3022 12.2717 1.2131 \u22ef parameters[12] -2.0922 3.0141 0.0426 0.3552 11.4220 1.6551 \u22ef parameters[13] 4.3457 1.7685 0.0250 0.2022 14.9620 1.0385 \u22ef parameters[14] -2.9048 1.6752 0.0237 0.1877 15.8258 1.0980 \u22ef parameters[15] 2.1551 1.8145 0.0257 0.2082 13.7275 1.2178 \u22ef parameters[16] -3.2932 1.4081 0.0199 0.1561 19.8148 1.0165 \u22ef parameters[17] -3.4255 2.6896 0.0380 0.3158 12.6164 1.2372 \u22ef \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22f1 1 column and 3 rows omitted Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% Symbol Float64 Float64 Float64 Float64 Float64 parameters[1] -2.8737 -0.2060 1.2397 3.2028 6.3763 parameters[2] 0.7006 3.3812 5.8509 7.5387 11.0436 parameters[3] -2.0910 -0.2111 0.1039 0.4571 1.0501 parameters[4] -5.8984 -2.5130 -1.6280 -0.7613 0.8443 parameters[5] -0.7348 -0.0564 0.4240 0.9659 5.2736 parameters[6] 1.6909 3.4942 4.5379 5.9346 8.2718 parameters[7] -11.1144 -7.4680 -5.2027 -2.8930 1.9571 parameters[8] -4.3334 -1.5037 0.2996 2.0048 4.4496 parameters[9] -1.9076 -0.1331 0.6428 1.7236 4.4656 parameters[10] -8.4372 -4.2836 0.1960 2.2765 5.9196 parameters[11] -5.1766 -1.7353 0.2017 1.6669 4.5451 parameters[12] -6.9702 -4.6678 -2.4274 0.6276 3.0518 parameters[13] 1.2283 3.0997 4.1223 5.5624 8.0027 parameters[14] -6.2349 -4.0604 -2.9481 -1.8547 0.5993 parameters[15] -1.9406 1.1370 2.4385 3.4656 5.0130 parameters[16] -5.6563 -4.2682 -3.5360 -2.4030 0.0173 parameters[17] -9.2556 -4.9700 -3.1804 -1.7896 1.5551 \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 3 rows omitted Now we extract the parameter samples from the sampled chain as theta (this is of size 5000 x 20 where 5000 is the number of iterations and 20 is the number of parameters). We'll use these primarily to determine how good our model's classifier is. # Extract all weight and bias parameters. theta = MCMCChains . group ( ch , :parameters ) . value ; Prediction Visualization \u00a4 # A helper to run the nn through data `x` using parameters `theta` nn_forward ( x , theta ) = nn ( x , vector_to_parameters ( theta , ps ), st )[ 1 ] # Plot the data we have. plot_data () # Find the index that provided the highest log posterior in the chain. _ , i = findmax ( ch [ :lp ]) # Extract the max row value from i. i = i . I [ 1 ] # Plot the posterior distribution with a contour plot x1_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) x2_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) Z = [ nn_forward ([ x1 , x2 ], theta [ i , : ])[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ) The contour plot above shows that the MAP method is not too bad at classifying our data. Now we can visualize our predictions. \\[ p(\\tilde{x} | X, \\alpha) = \\int_{\\theta} p(\\tilde{x} | \\theta) p(\\theta | X, \\alpha) \\approx \\sum_{\\theta \\sim p(\\theta | X, \\alpha)}f_{\\theta}(\\tilde{x}) \\] The nn_predict function takes the average predicted value from a network parameterized by weights drawn from the MCMC chain. # Return the average predicted value across multiple weights. function nn_predict ( x , theta , num ) return mean ([ nn_forward ( x , view ( theta , i , : ))[ 1 ] for i in 1 : 10 : num ]) end nn_predict (generic function with 1 method) Next, we use the nn_predict function to predict the value at a sample of points where the x1 and x2 coordinates range between -6 and 6. As we can see below, we still have a satisfactory fit to our data, and more importantly, we can also see where the neural network is uncertain about its predictions much easier\u2013-those regions between cluster boundaries. Plot the average prediction. plot_data () n_end = 1500 x1_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) x2_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) Z = [ nn_predict ([ x1 , x2 ], theta , n_end )[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ) <polyline clip-path=\"url(#clip882)\" style=\"stroke:#f8c931; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\" 248.242,995.572 251.669,993.136 323.668,971.121 370.328,936.563 399.093,924.706 463.689,879.991 474.518,874.437 549.943,864.228 606.94,823.418 625.369,815.618 700.794,797.038 757.435,766.846 776.219,763.058 851.645,752.915 927.07,737.862 955.127,766.846 1002.5,814.962 1005.97,823.418 1024.16,879.991 1038.49,936.563 1057.52,993.136 1077.92,1027.06 1081.49,1049.71 1089.16,1106.28 1092,1162.85 1092.49,1219.43 1093.38,1276 1092.33,1332.57 1088.78,1389.14 1086.71,1445.72 \"/> Suppose we are interested in how the predictive power of our Bayesian neural network evolved between samples. In that case, the following graph displays an animation of the contour plot generated from the network weights in samples 1 to 1,000. # Number of iterations to plot. n_end = 1000 anim = @gif for i in 1 : n_end plot_data () Z = [ nn_forward ([ x1 , x2 ], theta [ i , : ])[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ; title = \"Iteration $i \" , clim = ( 0 , 1 )) end every 5 This page was generated using Literate.jl .","title":"Bayesian Neural Network"},{"location":"examples/generated/intermediate/BayesianNN/main/#bayesian-neural-network","text":"We borrow this tutorial from the official Turing Docs . We will show how the explicit parameterization of Lux enables first-class composability with packages which expect flattened out parameter vectors. We will use Turing.jl with Lux.jl to implement implementing a classification algorithm. Lets start by importing the relevant libraries. # Import libraries using Lux using Turing , Plots , Random , ReverseDiff , NNlib , Functors # Hide sampling progress Turing . setprogress! ( false ); # Use reverse_diff due to the number of parameters in neural networks Turing . setadbackend ( :reversediff ) :reversediff","title":"Bayesian Neural Network"},{"location":"examples/generated/intermediate/BayesianNN/main/#generating-data","text":"Our goal here is to use a Bayesian neural network to classify points in an artificial dataset. The code below generates data points arranged in a box-like pattern and displays a graph of the dataset we'll be working with. # Number of points to generate N = 80 M = round ( Int , N / 4 ) rng = Random . default_rng () Random . seed! ( rng , 1234 ) # Generate artificial data x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; xt1s = Array ([[ x1s [ i ] + 0.5f0 ; x2s [ i ] + 0.5f0 ] for i in 1 : M ]) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; append! ( xt1s , Array ([[ x1s [ i ] - 5.0f0 ; x2s [ i ] - 5.0f0 ] for i in 1 : M ])) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; xt0s = Array ([[ x1s [ i ] + 0.5f0 ; x2s [ i ] - 5.0f0 ] for i in 1 : M ]) x1s = rand ( rng , Float32 , M ) * 4.5f0 ; x2s = rand ( rng , Float32 , M ) * 4.5f0 ; append! ( xt0s , Array ([[ x1s [ i ] - 5.0f0 ; x2s [ i ] + 0.5f0 ] for i in 1 : M ])) # Store all the data for later xs = [ xt1s ; xt0s ] ts = [ ones ( 2 * M ); zeros ( 2 * M )] # Plot data points function plot_data () x1 = first . ( xt1s ) y1 = last . ( xt1s ) x2 = first . ( xt0s ) y2 = last . ( xt0s ) plt = Plots . scatter ( x1 , y1 ; color = \"red\" , clim = ( 0 , 1 )) Plots . scatter! ( plt , x2 , y2 ; color = \"blue\" , clim = ( 0 , 1 )) return plt end plot_data ()","title":"Generating data"},{"location":"examples/generated/intermediate/BayesianNN/main/#building-the-neural-network","text":"The next step is to define a feedforward neural network where we express our parameters as distributions, and not single points as with traditional neural networks. For this we will use Dense to define liner layers and compose them via Chain , both are neural network primitives from Lux . The network nn we will create will have two hidden layers with tanh activations and one output layer with sigmoid activation, as shown below. The nn is an instance that acts as a function and can take data, parameters and current state as inputs and output predictions. We will define distributions on the neural network parameters. # Construct a neural network using Lux nn = Chain ( Dense ( 2 , 3 , tanh ), Dense ( 3 , 2 , tanh ), Dense ( 2 , 1 , sigmoid )) # Initialize the model weights and state ps , st = Lux . setup ( rng , nn ) Lux . parameterlength ( nn ) # number of paraemters in NN 20 The probabilistic model specification below creates a parameters variable, which has IID normal variables. The parameters represents all parameters of our neural net (weights and biases). # Create a regularization term and a Gaussian prior variance term. alpha = 0.09 sig = sqrt ( 1.0 / alpha ) 3.3333333333333335 Construct named tuple from a sampled parameter vector. We could also use ComponentArrays here and simply broadcast to avoid doing this. But let's do it this way to avoid dependencies. function vector_to_parameters ( ps_new :: AbstractVector , ps :: NamedTuple ) @assert length ( ps_new ) == Lux . parameterlength ( ps ) i = 1 function get_ps ( x ) z = reshape ( view ( ps_new , i : ( i + length ( x ) - 1 )), size ( x )) i += length ( x ) return z end return fmap ( get_ps , ps ) end # Specify the probabilistic model. @model function bayes_nn ( xs , ts ) global st # Sample the parameters nparameters = Lux . parameterlength ( nn ) parameters ~ MvNormal ( zeros ( nparameters ), sig .* ones ( nparameters )) # Forward NN to make predictions preds , st = nn ( xs , vector_to_parameters ( parameters , ps ), st ) # Observe each prediction. for i in 1 : length ( ts ) ts [ i ] ~ Bernoulli ( preds [ i ]) end end bayes_nn (generic function with 2 methods) Inference can now be performed by calling sample. We use the HMC sampler here. # Perform inference. N = 5000 ch = sample ( bayes_nn ( hcat ( xs ... ), ts ), HMC ( 0.05 , 4 ), N ) Chains MCMC chain (5000\u00d729\u00d71 Array{Float64, 3}): Iterations = 1:1:5000 Number of chains = 1 Samples per chain = 5000 Wall duration = 142.22 seconds Compute duration = 142.22 seconds parameters = parameters[1], parameters[2], parameters[3], parameters[4], parameters[5], parameters[6], parameters[7], parameters[8], parameters[9], parameters[10], parameters[11], parameters[12], parameters[13], parameters[14], parameters[15], parameters[16], parameters[17], parameters[18], parameters[19], parameters[20] internals = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, step_size, nom_step_size Summary Statistics parameters mean std naive_se mcse ess rhat \u22ef Symbol Float64 Float64 Float64 Float64 Float64 Float64 \u22ef parameters[1] 1.4675 2.3083 0.0326 0.2693 11.7281 2.0767 \u22ef parameters[2] 5.5552 2.7594 0.0390 0.3231 12.4936 1.1899 \u22ef parameters[3] 0.0273 0.7531 0.0107 0.0774 18.6028 1.1024 \u22ef parameters[4] -1.8129 1.6025 0.0227 0.1796 15.6117 1.0448 \u22ef parameters[5] 0.7135 1.3562 0.0192 0.1557 13.5410 1.1842 \u22ef parameters[6] 4.7089 1.7599 0.0249 0.1976 18.8688 1.0080 \u22ef parameters[7] -5.0105 3.4342 0.0486 0.4005 12.7796 1.0072 \u22ef parameters[8] 0.1951 2.3736 0.0336 0.2763 12.0470 1.4253 \u22ef parameters[9] 0.8814 1.6137 0.0228 0.1798 19.0521 1.0278 \u22ef parameters[10] -0.9196 4.1529 0.0587 0.4896 10.7452 2.1730 \u22ef parameters[11] -0.0995 2.6126 0.0369 0.3022 12.2717 1.2131 \u22ef parameters[12] -2.0922 3.0141 0.0426 0.3552 11.4220 1.6551 \u22ef parameters[13] 4.3457 1.7685 0.0250 0.2022 14.9620 1.0385 \u22ef parameters[14] -2.9048 1.6752 0.0237 0.1877 15.8258 1.0980 \u22ef parameters[15] 2.1551 1.8145 0.0257 0.2082 13.7275 1.2178 \u22ef parameters[16] -3.2932 1.4081 0.0199 0.1561 19.8148 1.0165 \u22ef parameters[17] -3.4255 2.6896 0.0380 0.3158 12.6164 1.2372 \u22ef \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee \u22f1 1 column and 3 rows omitted Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% Symbol Float64 Float64 Float64 Float64 Float64 parameters[1] -2.8737 -0.2060 1.2397 3.2028 6.3763 parameters[2] 0.7006 3.3812 5.8509 7.5387 11.0436 parameters[3] -2.0910 -0.2111 0.1039 0.4571 1.0501 parameters[4] -5.8984 -2.5130 -1.6280 -0.7613 0.8443 parameters[5] -0.7348 -0.0564 0.4240 0.9659 5.2736 parameters[6] 1.6909 3.4942 4.5379 5.9346 8.2718 parameters[7] -11.1144 -7.4680 -5.2027 -2.8930 1.9571 parameters[8] -4.3334 -1.5037 0.2996 2.0048 4.4496 parameters[9] -1.9076 -0.1331 0.6428 1.7236 4.4656 parameters[10] -8.4372 -4.2836 0.1960 2.2765 5.9196 parameters[11] -5.1766 -1.7353 0.2017 1.6669 4.5451 parameters[12] -6.9702 -4.6678 -2.4274 0.6276 3.0518 parameters[13] 1.2283 3.0997 4.1223 5.5624 8.0027 parameters[14] -6.2349 -4.0604 -2.9481 -1.8547 0.5993 parameters[15] -1.9406 1.1370 2.4385 3.4656 5.0130 parameters[16] -5.6563 -4.2682 -3.5360 -2.4030 0.0173 parameters[17] -9.2556 -4.9700 -3.1804 -1.7896 1.5551 \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 3 rows omitted Now we extract the parameter samples from the sampled chain as theta (this is of size 5000 x 20 where 5000 is the number of iterations and 20 is the number of parameters). We'll use these primarily to determine how good our model's classifier is. # Extract all weight and bias parameters. theta = MCMCChains . group ( ch , :parameters ) . value ;","title":"Building the Neural Network"},{"location":"examples/generated/intermediate/BayesianNN/main/#prediction-visualization","text":"# A helper to run the nn through data `x` using parameters `theta` nn_forward ( x , theta ) = nn ( x , vector_to_parameters ( theta , ps ), st )[ 1 ] # Plot the data we have. plot_data () # Find the index that provided the highest log posterior in the chain. _ , i = findmax ( ch [ :lp ]) # Extract the max row value from i. i = i . I [ 1 ] # Plot the posterior distribution with a contour plot x1_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) x2_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) Z = [ nn_forward ([ x1 , x2 ], theta [ i , : ])[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ) The contour plot above shows that the MAP method is not too bad at classifying our data. Now we can visualize our predictions. \\[ p(\\tilde{x} | X, \\alpha) = \\int_{\\theta} p(\\tilde{x} | \\theta) p(\\theta | X, \\alpha) \\approx \\sum_{\\theta \\sim p(\\theta | X, \\alpha)}f_{\\theta}(\\tilde{x}) \\] The nn_predict function takes the average predicted value from a network parameterized by weights drawn from the MCMC chain. # Return the average predicted value across multiple weights. function nn_predict ( x , theta , num ) return mean ([ nn_forward ( x , view ( theta , i , : ))[ 1 ] for i in 1 : 10 : num ]) end nn_predict (generic function with 1 method) Next, we use the nn_predict function to predict the value at a sample of points where the x1 and x2 coordinates range between -6 and 6. As we can see below, we still have a satisfactory fit to our data, and more importantly, we can also see where the neural network is uncertain about its predictions much easier\u2013-those regions between cluster boundaries. Plot the average prediction. plot_data () n_end = 1500 x1_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) x2_range = collect ( range ( - 6 ; stop = 6 , length = 25 )) Z = [ nn_predict ([ x1 , x2 ], theta , n_end )[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ) <polyline clip-path=\"url(#clip882)\" style=\"stroke:#f8c931; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\" 248.242,995.572 251.669,993.136 323.668,971.121 370.328,936.563 399.093,924.706 463.689,879.991 474.518,874.437 549.943,864.228 606.94,823.418 625.369,815.618 700.794,797.038 757.435,766.846 776.219,763.058 851.645,752.915 927.07,737.862 955.127,766.846 1002.5,814.962 1005.97,823.418 1024.16,879.991 1038.49,936.563 1057.52,993.136 1077.92,1027.06 1081.49,1049.71 1089.16,1106.28 1092,1162.85 1092.49,1219.43 1093.38,1276 1092.33,1332.57 1088.78,1389.14 1086.71,1445.72 \"/> Suppose we are interested in how the predictive power of our Bayesian neural network evolved between samples. In that case, the following graph displays an animation of the contour plot generated from the network weights in samples 1 to 1,000. # Number of iterations to plot. n_end = 1000 anim = @gif for i in 1 : n_end plot_data () Z = [ nn_forward ([ x1 , x2 ], theta [ i , : ])[ 1 ] for x1 in x1_range , x2 in x2_range ] contour! ( x1_range , x2_range , Z ; title = \"Iteration $i \" , clim = ( 0 , 1 )) end every 5 This page was generated using Literate.jl .","title":"Prediction Visualization"},{"location":"examples/generated/intermediate/NeuralODE/main/","text":"MNIST Classification using Neural ODEs \u00a4 Package Imports \u00a4 using Lux using ComponentArrays , CUDA , DiffEqSensitivity , NNlib , Optimisers , OrdinaryDiffEq , Random , Statistics , Zygote , OneHotArrays import MLDatasets : MNIST import MLUtils : DataLoader , splitobs CUDA . allowscalar ( false ) Activating project at `~/work/Lux.jl/Lux.jl/examples` Loading MNIST \u00a4 function loadmnist ( batchsize , train_split ) # Load MNIST: Only 1500 for demonstration purposes N = 1500 dataset = MNIST (; split = :train ) imgs = dataset . features [ : , : , 1 : N ] labels_raw = dataset . targets [ 1 : N ] # Process images into (H,W,C,BS) batches x_data = Float32 . ( reshape ( imgs , size ( imgs , 1 ), size ( imgs , 2 ), 1 , size ( imgs , 3 ))) y_data = onehotbatch ( labels_raw , 0 : 9 ) ( x_train , y_train ), ( x_test , y_test ) = splitobs (( x_data , y_data ); at = train_split ) return ( # Use DataLoader to automatically minibatch and shuffle the data DataLoader ( collect . (( x_train , y_train )); batchsize = batchsize , shuffle = true ), # Don't shuffle the test data DataLoader ( collect . (( x_test , y_test )); batchsize = batchsize , shuffle = false )) end loadmnist (generic function with 1 method) Define the Neural ODE Layer \u00a4 The NeuralODE is a ContainerLayer, which stores a model . The parameters and states of the NeuralODE are same as those of the underlying model. struct NeuralODE { M <: Lux . AbstractExplicitLayer , So , Se , T , K } <: Lux . AbstractExplicitContainerLayer {( :model ,)} model :: M solver :: So sensealg :: Se tspan :: T kwargs :: K end function NeuralODE ( model :: Lux . AbstractExplicitLayer ; solver = Tsit5 (), sensealg = InterpolatingAdjoint (; autojacvec = ZygoteVJP ()), tspan = ( 0.0f0 , 1.0f0 ), kwargs ... ) return NeuralODE ( model , solver , sensealg , tspan , kwargs ) end function ( n :: NeuralODE )( x , ps , st ) function dudt ( u , p , t ) u_ , st = n . model ( u , p , st ) return u_ end prob = ODEProblem { false }( ODEFunction { false }( dudt ), x , n . tspan , ps ) return solve ( prob , n . solver ; sensealg = n . sensealg , n . kwargs ... ), st end function diffeqsol_to_array ( x :: ODESolution { T , N , <: AbstractVector { <: CuArray }}) where { T , N } return dropdims ( gpu ( x ); dims = 3 ) end diffeqsol_to_array ( x :: ODESolution ) = dropdims ( Array ( x ); dims = 3 ) diffeqsol_to_array (generic function with 2 methods) Create and Initialize the Neural ODE Layer \u00a4 function create_model () # Construct the Neural ODE Model model = Chain ( FlattenLayer (), Dense ( 784 , 20 , tanh ), NeuralODE ( Chain ( Dense ( 20 , 10 , tanh ), Dense ( 10 , 10 , tanh ), Dense ( 10 , 20 , tanh )); save_everystep = false , reltol = 1.0f-3 , abstol = 1.0f-3 , save_start = false ), diffeqsol_to_array , Dense ( 20 , 10 )) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , model ) ps = ComponentArray ( ps ) |> gpu st = st |> gpu return model , ps , st end create_model (generic function with 1 method) Define Utility Functions \u00a4 logitcrossentropy ( y_pred , y ) = mean ( - sum ( y .* logsoftmax ( y_pred ); dims = 1 )) function loss ( x , y , model , ps , st ) y_pred , st = model ( x , ps , st ) return logitcrossentropy ( y_pred , y ), st end function accuracy ( model , ps , st , dataloader ) total_correct , total = 0 , 0 st = Lux . testmode ( st ) iterator = CUDA . functional () ? CuIterator ( dataloader ) : dataloader for ( x , y ) in iterator target_class = onecold ( cpu ( y )) predicted_class = onecold ( cpu ( model ( x , ps , st )[ 1 ])) total_correct += sum ( target_class .== predicted_class ) total += length ( target_class ) end return total_correct / total end accuracy (generic function with 1 method) Training \u00a4 function train () model , ps , st = create_model () # Training train_dataloader , test_dataloader = loadmnist ( 128 , 0.9 ) opt = Optimisers . ADAM ( 0.001f0 ) st_opt = Optimisers . setup ( opt , ps ) ### Warmup the Model img , lab = gpu ( train_dataloader . data [ 1 ][ : , : , : , 1 : 1 ]), gpu ( train_dataloader . data [ 2 ][ : , 1 : 1 ]) loss ( img , lab , model , ps , st ) ( l , _ ), back = pullback ( p -> loss ( img , lab , model , p , st ), ps ) back (( one ( l ), nothing )) ### Lets train the model nepochs = 9 for epoch in 1 : nepochs stime = time () iterator = CUDA . functional () ? CuIterator ( train_dataloader ) : train_dataloader for ( x , y ) in iterator ( l , st ), back = pullback ( p -> loss ( x , y , model , p , st ), ps ) gs = back (( one ( l ), nothing ))[ 1 ] st_opt , ps = Optimisers . update ( st_opt , ps , gs ) end ttime = time () - stime println ( \"[ $epoch / $nepochs ] \\t Time $ ( round ( ttime ; digits = 2 )) s \\t Training Accuracy: \" * \" $ ( round ( accuracy ( model , ps , st , train_dataloader ) * 100 ; digits = 2 )) % \\t \" * \"Test Accuracy: $ ( round ( accuracy ( model , ps , st , test_dataloader ) * 100 ; digits = 2 )) %\" ) end end train () [1/9] Time 1.91s Training Accuracy: 51.7% Test Accuracy: 44.0% [2/9] Time 0.28s Training Accuracy: 71.04% Test Accuracy: 66.67% [3/9] Time 0.3s Training Accuracy: 78.07% Test Accuracy: 72.0% [4/9] Time 0.19s Training Accuracy: 79.93% Test Accuracy: 73.33% [5/9] Time 0.23s Training Accuracy: 82.89% Test Accuracy: 78.0% [6/9] Time 0.22s Training Accuracy: 84.52% Test Accuracy: 78.67% [7/9] Time 0.17s Training Accuracy: 85.78% Test Accuracy: 80.67% [8/9] Time 0.2s Training Accuracy: 86.81% Test Accuracy: 81.33% [9/9] Time 0.17s Training Accuracy: 87.48% Test Accuracy: 82.67% This page was generated using Literate.jl .","title":"MNIST Classification using NeuralODE"},{"location":"examples/generated/intermediate/NeuralODE/main/#mnist-classification-using-neural-odes","text":"","title":"MNIST Classification using Neural ODEs"},{"location":"examples/generated/intermediate/NeuralODE/main/#package-imports","text":"using Lux using ComponentArrays , CUDA , DiffEqSensitivity , NNlib , Optimisers , OrdinaryDiffEq , Random , Statistics , Zygote , OneHotArrays import MLDatasets : MNIST import MLUtils : DataLoader , splitobs CUDA . allowscalar ( false ) Activating project at `~/work/Lux.jl/Lux.jl/examples`","title":"Package Imports"},{"location":"examples/generated/intermediate/NeuralODE/main/#loading-mnist","text":"function loadmnist ( batchsize , train_split ) # Load MNIST: Only 1500 for demonstration purposes N = 1500 dataset = MNIST (; split = :train ) imgs = dataset . features [ : , : , 1 : N ] labels_raw = dataset . targets [ 1 : N ] # Process images into (H,W,C,BS) batches x_data = Float32 . ( reshape ( imgs , size ( imgs , 1 ), size ( imgs , 2 ), 1 , size ( imgs , 3 ))) y_data = onehotbatch ( labels_raw , 0 : 9 ) ( x_train , y_train ), ( x_test , y_test ) = splitobs (( x_data , y_data ); at = train_split ) return ( # Use DataLoader to automatically minibatch and shuffle the data DataLoader ( collect . (( x_train , y_train )); batchsize = batchsize , shuffle = true ), # Don't shuffle the test data DataLoader ( collect . (( x_test , y_test )); batchsize = batchsize , shuffle = false )) end loadmnist (generic function with 1 method)","title":"Loading MNIST"},{"location":"examples/generated/intermediate/NeuralODE/main/#define-the-neural-ode-layer","text":"The NeuralODE is a ContainerLayer, which stores a model . The parameters and states of the NeuralODE are same as those of the underlying model. struct NeuralODE { M <: Lux . AbstractExplicitLayer , So , Se , T , K } <: Lux . AbstractExplicitContainerLayer {( :model ,)} model :: M solver :: So sensealg :: Se tspan :: T kwargs :: K end function NeuralODE ( model :: Lux . AbstractExplicitLayer ; solver = Tsit5 (), sensealg = InterpolatingAdjoint (; autojacvec = ZygoteVJP ()), tspan = ( 0.0f0 , 1.0f0 ), kwargs ... ) return NeuralODE ( model , solver , sensealg , tspan , kwargs ) end function ( n :: NeuralODE )( x , ps , st ) function dudt ( u , p , t ) u_ , st = n . model ( u , p , st ) return u_ end prob = ODEProblem { false }( ODEFunction { false }( dudt ), x , n . tspan , ps ) return solve ( prob , n . solver ; sensealg = n . sensealg , n . kwargs ... ), st end function diffeqsol_to_array ( x :: ODESolution { T , N , <: AbstractVector { <: CuArray }}) where { T , N } return dropdims ( gpu ( x ); dims = 3 ) end diffeqsol_to_array ( x :: ODESolution ) = dropdims ( Array ( x ); dims = 3 ) diffeqsol_to_array (generic function with 2 methods)","title":"Define the Neural ODE Layer"},{"location":"examples/generated/intermediate/NeuralODE/main/#create-and-initialize-the-neural-ode-layer","text":"function create_model () # Construct the Neural ODE Model model = Chain ( FlattenLayer (), Dense ( 784 , 20 , tanh ), NeuralODE ( Chain ( Dense ( 20 , 10 , tanh ), Dense ( 10 , 10 , tanh ), Dense ( 10 , 20 , tanh )); save_everystep = false , reltol = 1.0f-3 , abstol = 1.0f-3 , save_start = false ), diffeqsol_to_array , Dense ( 20 , 10 )) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , model ) ps = ComponentArray ( ps ) |> gpu st = st |> gpu return model , ps , st end create_model (generic function with 1 method)","title":"Create and Initialize the Neural ODE Layer"},{"location":"examples/generated/intermediate/NeuralODE/main/#define-utility-functions","text":"logitcrossentropy ( y_pred , y ) = mean ( - sum ( y .* logsoftmax ( y_pred ); dims = 1 )) function loss ( x , y , model , ps , st ) y_pred , st = model ( x , ps , st ) return logitcrossentropy ( y_pred , y ), st end function accuracy ( model , ps , st , dataloader ) total_correct , total = 0 , 0 st = Lux . testmode ( st ) iterator = CUDA . functional () ? CuIterator ( dataloader ) : dataloader for ( x , y ) in iterator target_class = onecold ( cpu ( y )) predicted_class = onecold ( cpu ( model ( x , ps , st )[ 1 ])) total_correct += sum ( target_class .== predicted_class ) total += length ( target_class ) end return total_correct / total end accuracy (generic function with 1 method)","title":"Define Utility Functions"},{"location":"examples/generated/intermediate/NeuralODE/main/#training","text":"function train () model , ps , st = create_model () # Training train_dataloader , test_dataloader = loadmnist ( 128 , 0.9 ) opt = Optimisers . ADAM ( 0.001f0 ) st_opt = Optimisers . setup ( opt , ps ) ### Warmup the Model img , lab = gpu ( train_dataloader . data [ 1 ][ : , : , : , 1 : 1 ]), gpu ( train_dataloader . data [ 2 ][ : , 1 : 1 ]) loss ( img , lab , model , ps , st ) ( l , _ ), back = pullback ( p -> loss ( img , lab , model , p , st ), ps ) back (( one ( l ), nothing )) ### Lets train the model nepochs = 9 for epoch in 1 : nepochs stime = time () iterator = CUDA . functional () ? CuIterator ( train_dataloader ) : train_dataloader for ( x , y ) in iterator ( l , st ), back = pullback ( p -> loss ( x , y , model , p , st ), ps ) gs = back (( one ( l ), nothing ))[ 1 ] st_opt , ps = Optimisers . update ( st_opt , ps , gs ) end ttime = time () - stime println ( \"[ $epoch / $nepochs ] \\t Time $ ( round ( ttime ; digits = 2 )) s \\t Training Accuracy: \" * \" $ ( round ( accuracy ( model , ps , st , train_dataloader ) * 100 ; digits = 2 )) % \\t \" * \"Test Accuracy: $ ( round ( accuracy ( model , ps , st , test_dataloader ) * 100 ; digits = 2 )) %\" ) end end train () [1/9] Time 1.91s Training Accuracy: 51.7% Test Accuracy: 44.0% [2/9] Time 0.28s Training Accuracy: 71.04% Test Accuracy: 66.67% [3/9] Time 0.3s Training Accuracy: 78.07% Test Accuracy: 72.0% [4/9] Time 0.19s Training Accuracy: 79.93% Test Accuracy: 73.33% [5/9] Time 0.23s Training Accuracy: 82.89% Test Accuracy: 78.0% [6/9] Time 0.22s Training Accuracy: 84.52% Test Accuracy: 78.67% [7/9] Time 0.17s Training Accuracy: 85.78% Test Accuracy: 80.67% [8/9] Time 0.2s Training Accuracy: 86.81% Test Accuracy: 81.33% [9/9] Time 0.17s Training Accuracy: 87.48% Test Accuracy: 82.67% This page was generated using Literate.jl .","title":"Training"},{"location":"introduction/ecosystem/","text":"Ecosystem \u00a4 Frameworks extending Lux \u00a4 Boltz.jl \u2013 Prebuilt deep learning models for image classification tasks DeepEquilibriumNetworks.jl \u2013 Continuous and Discrete Deep Equilibrium Networks DiffEqFlux.jl \u2013 Neural Differential Equations, Continuous Normalizing Flows, etc. Extended Julia Ecosystem \u00a4 As you might have noticed we don't do much apart from Neural Networks. All other parts of the DL training/evaluation pipeline should be offloaded to: Automatic Differentiation \u00a4 Zygote.jl \u2013 Currently the default and recommended AD library Enzyme.jl \u2013 Experimental Support (but will most likely become the future default) ForwardDiff.jl \u2013 For forward mode AD support ReverseDiff.jl \u2013 Tape based reverse mode AD (mostly untested) Data Manipulation and Loading \u00a4 Augmentor.jl DataLoaders.jl Images.jl DataAugmentation.jl Distributed DataParallel Training \u00a4 FluxMPI.jl Neural Network Primitives \u00a4 NNlib.jl Optimisation \u00a4 Optimisers.jl ParameterSchedulers.jl Optimization.jl Parameter Manipulation \u00a4 Functors.jl Serialization \u00a4 Serialization.jl JLD2.jl Testing Utilities \u00a4 FiniteDifferences.jl \u2013 Finite Differencing. Useful for testing gradient correctness JET.jl Training Visualization & Logging \u00a4 Wandb.jl TensorBoardLogger.jl","title":"Ecosystem"},{"location":"introduction/ecosystem/#ecosystem","text":"","title":"Ecosystem"},{"location":"introduction/ecosystem/#frameworks-extending-lux","text":"Boltz.jl \u2013 Prebuilt deep learning models for image classification tasks DeepEquilibriumNetworks.jl \u2013 Continuous and Discrete Deep Equilibrium Networks DiffEqFlux.jl \u2013 Neural Differential Equations, Continuous Normalizing Flows, etc.","title":"Frameworks extending Lux"},{"location":"introduction/ecosystem/#extended-julia-ecosystem","text":"As you might have noticed we don't do much apart from Neural Networks. All other parts of the DL training/evaluation pipeline should be offloaded to:","title":"Extended Julia Ecosystem"},{"location":"introduction/ecosystem/#automatic-differentiation","text":"Zygote.jl \u2013 Currently the default and recommended AD library Enzyme.jl \u2013 Experimental Support (but will most likely become the future default) ForwardDiff.jl \u2013 For forward mode AD support ReverseDiff.jl \u2013 Tape based reverse mode AD (mostly untested)","title":"Automatic Differentiation"},{"location":"introduction/ecosystem/#data-manipulation-and-loading","text":"Augmentor.jl DataLoaders.jl Images.jl DataAugmentation.jl","title":"Data Manipulation and Loading"},{"location":"introduction/ecosystem/#distributed-dataparallel-training","text":"FluxMPI.jl","title":"Distributed DataParallel Training"},{"location":"introduction/ecosystem/#neural-network-primitives","text":"NNlib.jl","title":"Neural Network Primitives"},{"location":"introduction/ecosystem/#optimisation","text":"Optimisers.jl ParameterSchedulers.jl Optimization.jl","title":"Optimisation"},{"location":"introduction/ecosystem/#parameter-manipulation","text":"Functors.jl","title":"Parameter Manipulation"},{"location":"introduction/ecosystem/#serialization","text":"Serialization.jl JLD2.jl","title":"Serialization"},{"location":"introduction/ecosystem/#testing-utilities","text":"FiniteDifferences.jl \u2013 Finite Differencing. Useful for testing gradient correctness JET.jl","title":"Testing Utilities"},{"location":"introduction/ecosystem/#training-visualization-logging","text":"Wandb.jl TensorBoardLogger.jl","title":"Training Visualization &amp; Logging"},{"location":"introduction/overview/","text":"Why we wrote Lux? \u00a4 Julia already has quite a few well established Neural Network Frameworks \u2013 Flux & KNet . However, certain design elements \u2013 Coupled Model and Parameters & Internal Mutations \u2013 associated with these frameworks make them less compiler and user friendly. Making changes to address these problems in the respective frameworks would be too disruptive for users. Here comes in Lux : a neural network framework built completely using pure functions to make it both compiler and autodiff friendly. Design Principles \u00a4 Layers must be immutable \u2013 cannot store any parameter/state but rather store the information to construct them Layers are pure functions Layers return a Tuple containing the result and the updated state Given same inputs the outputs must be same \u2013 yes this must hold true even for stochastic functions. Randomness must be controlled using rng s passed in the state. Easily extensible Why use Lux over Flux? \u00a4 Neural Networks for SciML : For SciML Applications (Neural ODEs, Deep Equilibrium Models) solvers typically expect a monolithic parameter vector. Flux enables this via its destructure mechanism, but destructure comes with various edge cases and limitations . Lux forces users to make an explicit distinction between state variables and parameter variables to avoid these issues. Also, it comes battery-included for distributed training using FluxMPI.jl (I know :P the naming) Sensible display of Custom Layers \u2013 Ever wanted to see Pytorch like Network printouts or wondered how to extend the pretty printing of Flux's layers? Lux handles all of that by default. Truly immutable models - No unexpected internal mutations since all layers are implemented as pure functions. All layers are also deterministic given the parameters and state: if a layer is supposed to be stochastic (say Dropout ), the state must contain a seed which is then updated after the function call. Easy Parameter Manipulation \u2013 By separating parameter data and layer structures, Lux makes implementing WeightNorm , SpectralNorm , etc. downright trivial. Without this separation, it is much harder to pass such parameters around without mutations which AD systems don't like. Why not use Lux? \u00a4 Small Neural Networks on CPU \u2013 Lux is developed for training large neural networks. For smaller architectures, we recommend using SimpleChains.jl . Lux won't magically speed up your code (yet) \u2013 Lux shares the same backend with Flux and so if your primary desire to shift is driven by performance, you will be disappointed. Special Architecture Support \u2013 Unfortunately, we currently don't support Cloud TPUs and even AMD GPUs are not well tested. (We do plan to support these in the nearish future)","title":"All about Lux"},{"location":"introduction/overview/#why-we-wrote-lux","text":"Julia already has quite a few well established Neural Network Frameworks \u2013 Flux & KNet . However, certain design elements \u2013 Coupled Model and Parameters & Internal Mutations \u2013 associated with these frameworks make them less compiler and user friendly. Making changes to address these problems in the respective frameworks would be too disruptive for users. Here comes in Lux : a neural network framework built completely using pure functions to make it both compiler and autodiff friendly.","title":"Why we wrote Lux?"},{"location":"introduction/overview/#design-principles","text":"Layers must be immutable \u2013 cannot store any parameter/state but rather store the information to construct them Layers are pure functions Layers return a Tuple containing the result and the updated state Given same inputs the outputs must be same \u2013 yes this must hold true even for stochastic functions. Randomness must be controlled using rng s passed in the state. Easily extensible","title":"Design Principles"},{"location":"introduction/overview/#why-use-lux-over-flux","text":"Neural Networks for SciML : For SciML Applications (Neural ODEs, Deep Equilibrium Models) solvers typically expect a monolithic parameter vector. Flux enables this via its destructure mechanism, but destructure comes with various edge cases and limitations . Lux forces users to make an explicit distinction between state variables and parameter variables to avoid these issues. Also, it comes battery-included for distributed training using FluxMPI.jl (I know :P the naming) Sensible display of Custom Layers \u2013 Ever wanted to see Pytorch like Network printouts or wondered how to extend the pretty printing of Flux's layers? Lux handles all of that by default. Truly immutable models - No unexpected internal mutations since all layers are implemented as pure functions. All layers are also deterministic given the parameters and state: if a layer is supposed to be stochastic (say Dropout ), the state must contain a seed which is then updated after the function call. Easy Parameter Manipulation \u2013 By separating parameter data and layer structures, Lux makes implementing WeightNorm , SpectralNorm , etc. downright trivial. Without this separation, it is much harder to pass such parameters around without mutations which AD systems don't like.","title":"Why use Lux over Flux?"},{"location":"introduction/overview/#why-not-use-lux","text":"Small Neural Networks on CPU \u2013 Lux is developed for training large neural networks. For smaller architectures, we recommend using SimpleChains.jl . Lux won't magically speed up your code (yet) \u2013 Lux shares the same backend with Flux and so if your primary desire to shift is driven by performance, you will be disappointed. Special Architecture Support \u2013 Unfortunately, we currently don't support Cloud TPUs and even AMD GPUs are not well tested. (We do plan to support these in the nearish future)","title":"Why not use Lux?"},{"location":"lib/Boltz/","text":"Boltz \u26a1 \u00a4 Accelerate \u26a1 your ML research using pre-built Deep Learning Models with Lux. Installation \u00a4 using Pkg Pkg . add ( \"Boltz\" ) Getting Started \u00a4 using Boltz , Lux model , ps , st = resnet ( :resnet18 ; pretrained = true ) Classification Models \u00a4 MODEL NAME FUNCTION NAME PRETRAINED TOP 1 ACCURACY (%) TOP 5 ACCURACY (%) AlexNet alexnet :alexnet \u2705 54.48 77.72 ResNet resnet :resnet18 \u2705 68.08 88.44 ResNet resnet :resnet34 \u2705 72.13 90.91 ResNet resnet :resnet50 \u2705 74.55 92.36 ResNet resnet :resnet101 \u2705 74.81 92.36 ResNet resnet :resnet152 \u2705 77.63 93.84 VGG vgg :vgg11 \u2705 67.35 87.91 VGG vgg :vgg13 \u2705 68.40 88.48 VGG vgg :vgg16 \u2705 70.24 89.80 VGG vgg :vgg19 \u2705 71.09 90.27 VGG vgg :vgg11_bn \u2705 69.09 88.94 VGG vgg :vgg13_bn \u2705 69.66 89.49 VGG vgg :vgg16_bn \u2705 72.11 91.02 VGG vgg :vgg19_bn \u2705 72.95 91.32 ConvMixer convmixer :small \ud83d\udeab ConvMixer convmixer :base \ud83d\udeab ConvMixer convmixer :large \ud83d\udeab DenseNet densenet :densenet121 \ud83d\udeab DenseNet densenet :densenet161 \ud83d\udeab DenseNet densenet :densenet169 \ud83d\udeab DenseNet densenet :densenet201 \ud83d\udeab GoogleNet googlenet :googlenet \ud83d\udeab MobileNet mobilenet :mobilenet_v1 \ud83d\udeab MobileNet mobilenet :mobilenet_v2 \ud83d\udeab MobileNet mobilenet :mobilenet_v3_small \ud83d\udeab MobileNet mobilenet :mobilenet_v3_large \ud83d\udeab ResNeXT resnext :resnext50 \ud83d\udeab ResNeXT resnext :resnext101 \ud83d\udeab ResNeXT resnext :resnext152 \ud83d\udeab Vision Transformer vision_transformer :tiny \ud83d\udeab Vision Transformer vision_transformer :small \ud83d\udeab Vision Transformer vision_transformer :base \ud83d\udeab Vision Transformer vision_transformer :large \ud83d\udeab Vision Transformer vision_transformer :huge \ud83d\udeab Vision Transformer vision_transformer :giant \ud83d\udeab Vision Transformer vision_transformer :gigantic \ud83d\udeab These models can be created using <FUNCTION>(<NAME>; pretrained = <PRETRAINED>) . Preprocessing \u00a4 All the pretrained models require that the images be normalized with the parameters mean = [0.485f0, 0.456f0, 0.406f0] and std = [0.229f0, 0.224f0, 0.225f0] .","title":"Boltz"},{"location":"lib/Boltz/#boltz","text":"Accelerate \u26a1 your ML research using pre-built Deep Learning Models with Lux.","title":"Boltz \u26a1"},{"location":"lib/Boltz/#installation","text":"using Pkg Pkg . add ( \"Boltz\" )","title":"Installation"},{"location":"lib/Boltz/#getting-started","text":"using Boltz , Lux model , ps , st = resnet ( :resnet18 ; pretrained = true )","title":"Getting Started"},{"location":"lib/Boltz/#classification-models","text":"MODEL NAME FUNCTION NAME PRETRAINED TOP 1 ACCURACY (%) TOP 5 ACCURACY (%) AlexNet alexnet :alexnet \u2705 54.48 77.72 ResNet resnet :resnet18 \u2705 68.08 88.44 ResNet resnet :resnet34 \u2705 72.13 90.91 ResNet resnet :resnet50 \u2705 74.55 92.36 ResNet resnet :resnet101 \u2705 74.81 92.36 ResNet resnet :resnet152 \u2705 77.63 93.84 VGG vgg :vgg11 \u2705 67.35 87.91 VGG vgg :vgg13 \u2705 68.40 88.48 VGG vgg :vgg16 \u2705 70.24 89.80 VGG vgg :vgg19 \u2705 71.09 90.27 VGG vgg :vgg11_bn \u2705 69.09 88.94 VGG vgg :vgg13_bn \u2705 69.66 89.49 VGG vgg :vgg16_bn \u2705 72.11 91.02 VGG vgg :vgg19_bn \u2705 72.95 91.32 ConvMixer convmixer :small \ud83d\udeab ConvMixer convmixer :base \ud83d\udeab ConvMixer convmixer :large \ud83d\udeab DenseNet densenet :densenet121 \ud83d\udeab DenseNet densenet :densenet161 \ud83d\udeab DenseNet densenet :densenet169 \ud83d\udeab DenseNet densenet :densenet201 \ud83d\udeab GoogleNet googlenet :googlenet \ud83d\udeab MobileNet mobilenet :mobilenet_v1 \ud83d\udeab MobileNet mobilenet :mobilenet_v2 \ud83d\udeab MobileNet mobilenet :mobilenet_v3_small \ud83d\udeab MobileNet mobilenet :mobilenet_v3_large \ud83d\udeab ResNeXT resnext :resnext50 \ud83d\udeab ResNeXT resnext :resnext101 \ud83d\udeab ResNeXT resnext :resnext152 \ud83d\udeab Vision Transformer vision_transformer :tiny \ud83d\udeab Vision Transformer vision_transformer :small \ud83d\udeab Vision Transformer vision_transformer :base \ud83d\udeab Vision Transformer vision_transformer :large \ud83d\udeab Vision Transformer vision_transformer :huge \ud83d\udeab Vision Transformer vision_transformer :giant \ud83d\udeab Vision Transformer vision_transformer :gigantic \ud83d\udeab These models can be created using <FUNCTION>(<NAME>; pretrained = <PRETRAINED>) .","title":"Classification Models"},{"location":"lib/Boltz/#preprocessing","text":"All the pretrained models require that the images be normalized with the parameters mean = [0.485f0, 0.456f0, 0.406f0] and std = [0.229f0, 0.224f0, 0.225f0] .","title":"Preprocessing"},{"location":"lib/LuxLib/","text":"LuxLib \u00a4 Backend for Lux.jl . Tutorials \u00a4 This is a developer-facing project and most users should not depend on it directly. As such, we don't have tutorials for this package. Instead, we recommend you check out the Lux tutorials . What's the distinction from NNlib.jl? \u00a4 Think of this package as a temporary location for functionalities that will move into NNlib.jl. At the moment, this is supposed to be a heavier dependency than NNlib.jl, and it makes no attempt to separate code across different architectures.","title":"Introduction"},{"location":"lib/LuxLib/#luxlib","text":"Backend for Lux.jl .","title":"LuxLib"},{"location":"lib/LuxLib/#tutorials","text":"This is a developer-facing project and most users should not depend on it directly. As such, we don't have tutorials for this package. Instead, we recommend you check out the Lux tutorials .","title":"Tutorials"},{"location":"lib/LuxLib/#whats-the-distinction-from-nnlibjl","text":"Think of this package as a temporary location for functionalities that will move into NNlib.jl. At the moment, this is supposed to be a heavier dependency than NNlib.jl, and it makes no attempt to separate code across different architectures.","title":"What's the distinction from NNlib.jl?"},{"location":"lib/LuxLib/api/","text":"Dropout \u00a4 # LuxLib.dropout \u2014 Function . dropout ( rng :: AbstractRNG , x , p , :: Val { training }; dims , invp = inv ( p )) dropout ( rng :: AbstractRNG , x , mask , p , :: Val { training }, :: Val { update_mask }; dims , invp = inv ( p )) Dropout: Simple Way to prevent Neural Networks for Overfitting. For details see [1]. Arguments rng : Random number generator x : Input Array mask : Dropout Mask. If not used then it is constructed automatically p : Probability of an element to be dropped out Val(training) : If true then dropout is applied on x with probability p along dims . Else, x is returned Val(update_mask) : If true then the mask is generated and used. Else, the mask provided is directly used Keyword Arguments dims : Dimensions along which dropout is applied invp : Inverse of the probability ( \\(\\frac{1}{p}\\) ) Returns Output Array after applying dropout Dropout Mask (if training == false , the returned value is meaningless) Updated state for the random number generator References [1] Srivastava, Nitish, et al. \"Dropout: a simple way to prevent neural networks from overfitting.\" The journal of machine learning research 15.1 (2014): 1929-1958. source Normalization \u00a4 # LuxLib.batchnorm \u2014 Function . batchnorm ( x , scale , bias , running_mean , running_var ; momentum , epsilon , training ) Batch Normalization. For details see [1]. Batch Normalization computes the mean and variance for each `D_1 \\times ... \\times D_{N - 2} \\times 1 \\times D_N input slice and normalises the input accordingly. Arguments x : Input to be Normalized scale : Scale factor ( \\(\\gamma\\) ) (can be nothing ) bias : Bias factor ( \\(\\beta\\) ) (can be nothing ) running_mean : Running mean (can be nothing ) running_var : Running variance (can be nothing ) Keyword Arguments momentum : Momentum for updating running mean and variance epsilon : Value added to the denominator for numerical stability training : Set to Val(true) if running in training mode Returns Normalized Array of same size as x . And a Named Tuple containing the updated running mean and variance. Performance Considerations If the input array is 2D , 4D , or 5D CuArray with element types Float16 , Float32 and Float64 , then the CUDNN code path will be used. In all other cases, a broadcasting fallback is used which is not highly optimized. References [1] Ioffe, Sergey, and Christian Szegedy. \"Batch normalization: Accelerating deep network training by reducing internal covariate shift.\" International conference on machine learning. PMLR, 2015. source # LuxLib.groupnorm \u2014 Function . groupnorm ( x , scale , bias ; groups , epsilon ) groupnorm ( x , scale , bias , running_mean , running_var ; groups , momentum , training , epsilon ) Group Normalization. For details see [1]. This op is similar to batch normalization, but statistics are shared across equally-sized groups of channels and not shared across batch dimension. Thus, group normalization does not depend on the batch composition and does not require maintaining internal state for storing statistics. Arguments x : Input to be Normalized scale : Scale factor ( \\(\\gamma\\) ) (can be nothing ) bias : Bias factor ( \\(\\beta\\) ) (can be nothing ) running_mean : Running mean of the inputs. Must be an AbstractVector or nothing . running_var : Running variance of the inputs. Must be an AbstractVector or nothing . Keyword Arguments groups : Number of groups momentum : Momentum for updating running mean and variance. training : Set to Val(true) if running in training mode. epsilon : Value added to the denominator for numerical stability Returns If using the first function signature, then the only the normalized array is returned. Otherwise, the normalized array and a named tuple containing updated running mean and updated running variance are returned. Additional Notes running_mean , running_var , momentum , and training exist only for backwards compatibility reasons. There is no well documented evidence in literature that tracking statistics for group normalization actually helps. It is recommended to not use these arguments at all. Performance Considerations The most common case of this Op \u2013 x is a 4D array and there is no statistics tracking \u2013 is optimized using KernelAbstractions and has a fast custom backwards pass implemented. All other cases have a fallback implementation which is not especially optimized. Additionally, if the element types of x , scale , and bias are not same and not one of Float32 and Float64 , then the Op uses the slower fallback implementation. We have tested the code path for Float16 and it works, but gradient accumulation is extremely fragile. Hence, for Float16 inputs, it uses the fallback implementation. If the batch size is small (< 16), then the fallback implementation will be faster than the KA version. However, this customization is not possible using the direct groupnorm interface. References [1] Wu, Yuxin, and Kaiming He. \"Group normalization.\" Proceedings of the European conference on computer vision (ECCV). 2018. source # LuxLib.layernorm \u2014 Function . layernorm ( x , scale , bias ; dims , epsilon ) Layer Normalization. For details see [1]. Given an input array \\(x\\) , this layer computes \\[ y = \\frac{x - \\mathbb{E}[x]}{\\sqrt{Var[x] + \\epsilon}} * \\gamma + \\beta \\] Arguments x : Input to be Normalized scale : Scale factor ( \\(\\gamma\\) ) (can be nothing ) bias : Bias factor ( \\(\\beta\\) ) (can be nothing ) Keyword Arguments dims : Dimensions along which the mean and std of x is computed epsilon : Value added to the denominator for numerical stability Returns Normalized Array of same size as x . References [1] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \"Layer normalization.\" arXiv preprint arXiv:1607.06450 (2016). source Index \u00a4 LuxLib.batchnorm LuxLib.dropout LuxLib.groupnorm LuxLib.layernorm","title":"API Reference"},{"location":"lib/LuxLib/api/#dropout","text":"# LuxLib.dropout \u2014 Function . dropout ( rng :: AbstractRNG , x , p , :: Val { training }; dims , invp = inv ( p )) dropout ( rng :: AbstractRNG , x , mask , p , :: Val { training }, :: Val { update_mask }; dims , invp = inv ( p )) Dropout: Simple Way to prevent Neural Networks for Overfitting. For details see [1]. Arguments rng : Random number generator x : Input Array mask : Dropout Mask. If not used then it is constructed automatically p : Probability of an element to be dropped out Val(training) : If true then dropout is applied on x with probability p along dims . Else, x is returned Val(update_mask) : If true then the mask is generated and used. Else, the mask provided is directly used Keyword Arguments dims : Dimensions along which dropout is applied invp : Inverse of the probability ( \\(\\frac{1}{p}\\) ) Returns Output Array after applying dropout Dropout Mask (if training == false , the returned value is meaningless) Updated state for the random number generator References [1] Srivastava, Nitish, et al. \"Dropout: a simple way to prevent neural networks from overfitting.\" The journal of machine learning research 15.1 (2014): 1929-1958. source","title":"Dropout"},{"location":"lib/LuxLib/api/#normalization","text":"# LuxLib.batchnorm \u2014 Function . batchnorm ( x , scale , bias , running_mean , running_var ; momentum , epsilon , training ) Batch Normalization. For details see [1]. Batch Normalization computes the mean and variance for each `D_1 \\times ... \\times D_{N - 2} \\times 1 \\times D_N input slice and normalises the input accordingly. Arguments x : Input to be Normalized scale : Scale factor ( \\(\\gamma\\) ) (can be nothing ) bias : Bias factor ( \\(\\beta\\) ) (can be nothing ) running_mean : Running mean (can be nothing ) running_var : Running variance (can be nothing ) Keyword Arguments momentum : Momentum for updating running mean and variance epsilon : Value added to the denominator for numerical stability training : Set to Val(true) if running in training mode Returns Normalized Array of same size as x . And a Named Tuple containing the updated running mean and variance. Performance Considerations If the input array is 2D , 4D , or 5D CuArray with element types Float16 , Float32 and Float64 , then the CUDNN code path will be used. In all other cases, a broadcasting fallback is used which is not highly optimized. References [1] Ioffe, Sergey, and Christian Szegedy. \"Batch normalization: Accelerating deep network training by reducing internal covariate shift.\" International conference on machine learning. PMLR, 2015. source # LuxLib.groupnorm \u2014 Function . groupnorm ( x , scale , bias ; groups , epsilon ) groupnorm ( x , scale , bias , running_mean , running_var ; groups , momentum , training , epsilon ) Group Normalization. For details see [1]. This op is similar to batch normalization, but statistics are shared across equally-sized groups of channels and not shared across batch dimension. Thus, group normalization does not depend on the batch composition and does not require maintaining internal state for storing statistics. Arguments x : Input to be Normalized scale : Scale factor ( \\(\\gamma\\) ) (can be nothing ) bias : Bias factor ( \\(\\beta\\) ) (can be nothing ) running_mean : Running mean of the inputs. Must be an AbstractVector or nothing . running_var : Running variance of the inputs. Must be an AbstractVector or nothing . Keyword Arguments groups : Number of groups momentum : Momentum for updating running mean and variance. training : Set to Val(true) if running in training mode. epsilon : Value added to the denominator for numerical stability Returns If using the first function signature, then the only the normalized array is returned. Otherwise, the normalized array and a named tuple containing updated running mean and updated running variance are returned. Additional Notes running_mean , running_var , momentum , and training exist only for backwards compatibility reasons. There is no well documented evidence in literature that tracking statistics for group normalization actually helps. It is recommended to not use these arguments at all. Performance Considerations The most common case of this Op \u2013 x is a 4D array and there is no statistics tracking \u2013 is optimized using KernelAbstractions and has a fast custom backwards pass implemented. All other cases have a fallback implementation which is not especially optimized. Additionally, if the element types of x , scale , and bias are not same and not one of Float32 and Float64 , then the Op uses the slower fallback implementation. We have tested the code path for Float16 and it works, but gradient accumulation is extremely fragile. Hence, for Float16 inputs, it uses the fallback implementation. If the batch size is small (< 16), then the fallback implementation will be faster than the KA version. However, this customization is not possible using the direct groupnorm interface. References [1] Wu, Yuxin, and Kaiming He. \"Group normalization.\" Proceedings of the European conference on computer vision (ECCV). 2018. source # LuxLib.layernorm \u2014 Function . layernorm ( x , scale , bias ; dims , epsilon ) Layer Normalization. For details see [1]. Given an input array \\(x\\) , this layer computes \\[ y = \\frac{x - \\mathbb{E}[x]}{\\sqrt{Var[x] + \\epsilon}} * \\gamma + \\beta \\] Arguments x : Input to be Normalized scale : Scale factor ( \\(\\gamma\\) ) (can be nothing ) bias : Bias factor ( \\(\\beta\\) ) (can be nothing ) Keyword Arguments dims : Dimensions along which the mean and std of x is computed epsilon : Value added to the denominator for numerical stability Returns Normalized Array of same size as x . References [1] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \"Layer normalization.\" arXiv preprint arXiv:1607.06450 (2016). source","title":"Normalization"},{"location":"lib/LuxLib/api/#index","text":"LuxLib.batchnorm LuxLib.dropout LuxLib.groupnorm LuxLib.layernorm","title":"Index"},{"location":"manual/dispatch_custom_inputs/","text":"Dispatching on Custom Input Types \u00a4 Which function should participate in dispatch? \u00a4 Defining a dispatch on (::Layer)(x::MyInputType, ps, st::NamedTuple) is inconvenient, since it requires the user to define a new method for every layer type. (::AbstractExplicitLayer)(x::MyInputType, ps, st::NamedTuple) doesn't work. Instead, we need to define the dispatch on Lux.apply(::AbstractExplicitLayer, x::MyInputType, ps, st::NamedTuple) . Concrete Example \u00a4 Consider Neural ODEs . In these models, often time we want to every iteration of the neural network to take the current time as input. Here, we won't go through implementing an entire Neural ODE model. Instead we will define a time dependent version of Chain . Time-Dependent Chain Implementation \u00a4 using Lux , Random struct TDChain { L <: NamedTuple } <: Lux . AbstractExplicitContainerLayer {( :layers ,)} layers :: L end function ( l :: TDChain )(( x , t ) :: Tuple , ps , st :: NamedTuple ) # Concatenate along the 2nd last dimension sz = ntuple ( i -> i == ndims ( x ) - 1 ? 1 : size ( x , i ), ndims ( x )) t_ = ones ( eltype ( x ), sz ) .* t # Needs to be modified for GPU for name in keys ( l . layers ) x , st_ = Lux . apply ( getfield ( l . layers , name ), cat ( x , t_ ; dims = ndims ( x ) - 1 ), getfield ( ps , name ), getfield ( st , name )) st = merge ( st , NamedTuple {( name ,)}(( st_ ,))) end return x , st end model = Chain ( Dense ( 3 , 4 ), TDChain ((; d1 = Dense ( 5 , 4 ), d2 = Dense ( 5 , 4 ))), Dense ( 4 , 1 )) Chain( layer_1 = Dense(3 => 4), # 16 parameters layer_2 = TDChain( layers = (d1 = Dense(5 => 4), d2 = Dense(5 => 4)), # 48 parameters ), layer_3 = Dense(4 => 1), # 5 parameters ) # Total: 69 parameters, # plus 0 states, summarysize 64 bytes. Running the TDChain \u00a4 rng = MersenneTwister ( 0 ) ps , st = Lux . setup ( rng , model ) x = randn ( rng , Float32 , 3 , 2 ) # model(x, ps, st) 3\u00d72 Matrix{Float32}: 0.473714 1.42305 0.300234 0.408387 -0.762677 0.588621 The last line is commented out, since it will not work. Try uncommenting it and see what happens. Dispatching on Custom Input Types \u00a4 Create a Custom Layer storing the time. struct ArrayAndTime { A <: AbstractArray , T <: Real } array :: A time :: T end Define the dispatch on Lux.apply(::AbstractExplicitLayer, x::ArrayAndTime, ps, st::NamedTuple) . function Lux . apply ( layer :: Lux . AbstractExplicitLayer , x :: ArrayAndTime , ps , st :: NamedTuple ) y , st = layer ( x . array , ps , st ) return ArrayAndTime ( y , x . time ), st end function Lux . apply ( layer :: TDChain , x :: ArrayAndTime , ps , st :: NamedTuple ) y , st = layer (( x . array , x . time ), ps , st ) return ArrayAndTime ( y , x . time ), st end Run the model. xt = ArrayAndTime ( x , 10.0f0 ) model ( xt , ps , st )[ 1 ] Main.ArrayAndTime{Matrix{Float32}, Float32}(Float32[4.8016562 5.174927], 10.0f0) Using the same input for non-TD models \u00a4 Writing proper dispatch means we can simple replace the TDChain with a Chain (of course with dimension corrections) and the pipeline still works. model = Chain ( Dense ( 3 , 4 ), Chain ((; d1 = Dense ( 4 , 4 ), d2 = Dense ( 4 , 4 ))), Dense ( 4 , 1 )) ps , st = Lux . setup ( rng , model ) model ( xt , ps , st )[ 1 ] Main.ArrayAndTime{Matrix{Float32}, Float32}(Float32[-0.08124366 -1.1121564], 10.0f0)","title":"Dispatch on Custom Inputs"},{"location":"manual/dispatch_custom_inputs/#dispatching-on-custom-input-types","text":"","title":"Dispatching on Custom Input Types"},{"location":"manual/dispatch_custom_inputs/#which-function-should-participate-in-dispatch","text":"Defining a dispatch on (::Layer)(x::MyInputType, ps, st::NamedTuple) is inconvenient, since it requires the user to define a new method for every layer type. (::AbstractExplicitLayer)(x::MyInputType, ps, st::NamedTuple) doesn't work. Instead, we need to define the dispatch on Lux.apply(::AbstractExplicitLayer, x::MyInputType, ps, st::NamedTuple) .","title":"Which function should participate in dispatch?"},{"location":"manual/dispatch_custom_inputs/#concrete-example","text":"Consider Neural ODEs . In these models, often time we want to every iteration of the neural network to take the current time as input. Here, we won't go through implementing an entire Neural ODE model. Instead we will define a time dependent version of Chain .","title":"Concrete Example"},{"location":"manual/dispatch_custom_inputs/#time-dependent-chain-implementation","text":"using Lux , Random struct TDChain { L <: NamedTuple } <: Lux . AbstractExplicitContainerLayer {( :layers ,)} layers :: L end function ( l :: TDChain )(( x , t ) :: Tuple , ps , st :: NamedTuple ) # Concatenate along the 2nd last dimension sz = ntuple ( i -> i == ndims ( x ) - 1 ? 1 : size ( x , i ), ndims ( x )) t_ = ones ( eltype ( x ), sz ) .* t # Needs to be modified for GPU for name in keys ( l . layers ) x , st_ = Lux . apply ( getfield ( l . layers , name ), cat ( x , t_ ; dims = ndims ( x ) - 1 ), getfield ( ps , name ), getfield ( st , name )) st = merge ( st , NamedTuple {( name ,)}(( st_ ,))) end return x , st end model = Chain ( Dense ( 3 , 4 ), TDChain ((; d1 = Dense ( 5 , 4 ), d2 = Dense ( 5 , 4 ))), Dense ( 4 , 1 )) Chain( layer_1 = Dense(3 => 4), # 16 parameters layer_2 = TDChain( layers = (d1 = Dense(5 => 4), d2 = Dense(5 => 4)), # 48 parameters ), layer_3 = Dense(4 => 1), # 5 parameters ) # Total: 69 parameters, # plus 0 states, summarysize 64 bytes.","title":"Time-Dependent Chain Implementation"},{"location":"manual/dispatch_custom_inputs/#running-the-tdchain","text":"rng = MersenneTwister ( 0 ) ps , st = Lux . setup ( rng , model ) x = randn ( rng , Float32 , 3 , 2 ) # model(x, ps, st) 3\u00d72 Matrix{Float32}: 0.473714 1.42305 0.300234 0.408387 -0.762677 0.588621 The last line is commented out, since it will not work. Try uncommenting it and see what happens.","title":"Running the TDChain"},{"location":"manual/dispatch_custom_inputs/#dispatching-on-custom-input-types_1","text":"Create a Custom Layer storing the time. struct ArrayAndTime { A <: AbstractArray , T <: Real } array :: A time :: T end Define the dispatch on Lux.apply(::AbstractExplicitLayer, x::ArrayAndTime, ps, st::NamedTuple) . function Lux . apply ( layer :: Lux . AbstractExplicitLayer , x :: ArrayAndTime , ps , st :: NamedTuple ) y , st = layer ( x . array , ps , st ) return ArrayAndTime ( y , x . time ), st end function Lux . apply ( layer :: TDChain , x :: ArrayAndTime , ps , st :: NamedTuple ) y , st = layer (( x . array , x . time ), ps , st ) return ArrayAndTime ( y , x . time ), st end Run the model. xt = ArrayAndTime ( x , 10.0f0 ) model ( xt , ps , st )[ 1 ] Main.ArrayAndTime{Matrix{Float32}, Float32}(Float32[4.8016562 5.174927], 10.0f0)","title":"Dispatching on Custom Input Types"},{"location":"manual/dispatch_custom_inputs/#using-the-same-input-for-non-td-models","text":"Writing proper dispatch means we can simple replace the TDChain with a Chain (of course with dimension corrections) and the pipeline still works. model = Chain ( Dense ( 3 , 4 ), Chain ((; d1 = Dense ( 4 , 4 ), d2 = Dense ( 4 , 4 ))), Dense ( 4 , 1 )) ps , st = Lux . setup ( rng , model ) model ( xt , ps , st )[ 1 ] Main.ArrayAndTime{Matrix{Float32}, Float32}(Float32[-0.08124366 -1.1121564], 10.0f0)","title":"Using the same input for non-TD models"},{"location":"manual/freezing_parameters/","text":"Freezing Model Parameters \u00a4 Warning API for freezing parameters should be considered experimental at this point. In this manual we will go over how to freeze certain parameters in a model. Freezing layers of a particular kind \u00a4 To freeze a particular kind of layer, let's say Dense in the following example. We can use Lux.@layer_map and freeze layers if they are of type Dense . using Lux , Random rng = Random . default_rng () Random . seed! ( rng , 0 ) model = Chain ( Dense ( 3 , 4 ), Chain ( Dense ( 4 , 4 ), Dropout ( 0.5f0 ), BatchNorm ( 4 )), Dense ( 4 , 1 ); disable_optimizations = true ) ps , st = Lux . setup ( rng , model ) x = randn ( rng , Float32 , 3 , 2 ) model ( x , ps , st ) function freeze_dense ( d :: Lux . Dense , ps , st , name :: String ) return Lux . freeze ( d , ps , st , ( :weight , :bias )) end freeze_dense ( l , ps , st , name ) = ( l , ps , st ) model_frozen , ps_frozen , st_frozen = Lux . @layer_map freeze_dense model ps st model_frozen ( x , ps_frozen , st_frozen ) (Float32[1.7641534 -1.7641534], (layer_1 = (frozen_params = (weight = Float32[-0.026350189 -0.5554656 -0.35653266; -0.17461072 0.6705545 0.29924855; -0.8935247 -0.42453378 -0.3020351; -0.7988979 -0.7666331 -0.7104237], bias = Float32[0.0; 0.0; 0.0; 0.0;;]), states = NamedTuple()), layer_2 = (layer_1 = (frozen_params = (weight = Float32[-0.47289538 -0.680748 0.1764085 0.34383082; 0.42747158 -0.13819042 -0.109261915 -0.6143286; -0.35790488 -0.20881107 0.70390546 0.48137343; 0.82561636 0.38187847 0.05779423 -0.35181466], bias = Float32[0.0; 0.0; 0.0; 0.0;;]), states = NamedTuple()), layer_2 = (rng = Random.Xoshiro(0x87711e5ce1a49ffe, 0xa210b60ecab6b8c5, 0x436c749552fc8172, 0x03e9c7d813a9f096), training = Val{true}()), layer_3 = (running_mean = Float32[-0.04517859, 0.03484953, -0.004917746, 0.0074841487], running_var = Float32[0.94082206, 0.92428976, 0.90048367, 0.90112025], training = Val{true}())), layer_3 = (frozen_params = (weight = Float32[0.3981135 0.45468387 -0.07694905 0.8353388], bias = Float32[0.0;;]), states = NamedTuple()))) Freezing by layer name \u00a4 When the function in layer_map is called, the 4th argument is the name of the layer. For example, if you want to freeze the 1st layer inside the inner Chain. The name for this would be <model>.layer_2.layer_1 . Freezing by layer name Freezing by layer type function freeze_by_name ( d , ps , st , name :: String ) if name == \"model.layer_2.layer_1\" return Lux . freeze ( d , ps , st , ( :weight , :bias )) else return d , ps , st end end function freeze_dense ( d :: Dense , ps , st , name :: String ) return Lux . freeze ( d , ps , st , ( :weight , :bias )) end freeze_dense ( l , ps , st , name ) = ( l , ps , st ) Freezing part of the parameters \u00a4 Instead of freezing all the parameters, we can simple specify (:weight,) to freeze only the weight parameter while training the bias parameter. Freezing some parameters of a layer Freezing all parameters of a layer function freeze_by_name ( d , ps , st , name :: String ) if name == \"model.layer_2.layer_1\" return Lux . freeze ( d , ps , st , ( :weight ,)) else return d , ps , st end end function freeze_by_name ( d , ps , st , name :: String ) if name == \"model.layer_2.layer_1\" return Lux . freeze ( d , ps , st , ( :weight , :bias )) else return d , ps , st end end Freezing part of a Chain \u00a4 Starting v0.4.22 , we can directly index into a Chain . So freezing a part of a Chain , is extremely easy. using Lux , Random rng = Random . default_rng () Random . seed! ( rng , 0 ) model = Chain ( Dense ( 3 , 4 ), Dense ( 4 , 4 ), Dropout ( 0.5f0 ), BatchNorm ( 4 ), Dense ( 4 , 1 )) model_frozen = Chain ( model [ 1 : 2 ], Lux . freeze ( model [ 3 : 4 ]), model [ 5 ]) ps , st = Lux . setup ( rng , model_frozen ) x = randn ( rng , Float32 , 3 , 2 ) model_frozen ( x , ps , st ) (Float32[1.7641534 -1.7641534], (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = (frozen_params = (layer_3 = NamedTuple(), layer_4 = (scale = Float32[1.0, 1.0, 1.0, 1.0], bias = Float32[0.0, 0.0, 0.0, 0.0])), states = (layer_3 = (rng = Random.Xoshiro(0x87711e5ce1a49ffe, 0xa210b60ecab6b8c5, 0x436c749552fc8172, 0x03e9c7d813a9f096), training = Val{true}()), layer_4 = (running_mean = Float32[-0.04517859, 0.03484953, -0.004917746, 0.0074841487], running_var = Float32[0.94082206, 0.92428976, 0.90048367, 0.90112025], training = Val{true}()))), layer_4 = NamedTuple()))","title":"Freezing Model Parameters"},{"location":"manual/freezing_parameters/#freezing-model-parameters","text":"Warning API for freezing parameters should be considered experimental at this point. In this manual we will go over how to freeze certain parameters in a model.","title":"Freezing Model Parameters"},{"location":"manual/freezing_parameters/#freezing-layers-of-a-particular-kind","text":"To freeze a particular kind of layer, let's say Dense in the following example. We can use Lux.@layer_map and freeze layers if they are of type Dense . using Lux , Random rng = Random . default_rng () Random . seed! ( rng , 0 ) model = Chain ( Dense ( 3 , 4 ), Chain ( Dense ( 4 , 4 ), Dropout ( 0.5f0 ), BatchNorm ( 4 )), Dense ( 4 , 1 ); disable_optimizations = true ) ps , st = Lux . setup ( rng , model ) x = randn ( rng , Float32 , 3 , 2 ) model ( x , ps , st ) function freeze_dense ( d :: Lux . Dense , ps , st , name :: String ) return Lux . freeze ( d , ps , st , ( :weight , :bias )) end freeze_dense ( l , ps , st , name ) = ( l , ps , st ) model_frozen , ps_frozen , st_frozen = Lux . @layer_map freeze_dense model ps st model_frozen ( x , ps_frozen , st_frozen ) (Float32[1.7641534 -1.7641534], (layer_1 = (frozen_params = (weight = Float32[-0.026350189 -0.5554656 -0.35653266; -0.17461072 0.6705545 0.29924855; -0.8935247 -0.42453378 -0.3020351; -0.7988979 -0.7666331 -0.7104237], bias = Float32[0.0; 0.0; 0.0; 0.0;;]), states = NamedTuple()), layer_2 = (layer_1 = (frozen_params = (weight = Float32[-0.47289538 -0.680748 0.1764085 0.34383082; 0.42747158 -0.13819042 -0.109261915 -0.6143286; -0.35790488 -0.20881107 0.70390546 0.48137343; 0.82561636 0.38187847 0.05779423 -0.35181466], bias = Float32[0.0; 0.0; 0.0; 0.0;;]), states = NamedTuple()), layer_2 = (rng = Random.Xoshiro(0x87711e5ce1a49ffe, 0xa210b60ecab6b8c5, 0x436c749552fc8172, 0x03e9c7d813a9f096), training = Val{true}()), layer_3 = (running_mean = Float32[-0.04517859, 0.03484953, -0.004917746, 0.0074841487], running_var = Float32[0.94082206, 0.92428976, 0.90048367, 0.90112025], training = Val{true}())), layer_3 = (frozen_params = (weight = Float32[0.3981135 0.45468387 -0.07694905 0.8353388], bias = Float32[0.0;;]), states = NamedTuple())))","title":"Freezing layers of a particular kind"},{"location":"manual/freezing_parameters/#freezing-by-layer-name","text":"When the function in layer_map is called, the 4th argument is the name of the layer. For example, if you want to freeze the 1st layer inside the inner Chain. The name for this would be <model>.layer_2.layer_1 . Freezing by layer name Freezing by layer type function freeze_by_name ( d , ps , st , name :: String ) if name == \"model.layer_2.layer_1\" return Lux . freeze ( d , ps , st , ( :weight , :bias )) else return d , ps , st end end function freeze_dense ( d :: Dense , ps , st , name :: String ) return Lux . freeze ( d , ps , st , ( :weight , :bias )) end freeze_dense ( l , ps , st , name ) = ( l , ps , st )","title":"Freezing by layer name"},{"location":"manual/freezing_parameters/#freezing-part-of-the-parameters","text":"Instead of freezing all the parameters, we can simple specify (:weight,) to freeze only the weight parameter while training the bias parameter. Freezing some parameters of a layer Freezing all parameters of a layer function freeze_by_name ( d , ps , st , name :: String ) if name == \"model.layer_2.layer_1\" return Lux . freeze ( d , ps , st , ( :weight ,)) else return d , ps , st end end function freeze_by_name ( d , ps , st , name :: String ) if name == \"model.layer_2.layer_1\" return Lux . freeze ( d , ps , st , ( :weight , :bias )) else return d , ps , st end end","title":"Freezing part of the parameters"},{"location":"manual/freezing_parameters/#freezing-part-of-a-chain","text":"Starting v0.4.22 , we can directly index into a Chain . So freezing a part of a Chain , is extremely easy. using Lux , Random rng = Random . default_rng () Random . seed! ( rng , 0 ) model = Chain ( Dense ( 3 , 4 ), Dense ( 4 , 4 ), Dropout ( 0.5f0 ), BatchNorm ( 4 ), Dense ( 4 , 1 )) model_frozen = Chain ( model [ 1 : 2 ], Lux . freeze ( model [ 3 : 4 ]), model [ 5 ]) ps , st = Lux . setup ( rng , model_frozen ) x = randn ( rng , Float32 , 3 , 2 ) model_frozen ( x , ps , st ) (Float32[1.7641534 -1.7641534], (layer_1 = NamedTuple(), layer_2 = NamedTuple(), layer_3 = (frozen_params = (layer_3 = NamedTuple(), layer_4 = (scale = Float32[1.0, 1.0, 1.0, 1.0], bias = Float32[0.0, 0.0, 0.0, 0.0])), states = (layer_3 = (rng = Random.Xoshiro(0x87711e5ce1a49ffe, 0xa210b60ecab6b8c5, 0x436c749552fc8172, 0x03e9c7d813a9f096), training = Val{true}()), layer_4 = (running_mean = Float32[-0.04517859, 0.03484953, -0.004917746, 0.0074841487], running_var = Float32[0.94082206, 0.92428976, 0.90048367, 0.90112025], training = Val{true}()))), layer_4 = NamedTuple()))","title":"Freezing part of a Chain"},{"location":"manual/interface/","text":"Lux Interface \u00a4 First let's set the expectations straight. Do you have to follow the interface? No . Should you follow it? Probably yes . Why? It provides the ability for frameworks built on top of Lux to be cross compatible. Additionally, any new functionality built into Lux, will just work for your framework. Warning The interface is optional for frameworks being developed independent of Lux. All functionality in the core library (and officially supported ones) must adhere to the interface Layer Interface \u00a4 Singular Layer \u00a4 If the layer doesn't contain any other Lux layer, then it is a Singular Layer . This means it should optionally subtype Lux.AbstractExplicitLayer but mandatorily define all the necessary functions mentioned in the docstrings. Consider a simplified version of Dense called Linear . First, setup the architectural details for this layer. Note, that the architecture doesn't contain any mutable structure like arrays. When in doubt, remember, once constructed a model architecture cannot change. Tip For people coming from Flux.jl background this might be weird. We recommend checking out the Flux to Lux migration guide first before proceeding. using Lux , Random struct Linear { F1 , F2 } <: Lux . AbstractExplicitLayer in_dims :: Int out_dims :: Int init_weight :: F1 init_bias :: F2 end function Linear ( in_dims :: Int , out_dims :: Int ; init_weight = Lux . glorot_uniform , init_bias = Lux . zeros32 ) return Linear { typeof ( init_weight ), typeof ( init_bias )}( in_dims , out_dims , init_weight , init_bias ) end l = Linear ( 2 , 4 ) Linear() Next, we need to implement functions which return the parameters and states for the layer. In case of Linear , the parameters are weight and bias while the states are empty. States become important when defining layers like BatchNorm , WeightNorm , etc. The recommended data structure for returning parameters is a NamedTuple, though anything satisfying the Parameter Interface is valid. function Lux . initialparameters ( rng :: AbstractRNG , l :: Linear ) return ( weight = l . init_weight ( rng , l . out_dims , l . in_dims ), bias = l . init_bias ( rng , l . out_dims , 1 )) end Lux . initialstates ( :: AbstractRNG , :: Linear ) = NamedTuple () You could also implement Lux.parameterlength and Lux.statelength to prevent wasteful reconstruction of the parameters and states. # This works println ( \"Parameter Length: \" , Lux . parameterlength ( l ), \"; State Length: \" , Lux . statelength ( l )) # But still recommened to define these Lux . parameterlength ( l :: Linear ) = l . out_dims * l . in_dims + l . out_dims Lux . statelength ( :: Linear ) = 0 Parameter Length: 12; State Length: 0 Tip You might notice that we don't pass in a PRNG for these functions. If your parameter length and/or state length depend on a random number generator, you should think really hard about what you are trying to do and why. Now, we need to define how the layer works. For this you make your layer a function with exactly 3 arguments \u2013 x the input, ps the parameters, and st the states. This function must return two things \u2013 y the output, and st_new the updated state. function ( l :: Linear )( x :: AbstractMatrix , ps , st :: NamedTuple ) y = ps . weight * x .+ ps . bias return y , st end Finally, let's run this layer. If you have made this far into the documentation, we don't feel you need a refresher on that. rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , l ) println ( \"Parameter Length: \" , Lux . parameterlength ( l ), \"; State Length: \" , Lux . statelength ( l )) x = randn ( rng , Float32 , 2 , 1 ) Lux . apply ( l , x , ps , st ) # or `l(x, ps, st)` (Float32[-0.15276335; 0.45325348; 1.0207279; 0.78226817;;], NamedTuple()) Container Layer \u00a4 If your layer comprises of other Lux layers, then it is a Container Layer . Note that you could treat it as a Singular Layer , and it is still fine. FWIW, if you cannot subtype your layer with Lux.AbstractExplicitContainerLayer then you should go down the Singular Layer route. But subtyping allows us to bypass some of these common definitions. Let us now define a layer, which is basically a composition of two linear layers. struct ComposedLinear { L1 , L2 } <: Lux . AbstractExplicitContainerLayer {( :linear_1 , :linear_2 )} linear_1 :: L1 linear_2 :: L2 end function ( cl :: ComposedLinear )( x :: AbstractMatrix , ps , st :: NamedTuple ) # To access the parameters and states for `linear_1` we do `ps.linear_1` and # `st.linear_1`. Similarly for `linear_2` y , st_l1 = cl . linear_1 ( x , ps . linear_1 , st . linear_1 ) y , st_l2 = cl . linear_2 ( y , ps . linear_2 , st . linear_2 ) # Finally, we need to return the new state which has the exact structure as `st` return y , ( linear_1 = st_l1 , linear_2 = st_l2 ) end Here, you will notice we have passed (:linear_1, :linear_2) to the supertype. It essentially informs the type that, <obj>.linear_1 and <obj>.linear_2 are Lux layers and we need to construct parameters and states for those. Let's construct these and see: model = ComposedLinear ( Linear ( 2 , 4 ), Linear ( 4 , 2 )) display ( model ) ps , st = Lux . setup ( rng , model ) println ( \"Parameters: \" , ps ) println ( \"States: \" , st ) println ( \"Parameter Length: \" , Lux . parameterlength ( model ), \"; State Length: \" , Lux . statelength ( model )) x = randn ( rng , Float32 , 2 , 1 ) Lux . apply ( model , x , ps , st ) # or `model(x, ps, st)` (Float32[1.3410565; 0.78000563;;], (linear_1 = NamedTuple(), linear_2 = NamedTuple())) Parameter Interface \u00a4 We accept any parameter type as long as we can fetch the parameters using getproperty(obj, :parameter_name) . This allows us to simulaneously support NamedTuple s and ComponentArray s. Let us go through a concrete example of what it means. Consider Dense which expects two parameters named weight and bias . Note If you are defining your own parameter type, it is your responsibility to make sure that it works with the AutoDiff System you are using. using Lux , Random d = Dense ( 2 , 3 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps_default , st = Lux . setup ( rng , d ) x = randn ( rng , Float32 , 2 , 1 ) println ( \"Result with `NamedTuple` parameters: \" , first ( d ( x , ps_default , st ))) Result with `NamedTuple` parameters: Float32[1.135916; 0.7668784; -1.0876652;;] Let, us define a custom paramter type with fields myweight and mybias but if we try to access weight we get back myweight , similar for bias . Warning This is for demonstrative purposes, don't try this at home! struct DenseLayerParameters { W , B } myweight :: W mybias :: B end function Base . getproperty ( ps :: DenseLayerParameters , x :: Symbol ) if x == :weight return getfield ( ps , :myweight ) elseif x == :bias return getfield ( ps , :mybias ) end return getfield ( ps , x ) end ps = DenseLayerParameters ( ps_default . weight , ps_default . bias ) println ( \"Result with `DenseLayerParameters` parameters: \" , first ( d ( x , ps , st ))) Result with `DenseLayerParameters` parameters: Float32[1.135916; 0.7668784; -1.0876652;;] The takeaway from this shouldn't be \u2013 lets define weird parameter types . Simply because you can do weird things like this doesn't mean you should, since it only leads to bugs. Instead this shows the flexibility you have for how your parameters can be structured. State Interface \u00a4 States are always type constrained to be NamedTuple . The structure of the input state must match that of the output state, i.e. keys(st_in) == keys(st_out) . This doesn't imply that types of the input and output state match. To generate efficient code, we often do dispatch on the state, for example, Dropout , BatchNorm , etc.","title":"Lux Interface"},{"location":"manual/interface/#lux-interface","text":"First let's set the expectations straight. Do you have to follow the interface? No . Should you follow it? Probably yes . Why? It provides the ability for frameworks built on top of Lux to be cross compatible. Additionally, any new functionality built into Lux, will just work for your framework. Warning The interface is optional for frameworks being developed independent of Lux. All functionality in the core library (and officially supported ones) must adhere to the interface","title":"Lux Interface"},{"location":"manual/interface/#layer-interface","text":"","title":"Layer Interface"},{"location":"manual/interface/#singular-layer","text":"If the layer doesn't contain any other Lux layer, then it is a Singular Layer . This means it should optionally subtype Lux.AbstractExplicitLayer but mandatorily define all the necessary functions mentioned in the docstrings. Consider a simplified version of Dense called Linear . First, setup the architectural details for this layer. Note, that the architecture doesn't contain any mutable structure like arrays. When in doubt, remember, once constructed a model architecture cannot change. Tip For people coming from Flux.jl background this might be weird. We recommend checking out the Flux to Lux migration guide first before proceeding. using Lux , Random struct Linear { F1 , F2 } <: Lux . AbstractExplicitLayer in_dims :: Int out_dims :: Int init_weight :: F1 init_bias :: F2 end function Linear ( in_dims :: Int , out_dims :: Int ; init_weight = Lux . glorot_uniform , init_bias = Lux . zeros32 ) return Linear { typeof ( init_weight ), typeof ( init_bias )}( in_dims , out_dims , init_weight , init_bias ) end l = Linear ( 2 , 4 ) Linear() Next, we need to implement functions which return the parameters and states for the layer. In case of Linear , the parameters are weight and bias while the states are empty. States become important when defining layers like BatchNorm , WeightNorm , etc. The recommended data structure for returning parameters is a NamedTuple, though anything satisfying the Parameter Interface is valid. function Lux . initialparameters ( rng :: AbstractRNG , l :: Linear ) return ( weight = l . init_weight ( rng , l . out_dims , l . in_dims ), bias = l . init_bias ( rng , l . out_dims , 1 )) end Lux . initialstates ( :: AbstractRNG , :: Linear ) = NamedTuple () You could also implement Lux.parameterlength and Lux.statelength to prevent wasteful reconstruction of the parameters and states. # This works println ( \"Parameter Length: \" , Lux . parameterlength ( l ), \"; State Length: \" , Lux . statelength ( l )) # But still recommened to define these Lux . parameterlength ( l :: Linear ) = l . out_dims * l . in_dims + l . out_dims Lux . statelength ( :: Linear ) = 0 Parameter Length: 12; State Length: 0 Tip You might notice that we don't pass in a PRNG for these functions. If your parameter length and/or state length depend on a random number generator, you should think really hard about what you are trying to do and why. Now, we need to define how the layer works. For this you make your layer a function with exactly 3 arguments \u2013 x the input, ps the parameters, and st the states. This function must return two things \u2013 y the output, and st_new the updated state. function ( l :: Linear )( x :: AbstractMatrix , ps , st :: NamedTuple ) y = ps . weight * x .+ ps . bias return y , st end Finally, let's run this layer. If you have made this far into the documentation, we don't feel you need a refresher on that. rng = Random . default_rng () Random . seed! ( rng , 0 ) ps , st = Lux . setup ( rng , l ) println ( \"Parameter Length: \" , Lux . parameterlength ( l ), \"; State Length: \" , Lux . statelength ( l )) x = randn ( rng , Float32 , 2 , 1 ) Lux . apply ( l , x , ps , st ) # or `l(x, ps, st)` (Float32[-0.15276335; 0.45325348; 1.0207279; 0.78226817;;], NamedTuple())","title":"Singular Layer"},{"location":"manual/interface/#container-layer","text":"If your layer comprises of other Lux layers, then it is a Container Layer . Note that you could treat it as a Singular Layer , and it is still fine. FWIW, if you cannot subtype your layer with Lux.AbstractExplicitContainerLayer then you should go down the Singular Layer route. But subtyping allows us to bypass some of these common definitions. Let us now define a layer, which is basically a composition of two linear layers. struct ComposedLinear { L1 , L2 } <: Lux . AbstractExplicitContainerLayer {( :linear_1 , :linear_2 )} linear_1 :: L1 linear_2 :: L2 end function ( cl :: ComposedLinear )( x :: AbstractMatrix , ps , st :: NamedTuple ) # To access the parameters and states for `linear_1` we do `ps.linear_1` and # `st.linear_1`. Similarly for `linear_2` y , st_l1 = cl . linear_1 ( x , ps . linear_1 , st . linear_1 ) y , st_l2 = cl . linear_2 ( y , ps . linear_2 , st . linear_2 ) # Finally, we need to return the new state which has the exact structure as `st` return y , ( linear_1 = st_l1 , linear_2 = st_l2 ) end Here, you will notice we have passed (:linear_1, :linear_2) to the supertype. It essentially informs the type that, <obj>.linear_1 and <obj>.linear_2 are Lux layers and we need to construct parameters and states for those. Let's construct these and see: model = ComposedLinear ( Linear ( 2 , 4 ), Linear ( 4 , 2 )) display ( model ) ps , st = Lux . setup ( rng , model ) println ( \"Parameters: \" , ps ) println ( \"States: \" , st ) println ( \"Parameter Length: \" , Lux . parameterlength ( model ), \"; State Length: \" , Lux . statelength ( model )) x = randn ( rng , Float32 , 2 , 1 ) Lux . apply ( model , x , ps , st ) # or `model(x, ps, st)` (Float32[1.3410565; 0.78000563;;], (linear_1 = NamedTuple(), linear_2 = NamedTuple()))","title":"Container Layer"},{"location":"manual/interface/#parameter-interface","text":"We accept any parameter type as long as we can fetch the parameters using getproperty(obj, :parameter_name) . This allows us to simulaneously support NamedTuple s and ComponentArray s. Let us go through a concrete example of what it means. Consider Dense which expects two parameters named weight and bias . Note If you are defining your own parameter type, it is your responsibility to make sure that it works with the AutoDiff System you are using. using Lux , Random d = Dense ( 2 , 3 ) rng = Random . default_rng () Random . seed! ( rng , 0 ) ps_default , st = Lux . setup ( rng , d ) x = randn ( rng , Float32 , 2 , 1 ) println ( \"Result with `NamedTuple` parameters: \" , first ( d ( x , ps_default , st ))) Result with `NamedTuple` parameters: Float32[1.135916; 0.7668784; -1.0876652;;] Let, us define a custom paramter type with fields myweight and mybias but if we try to access weight we get back myweight , similar for bias . Warning This is for demonstrative purposes, don't try this at home! struct DenseLayerParameters { W , B } myweight :: W mybias :: B end function Base . getproperty ( ps :: DenseLayerParameters , x :: Symbol ) if x == :weight return getfield ( ps , :myweight ) elseif x == :bias return getfield ( ps , :mybias ) end return getfield ( ps , x ) end ps = DenseLayerParameters ( ps_default . weight , ps_default . bias ) println ( \"Result with `DenseLayerParameters` parameters: \" , first ( d ( x , ps , st ))) Result with `DenseLayerParameters` parameters: Float32[1.135916; 0.7668784; -1.0876652;;] The takeaway from this shouldn't be \u2013 lets define weird parameter types . Simply because you can do weird things like this doesn't mean you should, since it only leads to bugs. Instead this shows the flexibility you have for how your parameters can be structured.","title":"Parameter Interface"},{"location":"manual/interface/#state-interface","text":"States are always type constrained to be NamedTuple . The structure of the input state must match that of the output state, i.e. keys(st_in) == keys(st_out) . This doesn't imply that types of the input and output state match. To generate efficient code, we often do dispatch on the state, for example, Dropout , BatchNorm , etc.","title":"State Interface"},{"location":"manual/migrate_from_flux/","text":"Migrating from Flux to Lux \u00a4 For the core library layers like Dense , Conv , etc. we have intentionlly kept the API very similar to Flux. In most cases, replacing using Flux with using Lux should be enough to get you started. We cover the additional changes that you will have to make in the following example. Lux Flux using Lux , Random , NNlib , Zygote model = Chain ( Dense ( 2 => 4 ), BatchNorm ( 4 , relu ), Dense ( 4 => 2 )) rng = Random . default_rng () x = randn ( rng , Float32 , 2 , 4 ) ps , st = Lux . setup ( rng , model ) model ( x , ps , st ) gradient ( ps -> sum ( first ( model ( x , ps , st ))), ps ) using Flux , Random , NNlib , Zygote model = Chain ( Dense ( 2 => 4 ), BatchNorm ( 4 , relu ), Dense ( 4 => 2 )) rng = Random . default_rng () x = randn ( rng , Float32 , 2 , 4 ) model ( x ) gradient ( model -> sum ( model ( x )), model ) Implementing Custom Layers \u00a4 Flux and Lux operate under extremely different design philosophies regarding how layers should be implemented. A summary of the differences would be: Flux stores everything in a single struct and relies on Functors.@functor and Flux.trainable to distinguish between trainable and non-trainable parameters. Lux relies on the user to define Lux.initialparameters and Lux.initialstates to distinguish between trainable parameters (called \"parameters\") and non-trainable parameters (called \"states\"). Additionally Lux layers define the model architecture, hence device transfer utilities like gpu , cpu , etc. cannot be applied on Lux layers, instead they need to be applied on the parameters and states. Let's work through a concrete example to demonstrate this. We will implement a very simple layer that computes \\(A \\times B \\times x\\) where \\(A\\) is not trainable and \\(B\\) is trainable. Lux Flux using Lux , Random , NNlib , Zygote struct LuxLinear <: Lux . AbstractExplicitLayer init_A init_B end function LuxLinear ( A :: AbstractArray , B :: AbstractArray ) # Storing Arrays or any mutable structure inside a Lux Layer is not recommended # instead we will convert this to a function to perform lazy initialization return LuxLinear (() -> copy ( A ), () -> copy ( B )) end # `B` is a parameter Lux . initialparameters ( rng :: AbstractRNG , layer :: LuxLinear ) = ( B = layer . init_B (),) # `A` is a state Lux . initialstates ( rng :: AbstractRNG , layer :: LuxLinear ) = ( A = layer . init_A (),) ( l :: LuxLinear )( x , ps , st ) = st . A * ps . B * x , st using Flux , Random , NNlib , Zygote , Optimisers struct FluxLinear A B end # `A` is not trainable Optimisers . trainable ( f :: FluxLinear ) = ( B = f . B ,) # Needed so that both `A` and `B` can be transfered between devices Flux . @functor FluxLinear ( l :: FluxLinear )( x ) = l . A * l . B * x Now let us run the model. Lux Flux rng = Random . default_rng () model = LuxLinear ( randn ( rng , 2 , 4 ), randn ( rng , 4 , 2 )) x = randn ( rng , 2 , 1 ) ps , st = Lux . setup ( rng , model ) model ( x , ps , st ) gradient ( ps -> sum ( first ( model ( x , ps , st ))), ps ) rng = Random . default_rng () model = FluxLinear ( randn ( rng , 2 , 4 ), randn ( rng , 4 , 2 )) x = randn ( rng , 2 , 1 ) model ( x ) gradient ( model -> sum ( model ( x )), model ) To reiterate some of the important points: Don't store mutables like Arrays inside a Lux Layer. Parameters and States should be constructured inside the respective initial* functions. Certain Important Implementation Details \u00a4 Training/Inference Mode \u00a4 Flux supports a mode called :auto which automatically decides if the user is training the model or running inference. This is the default mode for Flux.BatchNorm , Flux.GroupNorm , Flux.Dropout , etc. Lux doesn't support this mode (specifically to keep code simple and do exactly what the user wants), hence our default mode is training . This can be changed using Lux.testmode . Can't access functions like relu , sigmoid , etc? \u00a4 Unlike Flux we don't reexport functionality from NNlib , all you need to do to fix this is add using NNlib . Missing some common layers from Flux \u00a4 Lux is a very new framework, as such we haven't implemented all Layers that are a part of Flux. We are tracking the missing features in this issue , and hope to have them implemented soon. If you really need those functionality check out the next section. Can we still use Flux Layers? \u00a4 We don't recommend this method, but here is a way to compose Flux with Lux. using Lux , NNlib , Random , Optimisers import Flux # Layer Implementation struct FluxCompatLayer { L , I } <: Lux . AbstractExplicitLayer layer :: L init_parameters :: I end function FluxCompatLayer ( flayer ) p , re = Optimisers . destructure ( flayer ) p_ = copy ( p ) return FluxCompatLayer ( re , () -> p_ ) end Lux . initialparameters ( rng :: AbstractRNG , l :: FluxCompatLayer ) = ( p = l . init_parameters (),) ( f :: FluxCompatLayer )( x , ps , st ) = f . layer ( ps . p )( x ), st # Running the model fmodel = Flux . Chain ( Flux . Dense ( 3 => 4 , relu ), Flux . Dense ( 4 => 1 )) lmodel = FluxCompatLayer ( fmodel ) rng = Random . default_rng () x = randn ( rng , 3 , 1 ) ps , st = Lux . setup ( rng , lmodel ) lmodel ( x , ps , st )[ 1 ] == fmodel ( x )","title":"Migrating from Flux to Lux"},{"location":"manual/migrate_from_flux/#migrating-from-flux-to-lux","text":"For the core library layers like Dense , Conv , etc. we have intentionlly kept the API very similar to Flux. In most cases, replacing using Flux with using Lux should be enough to get you started. We cover the additional changes that you will have to make in the following example. Lux Flux using Lux , Random , NNlib , Zygote model = Chain ( Dense ( 2 => 4 ), BatchNorm ( 4 , relu ), Dense ( 4 => 2 )) rng = Random . default_rng () x = randn ( rng , Float32 , 2 , 4 ) ps , st = Lux . setup ( rng , model ) model ( x , ps , st ) gradient ( ps -> sum ( first ( model ( x , ps , st ))), ps ) using Flux , Random , NNlib , Zygote model = Chain ( Dense ( 2 => 4 ), BatchNorm ( 4 , relu ), Dense ( 4 => 2 )) rng = Random . default_rng () x = randn ( rng , Float32 , 2 , 4 ) model ( x ) gradient ( model -> sum ( model ( x )), model )","title":"Migrating from Flux to Lux"},{"location":"manual/migrate_from_flux/#implementing-custom-layers","text":"Flux and Lux operate under extremely different design philosophies regarding how layers should be implemented. A summary of the differences would be: Flux stores everything in a single struct and relies on Functors.@functor and Flux.trainable to distinguish between trainable and non-trainable parameters. Lux relies on the user to define Lux.initialparameters and Lux.initialstates to distinguish between trainable parameters (called \"parameters\") and non-trainable parameters (called \"states\"). Additionally Lux layers define the model architecture, hence device transfer utilities like gpu , cpu , etc. cannot be applied on Lux layers, instead they need to be applied on the parameters and states. Let's work through a concrete example to demonstrate this. We will implement a very simple layer that computes \\(A \\times B \\times x\\) where \\(A\\) is not trainable and \\(B\\) is trainable. Lux Flux using Lux , Random , NNlib , Zygote struct LuxLinear <: Lux . AbstractExplicitLayer init_A init_B end function LuxLinear ( A :: AbstractArray , B :: AbstractArray ) # Storing Arrays or any mutable structure inside a Lux Layer is not recommended # instead we will convert this to a function to perform lazy initialization return LuxLinear (() -> copy ( A ), () -> copy ( B )) end # `B` is a parameter Lux . initialparameters ( rng :: AbstractRNG , layer :: LuxLinear ) = ( B = layer . init_B (),) # `A` is a state Lux . initialstates ( rng :: AbstractRNG , layer :: LuxLinear ) = ( A = layer . init_A (),) ( l :: LuxLinear )( x , ps , st ) = st . A * ps . B * x , st using Flux , Random , NNlib , Zygote , Optimisers struct FluxLinear A B end # `A` is not trainable Optimisers . trainable ( f :: FluxLinear ) = ( B = f . B ,) # Needed so that both `A` and `B` can be transfered between devices Flux . @functor FluxLinear ( l :: FluxLinear )( x ) = l . A * l . B * x Now let us run the model. Lux Flux rng = Random . default_rng () model = LuxLinear ( randn ( rng , 2 , 4 ), randn ( rng , 4 , 2 )) x = randn ( rng , 2 , 1 ) ps , st = Lux . setup ( rng , model ) model ( x , ps , st ) gradient ( ps -> sum ( first ( model ( x , ps , st ))), ps ) rng = Random . default_rng () model = FluxLinear ( randn ( rng , 2 , 4 ), randn ( rng , 4 , 2 )) x = randn ( rng , 2 , 1 ) model ( x ) gradient ( model -> sum ( model ( x )), model ) To reiterate some of the important points: Don't store mutables like Arrays inside a Lux Layer. Parameters and States should be constructured inside the respective initial* functions.","title":"Implementing Custom Layers"},{"location":"manual/migrate_from_flux/#certain-important-implementation-details","text":"","title":"Certain Important Implementation Details"},{"location":"manual/migrate_from_flux/#traininginference-mode","text":"Flux supports a mode called :auto which automatically decides if the user is training the model or running inference. This is the default mode for Flux.BatchNorm , Flux.GroupNorm , Flux.Dropout , etc. Lux doesn't support this mode (specifically to keep code simple and do exactly what the user wants), hence our default mode is training . This can be changed using Lux.testmode .","title":"Training/Inference Mode"},{"location":"manual/migrate_from_flux/#cant-access-functions-like-relu-sigmoid-etc","text":"Unlike Flux we don't reexport functionality from NNlib , all you need to do to fix this is add using NNlib .","title":"Can't access functions like relu, sigmoid, etc?"},{"location":"manual/migrate_from_flux/#missing-some-common-layers-from-flux","text":"Lux is a very new framework, as such we haven't implemented all Layers that are a part of Flux. We are tracking the missing features in this issue , and hope to have them implemented soon. If you really need those functionality check out the next section.","title":"Missing some common layers from Flux"},{"location":"manual/migrate_from_flux/#can-we-still-use-flux-layers","text":"We don't recommend this method, but here is a way to compose Flux with Lux. using Lux , NNlib , Random , Optimisers import Flux # Layer Implementation struct FluxCompatLayer { L , I } <: Lux . AbstractExplicitLayer layer :: L init_parameters :: I end function FluxCompatLayer ( flayer ) p , re = Optimisers . destructure ( flayer ) p_ = copy ( p ) return FluxCompatLayer ( re , () -> p_ ) end Lux . initialparameters ( rng :: AbstractRNG , l :: FluxCompatLayer ) = ( p = l . init_parameters (),) ( f :: FluxCompatLayer )( x , ps , st ) = f . layer ( ps . p )( x ), st # Running the model fmodel = Flux . Chain ( Flux . Dense ( 3 => 4 , relu ), Flux . Dense ( 4 => 1 )) lmodel = FluxCompatLayer ( fmodel ) rng = Random . default_rng () x = randn ( rng , 3 , 1 ) ps , st = Lux . setup ( rng , lmodel ) lmodel ( x , ps , st )[ 1 ] == fmodel ( x )","title":"Can we still use Flux Layers?"}]}